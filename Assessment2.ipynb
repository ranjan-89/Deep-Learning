{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl-rzbgFNXTi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Day 1"
      ],
      "metadata": {
        "id": "iMAxsgBn6Vhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation function**"
      ],
      "metadata": {
        "id": "POTB3MQ-y0pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+math.exp(-x))"
      ],
      "metadata": {
        "id": "H6zRfhtqynhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHVI8OEAzIUH",
        "outputId": "dcfc54f0-b9c7-47f6-8b68-c4626610be2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7310585786300049"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggSgFTaszIg4",
        "outputId": "4f700443-9f4a-4e2a-ce81-4928320ffc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tanh"
      ],
      "metadata": {
        "id": "zL71T9_OzRXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tanh(x):\n",
        "  return math.exp(x)-math.exp(-x)/(math.exp(x)+math.exp(-x))"
      ],
      "metadata": {
        "id": "uf8i9wpgzIqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tanh(-499)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0wCIiWIzbgZ",
        "outputId": "d88e3067-053a-46bb-c3da-d103501704dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tanh(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3EmlImezpca",
        "outputId": "e1619325-9665-4e26-c3f9-23d4d00ac758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22026.465794804655"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tanh(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTJfm-DkzsNo",
        "outputId": "40fd758a-9e2b-47f3-a9c7-9111f9958663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU"
      ],
      "metadata": {
        "id": "ddftcJJBz9ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Relu(x):\n",
        "  return(max(0,x))"
      ],
      "metadata": {
        "id": "1b2YIZ1H0Be3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Relu(-56)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmyMg0Sf0RCD",
        "outputId": "e9db9fab-9ef8-4ab5-a1ce-909ca9ab768e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Relu(456)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJsJh3Rt0aVP",
        "outputId": "81fdd4ad-e4a0-4908-c11e-adff19d09e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "456"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Relu(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VugLv_380clA",
        "outputId": "e54f0018-5085-49f9-ca5c-11de04dd5e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leaky Relu"
      ],
      "metadata": {
        "id": "UNmD3tcC3i05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LeakyRelu(x):\n",
        "  return(max(0.01*x,x))"
      ],
      "metadata": {
        "id": "FKBnTO-J3nuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LeakyRelu(-56)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JBx3U_w3n7U",
        "outputId": "16e2ae38-3749-4a6e-feca-564b72d46d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.56"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELU"
      ],
      "metadata": {
        "id": "JK_pADAQ31FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def elu(x, alpha=1.0):\n",
        "    return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n"
      ],
      "metadata": {
        "id": "WIxi4Cq23oIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elu(45)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H2spP7b4B3t",
        "outputId": "aa11a773-6b09-42b3-c856-b664edf49db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(45.)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SELU"
      ],
      "metadata": {
        "id": "oYd-55EK4JZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SELU\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def selu(x, alpha=1.6733, scale=1.0507):\n",
        "    return scale * np.where(x > 0, x, alpha * (np.exp(x) - 1))\n"
      ],
      "metadata": {
        "id": "TA8qqIBL4CE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selu(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDfmjXBz4buD",
        "outputId": "d879e6fd-04e4-44b0-b6cb-7790cbf8641a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day1 (01/01/2023)**"
      ],
      "metadata": {
        "id": "Zx2g12VF6gv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/insurance_data (1) (1).csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sTBvk-UVNg_H",
        "outputId": "f84aa5e5-4f73-41b7-eb68-c29344fb928a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  affordibility  bought_insurance\n",
              "0   22              1                 0\n",
              "1   25              0                 0\n",
              "2   47              1                 1\n",
              "3   52              0                 0\n",
              "4   46              1                 1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7598f626-d0b9-4329-aa8a-08a7bcae6585\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>affordibility</th>\n",
              "      <th>bought_insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7598f626-d0b9-4329-aa8a-08a7bcae6585')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7598f626-d0b9-4329-aa8a-08a7bcae6585 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7598f626-d0b9-4329-aa8a-08a7bcae6585');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43d0cd2e-23e4-477f-86ac-7d6a204d16e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43d0cd2e-23e4-477f-86ac-7d6a204d16e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43d0cd2e-23e4-477f-86ac-7d6a204d16e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4cY8er8zrQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOooQXHkOxe1",
        "outputId": "42bc5710-3a3c-47b1-f7d2-3415d9d6b496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into training and testing\n",
        "from sklearn.model_selection  import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2,random_state=20)"
      ],
      "metadata": {
        "id": "ns3ShK1AN90l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkW3spKeOqbH",
        "outputId": "e2cd3573-9cf1-48cf-aa5a-28061a1214ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled=X_train.copy()\n",
        "X_train_scaled['age']=X_train_scaled['age']/100\n",
        "\n",
        "X_test_scaled=X_test.copy()\n",
        "X_test_scaled['age']=X_test_scaled['age']/100\n",
        "\n"
      ],
      "metadata": {
        "id": "TAVVufK6OulW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "TPYyeCbKPYAn",
        "outputId": "9803d0b5-a479-4a39-f2d4-9023a61e9be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  affordibility\n",
              "18  0.19              0\n",
              "25  0.54              1\n",
              "23  0.45              1\n",
              "22  0.40              1\n",
              "21  0.26              0\n",
              "5   0.56              1\n",
              "24  0.50              1\n",
              "19  0.18              1\n",
              "14  0.49              1\n",
              "17  0.58              1\n",
              "6   0.55              0\n",
              "16  0.25              0\n",
              "8   0.62              1\n",
              "0   0.22              1\n",
              "2   0.47              1\n",
              "7   0.60              0\n",
              "11  0.28              1\n",
              "20  0.21              1\n",
              "9   0.61              1\n",
              "15  0.55              1\n",
              "26  0.23              1\n",
              "3   0.52              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44bc7df6-5b35-4bee-b72b-4a71b18e69ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>affordibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.56</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44bc7df6-5b35-4bee-b72b-4a71b18e69ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44bc7df6-5b35-4bee-b72b-4a71b18e69ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44bc7df6-5b35-4bee-b72b-4a71b18e69ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0861aad-e97b-4757-b2bc-be96d3e16bae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0861aad-e97b-4757-b2bc-be96d3e16bae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0861aad-e97b-4757-b2bc-be96d3e16bae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f1002a1d-3018-4292-9595-5c2415dd6c76\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train_scaled')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1002a1d-3018-4292-9595-5c2415dd6c76 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train_scaled');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2=keras.Sequential([\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1,input_shape=(2,),activation='sigmoid',kernel_initializer='ones',bias_initializer='zeros')])\n",
        "\n",
        "model2.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model2.fit(X_train_scaled,y_train,epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74FhaTkdPdYK",
        "outputId": "fe8bf02e-12f8-4503-d334-5f636aa6ec46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.6459 - accuracy: 0.5909\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.5909\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6454 - accuracy: 0.5909\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6451 - accuracy: 0.5909\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6448 - accuracy: 0.5909\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6446 - accuracy: 0.5909\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6443 - accuracy: 0.5909\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6441 - accuracy: 0.5909\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6438 - accuracy: 0.5909\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6435 - accuracy: 0.5909\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6433 - accuracy: 0.5909\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6430 - accuracy: 0.5909\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6428 - accuracy: 0.5909\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6425 - accuracy: 0.5909\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6423 - accuracy: 0.5909\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6420 - accuracy: 0.5909\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.5909\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.5909\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6413 - accuracy: 0.5909\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.5909\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6408 - accuracy: 0.5909\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.5909\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6403 - accuracy: 0.5909\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6400 - accuracy: 0.5909\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - accuracy: 0.5909\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6396 - accuracy: 0.5909\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6393 - accuracy: 0.5909\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6391 - accuracy: 0.5909\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.5909\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6386 - accuracy: 0.5909\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.5909\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6381 - accuracy: 0.5909\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6379 - accuracy: 0.5909\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6377 - accuracy: 0.5909\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6374 - accuracy: 0.5909\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6372 - accuracy: 0.5909\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6370 - accuracy: 0.5909\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6368 - accuracy: 0.5909\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6365 - accuracy: 0.5909\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6363 - accuracy: 0.5909\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6361 - accuracy: 0.5909\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6359 - accuracy: 0.5909\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6356 - accuracy: 0.5909\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6354 - accuracy: 0.5909\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.5909\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6350 - accuracy: 0.5909\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.5909\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6345 - accuracy: 0.5909\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6343 - accuracy: 0.5909\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6341 - accuracy: 0.5909\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 0.5909\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6337 - accuracy: 0.5909\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6335 - accuracy: 0.5909\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6333 - accuracy: 0.5909\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.5909\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6328 - accuracy: 0.5909\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6326 - accuracy: 0.5909\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6324 - accuracy: 0.5909\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6322 - accuracy: 0.5909\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6320 - accuracy: 0.5909\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6318 - accuracy: 0.5909\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6316 - accuracy: 0.5909\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6314 - accuracy: 0.5909\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6312 - accuracy: 0.5909\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6310 - accuracy: 0.5909\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6308 - accuracy: 0.5909\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.5909\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6304 - accuracy: 0.5909\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6302 - accuracy: 0.5909\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6300 - accuracy: 0.5909\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6298 - accuracy: 0.5909\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6297 - accuracy: 0.5909\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6295 - accuracy: 0.5909\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6293 - accuracy: 0.5909\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6291 - accuracy: 0.5909\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6289 - accuracy: 0.5909\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6287 - accuracy: 0.5909\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6285 - accuracy: 0.5909\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6283 - accuracy: 0.5909\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6282 - accuracy: 0.5909\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6280 - accuracy: 0.5909\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6278 - accuracy: 0.5909\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6276 - accuracy: 0.5909\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6274 - accuracy: 0.5909\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6273 - accuracy: 0.5909\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6271 - accuracy: 0.5909\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6269 - accuracy: 0.5909\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6267 - accuracy: 0.5909\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6266 - accuracy: 0.5909\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6264 - accuracy: 0.5909\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6262 - accuracy: 0.5909\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6260 - accuracy: 0.5909\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6259 - accuracy: 0.5909\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.5909\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6255 - accuracy: 0.5909\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6254 - accuracy: 0.5909\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6252 - accuracy: 0.5909\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6250 - accuracy: 0.5909\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6249 - accuracy: 0.5909\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6247 - accuracy: 0.5909\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6245 - accuracy: 0.5909\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6244 - accuracy: 0.5909\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6242 - accuracy: 0.5909\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6241 - accuracy: 0.5909\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.5909\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6237 - accuracy: 0.5909\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6236 - accuracy: 0.5909\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6234 - accuracy: 0.5909\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6233 - accuracy: 0.5909\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6231 - accuracy: 0.5909\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6230 - accuracy: 0.5909\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6228 - accuracy: 0.5909\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.5909\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6225 - accuracy: 0.5909\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6224 - accuracy: 0.5909\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.5909\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6221 - accuracy: 0.5909\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6219 - accuracy: 0.5909\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6218 - accuracy: 0.5909\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6216 - accuracy: 0.5909\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6215 - accuracy: 0.5909\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6213 - accuracy: 0.5909\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6212 - accuracy: 0.5909\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6210 - accuracy: 0.5909\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6209 - accuracy: 0.5909\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.5909\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6206 - accuracy: 0.5909\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6205 - accuracy: 0.5909\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6203 - accuracy: 0.5909\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6202 - accuracy: 0.5909\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6200 - accuracy: 0.5909\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6199 - accuracy: 0.5909\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6198 - accuracy: 0.5909\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6196 - accuracy: 0.5909\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6195 - accuracy: 0.5909\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6194 - accuracy: 0.5909\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6192 - accuracy: 0.5909\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6191 - accuracy: 0.5909\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6190 - accuracy: 0.5909\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6188 - accuracy: 0.5909\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6187 - accuracy: 0.5909\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6186 - accuracy: 0.5909\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6184 - accuracy: 0.5909\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6183 - accuracy: 0.5909\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6182 - accuracy: 0.5909\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6181 - accuracy: 0.5909\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6179 - accuracy: 0.5909\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6178 - accuracy: 0.5909\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.5909\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6175 - accuracy: 0.5909\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6174 - accuracy: 0.5909\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6173 - accuracy: 0.5909\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6172 - accuracy: 0.5909\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.5909\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6169 - accuracy: 0.5909\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6168 - accuracy: 0.5909\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6167 - accuracy: 0.5909\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.5909\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6164 - accuracy: 0.5909\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6163 - accuracy: 0.5909\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6162 - accuracy: 0.5909\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6161 - accuracy: 0.5909\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.5909\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6158 - accuracy: 0.5909\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6157 - accuracy: 0.5909\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6156 - accuracy: 0.5909\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6155 - accuracy: 0.5909\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6154 - accuracy: 0.5909\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6153 - accuracy: 0.5909\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6151 - accuracy: 0.5909\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6150 - accuracy: 0.5909\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6149 - accuracy: 0.5909\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6148 - accuracy: 0.5909\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6147 - accuracy: 0.5909\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6146 - accuracy: 0.5909\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6145 - accuracy: 0.5909\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6143 - accuracy: 0.5909\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6142 - accuracy: 0.5909\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6141 - accuracy: 0.5909\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6140 - accuracy: 0.5909\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6139 - accuracy: 0.5909\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6138 - accuracy: 0.5909\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6137 - accuracy: 0.5909\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6136 - accuracy: 0.5909\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6135 - accuracy: 0.5909\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6134 - accuracy: 0.5909\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6132 - accuracy: 0.5909\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6131 - accuracy: 0.5909\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6130 - accuracy: 0.5909\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.5909\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6128 - accuracy: 0.5909\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6127 - accuracy: 0.5909\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6126 - accuracy: 0.5909\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6125 - accuracy: 0.6364\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.6364\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6123 - accuracy: 0.6364\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6122 - accuracy: 0.6364\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6121 - accuracy: 0.6364\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6120 - accuracy: 0.6364\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6119 - accuracy: 0.6364\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6118 - accuracy: 0.6364\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.6364\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6116 - accuracy: 0.6364\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6115 - accuracy: 0.6364\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.6364\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6113 - accuracy: 0.6364\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6112 - accuracy: 0.6364\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6111 - accuracy: 0.6364\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.6364\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6109 - accuracy: 0.6364\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6108 - accuracy: 0.6364\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6107 - accuracy: 0.6364\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6106 - accuracy: 0.6364\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.6364\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6104 - accuracy: 0.6364\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6103 - accuracy: 0.6364\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6102 - accuracy: 0.6364\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6101 - accuracy: 0.6364\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6100 - accuracy: 0.6364\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6099 - accuracy: 0.6364\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6098 - accuracy: 0.6364\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6097 - accuracy: 0.6364\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6096 - accuracy: 0.6364\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6095 - accuracy: 0.6364\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6094 - accuracy: 0.6364\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6093 - accuracy: 0.6364\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6092 - accuracy: 0.6364\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6091 - accuracy: 0.6364\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6090 - accuracy: 0.6364\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6089 - accuracy: 0.6364\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6088 - accuracy: 0.6364\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6087 - accuracy: 0.6364\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.6364\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6085 - accuracy: 0.6364\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6084 - accuracy: 0.6364\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6083 - accuracy: 0.6364\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6082 - accuracy: 0.6364\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6082 - accuracy: 0.6364\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6081 - accuracy: 0.6364\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6080 - accuracy: 0.6364\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6079 - accuracy: 0.6364\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6078 - accuracy: 0.6364\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6077 - accuracy: 0.6364\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6076 - accuracy: 0.6364\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6075 - accuracy: 0.6364\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6074 - accuracy: 0.6364\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.6364\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6072 - accuracy: 0.6364\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6071 - accuracy: 0.6364\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.6364\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6069 - accuracy: 0.6364\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6069 - accuracy: 0.6364\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6068 - accuracy: 0.6364\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.6364\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6066 - accuracy: 0.6364\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6065 - accuracy: 0.6364\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6064 - accuracy: 0.6364\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6063 - accuracy: 0.6364\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.6364\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6061 - accuracy: 0.6364\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6060 - accuracy: 0.6364\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6060 - accuracy: 0.6364\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6059 - accuracy: 0.6364\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6058 - accuracy: 0.6364\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6057 - accuracy: 0.6364\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6056 - accuracy: 0.6364\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6055 - accuracy: 0.6364\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6054 - accuracy: 0.6364\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6053 - accuracy: 0.6364\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6052 - accuracy: 0.6364\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6052 - accuracy: 0.6364\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6051 - accuracy: 0.6364\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6050 - accuracy: 0.6364\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.6364\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6048 - accuracy: 0.6364\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.6364\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6046 - accuracy: 0.6364\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6045 - accuracy: 0.6364\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6045 - accuracy: 0.6364\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6044 - accuracy: 0.6364\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6043 - accuracy: 0.6364\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6042 - accuracy: 0.6364\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6041 - accuracy: 0.6364\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6040 - accuracy: 0.6364\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6039 - accuracy: 0.6364\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6038 - accuracy: 0.6364\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6038 - accuracy: 0.6364\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6037 - accuracy: 0.6364\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6036 - accuracy: 0.6364\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6035 - accuracy: 0.6364\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6034 - accuracy: 0.6364\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6033 - accuracy: 0.6364\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6032 - accuracy: 0.6364\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6032 - accuracy: 0.6364\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6031 - accuracy: 0.6364\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6030 - accuracy: 0.6364\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6029 - accuracy: 0.6364\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6028 - accuracy: 0.5909\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6027 - accuracy: 0.5909\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6026 - accuracy: 0.5909\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6026 - accuracy: 0.5909\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6025 - accuracy: 0.5909\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6024 - accuracy: 0.5909\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6023 - accuracy: 0.5909\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6022 - accuracy: 0.5909\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6021 - accuracy: 0.5909\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6021 - accuracy: 0.5909\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6020 - accuracy: 0.5909\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6019 - accuracy: 0.5909\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6018 - accuracy: 0.5909\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6017 - accuracy: 0.5909\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6016 - accuracy: 0.5909\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6016 - accuracy: 0.5909\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6015 - accuracy: 0.5909\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.5909\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6013 - accuracy: 0.5909\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6012 - accuracy: 0.5909\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6011 - accuracy: 0.5909\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6011 - accuracy: 0.5909\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6010 - accuracy: 0.5909\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.5909\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6008 - accuracy: 0.5909\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6007 - accuracy: 0.5909\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6006 - accuracy: 0.6364\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6006 - accuracy: 0.6364\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6005 - accuracy: 0.6364\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6004 - accuracy: 0.6364\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6003 - accuracy: 0.6364\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6002 - accuracy: 0.6364\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6002 - accuracy: 0.6364\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6001 - accuracy: 0.6364\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6000 - accuracy: 0.6364\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5999 - accuracy: 0.6364\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5998 - accuracy: 0.6364\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5997 - accuracy: 0.6364\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.6364\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5996 - accuracy: 0.6364\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5995 - accuracy: 0.6364\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5994 - accuracy: 0.6364\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5993 - accuracy: 0.6364\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5993 - accuracy: 0.6364\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5992 - accuracy: 0.6364\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5991 - accuracy: 0.6364\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5990 - accuracy: 0.6364\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5989 - accuracy: 0.6364\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5989 - accuracy: 0.6364\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5988 - accuracy: 0.6364\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5987 - accuracy: 0.6364\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5986 - accuracy: 0.6364\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5985 - accuracy: 0.6364\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5985 - accuracy: 0.6364\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5984 - accuracy: 0.6364\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5983 - accuracy: 0.6364\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5982 - accuracy: 0.6364\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5981 - accuracy: 0.6364\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5981 - accuracy: 0.6364\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5980 - accuracy: 0.6364\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5979 - accuracy: 0.6364\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5978 - accuracy: 0.6364\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5977 - accuracy: 0.6364\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5977 - accuracy: 0.6364\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5976 - accuracy: 0.6364\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5975 - accuracy: 0.6364\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5974 - accuracy: 0.6364\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5973 - accuracy: 0.6364\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5973 - accuracy: 0.6364\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5972 - accuracy: 0.6364\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5971 - accuracy: 0.6364\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5970 - accuracy: 0.6364\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5970 - accuracy: 0.6364\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5969 - accuracy: 0.6364\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5968 - accuracy: 0.6364\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.6364\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5966 - accuracy: 0.6364\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5966 - accuracy: 0.6364\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5965 - accuracy: 0.6364\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5964 - accuracy: 0.6364\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5963 - accuracy: 0.6364\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5963 - accuracy: 0.6364\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5962 - accuracy: 0.6364\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5961 - accuracy: 0.6364\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5960 - accuracy: 0.6364\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5959 - accuracy: 0.6364\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5959 - accuracy: 0.6364\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5958 - accuracy: 0.6364\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5957 - accuracy: 0.6364\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5956 - accuracy: 0.6364\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5956 - accuracy: 0.6364\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5955 - accuracy: 0.6364\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5954 - accuracy: 0.6364\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5953 - accuracy: 0.6364\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5953 - accuracy: 0.6364\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5952 - accuracy: 0.6364\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5951 - accuracy: 0.6364\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5950 - accuracy: 0.6364\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5950 - accuracy: 0.6364\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5949 - accuracy: 0.6364\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5948 - accuracy: 0.6364\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5947 - accuracy: 0.6364\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5946 - accuracy: 0.6364\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5946 - accuracy: 0.6364\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5945 - accuracy: 0.6364\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5944 - accuracy: 0.6364\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5943 - accuracy: 0.6364\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5943 - accuracy: 0.6364\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5942 - accuracy: 0.6364\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5941 - accuracy: 0.6364\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5940 - accuracy: 0.6364\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5940 - accuracy: 0.6364\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5939 - accuracy: 0.6364\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5938 - accuracy: 0.6364\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5937 - accuracy: 0.6364\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5937 - accuracy: 0.6364\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5936 - accuracy: 0.6364\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5935 - accuracy: 0.6364\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5934 - accuracy: 0.6364\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5934 - accuracy: 0.6364\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5933 - accuracy: 0.6364\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5932 - accuracy: 0.6364\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5931 - accuracy: 0.6364\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5931 - accuracy: 0.6364\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5930 - accuracy: 0.6364\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5929 - accuracy: 0.6364\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5929 - accuracy: 0.6364\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.6364\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5927 - accuracy: 0.6364\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5926 - accuracy: 0.6364\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5926 - accuracy: 0.6364\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5925 - accuracy: 0.6364\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.6364\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5923 - accuracy: 0.6364\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5923 - accuracy: 0.6364\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5922 - accuracy: 0.6364\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5921 - accuracy: 0.6364\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5920 - accuracy: 0.6364\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5920 - accuracy: 0.6364\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5919 - accuracy: 0.6364\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5918 - accuracy: 0.6364\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5918 - accuracy: 0.6364\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5917 - accuracy: 0.6364\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.6364\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5915 - accuracy: 0.6364\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5915 - accuracy: 0.6364\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5914 - accuracy: 0.6364\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.6364\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5912 - accuracy: 0.6364\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5912 - accuracy: 0.6364\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5911 - accuracy: 0.6364\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5910 - accuracy: 0.6364\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5910 - accuracy: 0.6364\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5909 - accuracy: 0.6364\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5908 - accuracy: 0.6364\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5907 - accuracy: 0.6364\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5907 - accuracy: 0.6364\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5906 - accuracy: 0.6364\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5905 - accuracy: 0.6364\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5904 - accuracy: 0.6364\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5904 - accuracy: 0.6364\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5903 - accuracy: 0.6364\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5902 - accuracy: 0.6364\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5902 - accuracy: 0.6364\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5901 - accuracy: 0.6364\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5900 - accuracy: 0.6364\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5899 - accuracy: 0.6364\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5899 - accuracy: 0.6364\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5898 - accuracy: 0.6364\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5897 - accuracy: 0.6364\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5897 - accuracy: 0.6364\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5896 - accuracy: 0.6364\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5895 - accuracy: 0.6364\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5894 - accuracy: 0.6364\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5894 - accuracy: 0.6364\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5893 - accuracy: 0.6364\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5892 - accuracy: 0.6364\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5892 - accuracy: 0.6364\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5891 - accuracy: 0.6364\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5890 - accuracy: 0.6364\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5890 - accuracy: 0.6364\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5889 - accuracy: 0.6364\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5888 - accuracy: 0.6364\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5887 - accuracy: 0.6364\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5887 - accuracy: 0.6364\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5886 - accuracy: 0.6364\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5885 - accuracy: 0.6364\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5885 - accuracy: 0.6364\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.6364\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5883 - accuracy: 0.6364\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5883 - accuracy: 0.6364\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5882 - accuracy: 0.6364\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5881 - accuracy: 0.6364\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5880 - accuracy: 0.6364\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5880 - accuracy: 0.6364\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5879 - accuracy: 0.6364\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5878 - accuracy: 0.6364\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5878 - accuracy: 0.6364\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5877 - accuracy: 0.6364\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5876 - accuracy: 0.6364\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5876 - accuracy: 0.6364\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5875 - accuracy: 0.6364\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5874 - accuracy: 0.6364\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5873 - accuracy: 0.6364\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5873 - accuracy: 0.6364\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5872 - accuracy: 0.6364\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5871 - accuracy: 0.6364\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5871 - accuracy: 0.6364\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5870 - accuracy: 0.6364\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5869 - accuracy: 0.6364\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5869 - accuracy: 0.6364\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5868 - accuracy: 0.6364\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.6364\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5867 - accuracy: 0.6364\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5866 - accuracy: 0.6364\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5865 - accuracy: 0.6364\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5865 - accuracy: 0.6364\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5864 - accuracy: 0.6364\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5863 - accuracy: 0.6364\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5862 - accuracy: 0.6364\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5862 - accuracy: 0.6364\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5861 - accuracy: 0.6364\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5860 - accuracy: 0.6364\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5860 - accuracy: 0.6364\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5859 - accuracy: 0.6364\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5858 - accuracy: 0.6364\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5858 - accuracy: 0.6364\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5857 - accuracy: 0.6364\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5856 - accuracy: 0.6364\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.6364\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5855 - accuracy: 0.6364\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5854 - accuracy: 0.6364\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5854 - accuracy: 0.6364\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 0.6364\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5852 - accuracy: 0.6364\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5852 - accuracy: 0.6364\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5851 - accuracy: 0.6364\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5850 - accuracy: 0.6364\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.6364\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5849 - accuracy: 0.6364\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5848 - accuracy: 0.6364\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5848 - accuracy: 0.6364\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.6364\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5846 - accuracy: 0.6364\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5846 - accuracy: 0.6364\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5845 - accuracy: 0.6364\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5844 - accuracy: 0.6364\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5844 - accuracy: 0.6364\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5843 - accuracy: 0.6364\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5842 - accuracy: 0.6364\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5842 - accuracy: 0.6364\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5841 - accuracy: 0.6364\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5840 - accuracy: 0.6364\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5840 - accuracy: 0.6364\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5839 - accuracy: 0.6364\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5838 - accuracy: 0.6364\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5838 - accuracy: 0.6364\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5837 - accuracy: 0.6364\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.6364\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.6364\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.6364\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.6364\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.6364\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5833 - accuracy: 0.6364\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5832 - accuracy: 0.6364\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5832 - accuracy: 0.6364\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5831 - accuracy: 0.6364\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5830 - accuracy: 0.6364\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5830 - accuracy: 0.6364\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5829 - accuracy: 0.6364\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5828 - accuracy: 0.6364\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5828 - accuracy: 0.6364\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5827 - accuracy: 0.6364\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5826 - accuracy: 0.6364\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5826 - accuracy: 0.6364\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5825 - accuracy: 0.6364\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5824 - accuracy: 0.6364\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5824 - accuracy: 0.6364\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5823 - accuracy: 0.6364\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5822 - accuracy: 0.6364\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5822 - accuracy: 0.6364\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5821 - accuracy: 0.6364\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5820 - accuracy: 0.6364\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5820 - accuracy: 0.6364\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5819 - accuracy: 0.6364\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5818 - accuracy: 0.6364\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5818 - accuracy: 0.6364\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5817 - accuracy: 0.6364\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5816 - accuracy: 0.6364\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5816 - accuracy: 0.6364\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5815 - accuracy: 0.6364\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5815 - accuracy: 0.6364\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5814 - accuracy: 0.6364\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5813 - accuracy: 0.6364\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5813 - accuracy: 0.6364\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5812 - accuracy: 0.6364\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5811 - accuracy: 0.6364\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5811 - accuracy: 0.6364\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5810 - accuracy: 0.6364\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5809 - accuracy: 0.6364\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5809 - accuracy: 0.6364\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5808 - accuracy: 0.6364\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5807 - accuracy: 0.6364\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5807 - accuracy: 0.6364\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5806 - accuracy: 0.6364\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5805 - accuracy: 0.6364\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5805 - accuracy: 0.6364\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5804 - accuracy: 0.6364\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5804 - accuracy: 0.6364\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5803 - accuracy: 0.6364\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5802 - accuracy: 0.6364\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5802 - accuracy: 0.6364\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5801 - accuracy: 0.6364\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5800 - accuracy: 0.6364\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5800 - accuracy: 0.6364\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5799 - accuracy: 0.6364\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5798 - accuracy: 0.6364\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5798 - accuracy: 0.6364\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5797 - accuracy: 0.6364\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5797 - accuracy: 0.6364\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5796 - accuracy: 0.6364\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5795 - accuracy: 0.6364\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5795 - accuracy: 0.6364\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5794 - accuracy: 0.6364\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5793 - accuracy: 0.6364\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5793 - accuracy: 0.6364\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5792 - accuracy: 0.6364\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5791 - accuracy: 0.6364\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5791 - accuracy: 0.6364\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5790 - accuracy: 0.6364\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5790 - accuracy: 0.6364\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5789 - accuracy: 0.6364\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5788 - accuracy: 0.6364\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5788 - accuracy: 0.6364\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5787 - accuracy: 0.6364\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.6364\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5786 - accuracy: 0.6364\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5785 - accuracy: 0.6364\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5784 - accuracy: 0.6364\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5784 - accuracy: 0.6364\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5783 - accuracy: 0.6364\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5783 - accuracy: 0.6364\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5782 - accuracy: 0.6364\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5781 - accuracy: 0.6364\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5781 - accuracy: 0.6364\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5780 - accuracy: 0.6364\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5779 - accuracy: 0.6364\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5779 - accuracy: 0.6364\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5778 - accuracy: 0.6364\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5778 - accuracy: 0.6364\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5777 - accuracy: 0.6364\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5776 - accuracy: 0.6364\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5776 - accuracy: 0.6364\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5775 - accuracy: 0.6364\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5774 - accuracy: 0.6364\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5774 - accuracy: 0.6364\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5773 - accuracy: 0.6364\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5773 - accuracy: 0.6364\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5772 - accuracy: 0.6364\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5771 - accuracy: 0.6364\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5771 - accuracy: 0.6364\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5770 - accuracy: 0.6364\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5769 - accuracy: 0.6364\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5769 - accuracy: 0.6364\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5768 - accuracy: 0.6364\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5768 - accuracy: 0.6364\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5767 - accuracy: 0.6364\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5766 - accuracy: 0.6364\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5766 - accuracy: 0.6364\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5765 - accuracy: 0.6364\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5764 - accuracy: 0.6364\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5764 - accuracy: 0.6364\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5763 - accuracy: 0.6364\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.6364\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5762 - accuracy: 0.6364\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5761 - accuracy: 0.6364\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5761 - accuracy: 0.6364\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5760 - accuracy: 0.6364\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5759 - accuracy: 0.6364\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5759 - accuracy: 0.6364\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5758 - accuracy: 0.6364\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5758 - accuracy: 0.6364\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5757 - accuracy: 0.6364\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.6364\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5756 - accuracy: 0.6364\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5755 - accuracy: 0.6364\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5755 - accuracy: 0.6364\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5754 - accuracy: 0.6364\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5753 - accuracy: 0.6364\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5753 - accuracy: 0.6364\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5752 - accuracy: 0.6364\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5751 - accuracy: 0.6364\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5751 - accuracy: 0.6364\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5750 - accuracy: 0.6364\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5750 - accuracy: 0.6364\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5749 - accuracy: 0.6364\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5748 - accuracy: 0.6364\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5748 - accuracy: 0.6364\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5747 - accuracy: 0.6364\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5747 - accuracy: 0.6364\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5746 - accuracy: 0.6364\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5745 - accuracy: 0.6364\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5745 - accuracy: 0.6364\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5744 - accuracy: 0.6364\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5743 - accuracy: 0.6364\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5743 - accuracy: 0.6364\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5742 - accuracy: 0.6364\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5742 - accuracy: 0.6364\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5741 - accuracy: 0.6364\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5740 - accuracy: 0.6364\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5740 - accuracy: 0.6364\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5739 - accuracy: 0.6364\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5739 - accuracy: 0.6364\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5738 - accuracy: 0.6364\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5737 - accuracy: 0.6364\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5737 - accuracy: 0.6364\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.6364\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.6364\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.6364\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5734 - accuracy: 0.6364\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5734 - accuracy: 0.6364\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5733 - accuracy: 0.6364\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5733 - accuracy: 0.6364\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5732 - accuracy: 0.6364\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5731 - accuracy: 0.6364\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5731 - accuracy: 0.6364\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5730 - accuracy: 0.6364\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5730 - accuracy: 0.6364\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5729 - accuracy: 0.6364\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.6364\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.6364\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5727 - accuracy: 0.6364\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5727 - accuracy: 0.6364\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5726 - accuracy: 0.6364\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5725 - accuracy: 0.6364\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5725 - accuracy: 0.6364\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5724 - accuracy: 0.6364\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5723 - accuracy: 0.6364\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5723 - accuracy: 0.6364\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5722 - accuracy: 0.6364\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5722 - accuracy: 0.6364\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5721 - accuracy: 0.6364\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5720 - accuracy: 0.6364\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5720 - accuracy: 0.6364\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5719 - accuracy: 0.6364\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5719 - accuracy: 0.6364\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5718 - accuracy: 0.6364\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5717 - accuracy: 0.6364\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5717 - accuracy: 0.6364\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5716 - accuracy: 0.6364\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5716 - accuracy: 0.6364\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5715 - accuracy: 0.6364\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5714 - accuracy: 0.6364\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5714 - accuracy: 0.6364\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5713 - accuracy: 0.6364\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5713 - accuracy: 0.6364\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5712 - accuracy: 0.6364\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5712 - accuracy: 0.6364\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5711 - accuracy: 0.6364\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5710 - accuracy: 0.6364\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5710 - accuracy: 0.6364\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 0.6364\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5709 - accuracy: 0.6364\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5708 - accuracy: 0.6364\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5707 - accuracy: 0.6364\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5707 - accuracy: 0.6364\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5706 - accuracy: 0.6364\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5706 - accuracy: 0.6364\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5705 - accuracy: 0.6364\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5704 - accuracy: 0.6364\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5704 - accuracy: 0.6364\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5703 - accuracy: 0.6364\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5703 - accuracy: 0.6364\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5702 - accuracy: 0.6364\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5701 - accuracy: 0.6364\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5701 - accuracy: 0.6364\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5700 - accuracy: 0.6364\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5700 - accuracy: 0.6364\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5699 - accuracy: 0.6364\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5698 - accuracy: 0.6364\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5698 - accuracy: 0.6364\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5697 - accuracy: 0.6364\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5697 - accuracy: 0.6364\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5696 - accuracy: 0.6364\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5695 - accuracy: 0.6364\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5695 - accuracy: 0.6364\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5694 - accuracy: 0.6364\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5694 - accuracy: 0.6364\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5693 - accuracy: 0.6364\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5693 - accuracy: 0.6364\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5692 - accuracy: 0.6364\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.6364\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.6364\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5690 - accuracy: 0.6364\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5690 - accuracy: 0.6364\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5689 - accuracy: 0.6364\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5688 - accuracy: 0.6364\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5688 - accuracy: 0.6364\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5687 - accuracy: 0.6364\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5687 - accuracy: 0.6364\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5686 - accuracy: 0.6364\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5685 - accuracy: 0.6364\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5685 - accuracy: 0.6364\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5684 - accuracy: 0.6364\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5684 - accuracy: 0.6364\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5683 - accuracy: 0.6364\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5683 - accuracy: 0.6364\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5682 - accuracy: 0.6364\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5681 - accuracy: 0.6364\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5681 - accuracy: 0.6364\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5680 - accuracy: 0.6364\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5680 - accuracy: 0.6364\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5679 - accuracy: 0.6364\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5678 - accuracy: 0.6364\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5678 - accuracy: 0.6364\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5677 - accuracy: 0.6364\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5677 - accuracy: 0.6364\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5676 - accuracy: 0.6364\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5676 - accuracy: 0.6364\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5675 - accuracy: 0.6364\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5674 - accuracy: 0.6364\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5674 - accuracy: 0.6364\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5673 - accuracy: 0.6364\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5673 - accuracy: 0.6364\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5672 - accuracy: 0.6364\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5671 - accuracy: 0.6364\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5671 - accuracy: 0.6364\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5670 - accuracy: 0.6364\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5670 - accuracy: 0.6364\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5669 - accuracy: 0.6364\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5669 - accuracy: 0.6364\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5668 - accuracy: 0.6364\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5667 - accuracy: 0.6364\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5667 - accuracy: 0.6364\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5666 - accuracy: 0.6364\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5666 - accuracy: 0.6364\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5665 - accuracy: 0.6364\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5665 - accuracy: 0.6364\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.6364\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5663 - accuracy: 0.6364\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5663 - accuracy: 0.6364\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5662 - accuracy: 0.6364\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5662 - accuracy: 0.6364\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5661 - accuracy: 0.6364\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5660 - accuracy: 0.6364\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5660 - accuracy: 0.6364\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5659 - accuracy: 0.6364\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5659 - accuracy: 0.6364\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5658 - accuracy: 0.6364\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5658 - accuracy: 0.6364\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5657 - accuracy: 0.6364\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5656 - accuracy: 0.6364\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5656 - accuracy: 0.6364\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5655 - accuracy: 0.6364\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5655 - accuracy: 0.6364\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.6364\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5654 - accuracy: 0.6364\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5653 - accuracy: 0.6364\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5652 - accuracy: 0.6364\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5652 - accuracy: 0.6364\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5651 - accuracy: 0.6364\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5651 - accuracy: 0.6364\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5650 - accuracy: 0.6364\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5650 - accuracy: 0.6364\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5649 - accuracy: 0.6364\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5648 - accuracy: 0.6364\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5648 - accuracy: 0.6364\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5647 - accuracy: 0.6364\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5647 - accuracy: 0.6364\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5646 - accuracy: 0.6364\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5646 - accuracy: 0.6364\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5645 - accuracy: 0.6364\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5644 - accuracy: 0.6364\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5644 - accuracy: 0.6364\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5643 - accuracy: 0.6364\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5643 - accuracy: 0.6364\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5642 - accuracy: 0.6364\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5642 - accuracy: 0.6364\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5641 - accuracy: 0.6364\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.6364\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5640 - accuracy: 0.6364\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5639 - accuracy: 0.6364\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5639 - accuracy: 0.6364\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5638 - accuracy: 0.6364\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5638 - accuracy: 0.6364\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5637 - accuracy: 0.6364\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5636 - accuracy: 0.6364\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5636 - accuracy: 0.6364\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5635 - accuracy: 0.6364\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5635 - accuracy: 0.6364\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5634 - accuracy: 0.6364\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5634 - accuracy: 0.6364\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5633 - accuracy: 0.6364\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5632 - accuracy: 0.6364\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5632 - accuracy: 0.6364\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5631 - accuracy: 0.6364\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5631 - accuracy: 0.6364\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5630 - accuracy: 0.6364\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.6364\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5629 - accuracy: 0.6364\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5628 - accuracy: 0.6364\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5628 - accuracy: 0.6364\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5627 - accuracy: 0.6364\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5627 - accuracy: 0.6364\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5626 - accuracy: 0.6364\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5626 - accuracy: 0.6364\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5625 - accuracy: 0.6364\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5624 - accuracy: 0.6364\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5624 - accuracy: 0.6364\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.6364\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.6364\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5622 - accuracy: 0.6364\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5622 - accuracy: 0.6364\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5621 - accuracy: 0.6364\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5621 - accuracy: 0.6364\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5620 - accuracy: 0.6364\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5619 - accuracy: 0.6364\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5619 - accuracy: 0.6364\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5618 - accuracy: 0.6364\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5618 - accuracy: 0.6364\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5617 - accuracy: 0.6364\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5617 - accuracy: 0.6364\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5616 - accuracy: 0.6364\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5615 - accuracy: 0.6364\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5615 - accuracy: 0.6364\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5614 - accuracy: 0.6364\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5614 - accuracy: 0.6364\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5613 - accuracy: 0.6364\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5613 - accuracy: 0.6364\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5612 - accuracy: 0.6364\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5611 - accuracy: 0.6364\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5611 - accuracy: 0.6364\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5610 - accuracy: 0.6364\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5610 - accuracy: 0.6364\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5609 - accuracy: 0.6364\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5609 - accuracy: 0.6364\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.6364\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5608 - accuracy: 0.6364\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5607 - accuracy: 0.6364\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5606 - accuracy: 0.6364\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5606 - accuracy: 0.6364\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5605 - accuracy: 0.6364\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5605 - accuracy: 0.6364\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5604 - accuracy: 0.6364\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5604 - accuracy: 0.6364\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5603 - accuracy: 0.6364\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5603 - accuracy: 0.6364\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5602 - accuracy: 0.6364\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.6364\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5601 - accuracy: 0.6364\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5600 - accuracy: 0.6364\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5600 - accuracy: 0.6364\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5599 - accuracy: 0.6364\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5599 - accuracy: 0.6364\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5598 - accuracy: 0.6364\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5597 - accuracy: 0.6364\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5597 - accuracy: 0.6364\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.6364\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.6364\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5595 - accuracy: 0.6364\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5595 - accuracy: 0.6364\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5594 - accuracy: 0.6364\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5594 - accuracy: 0.6364\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5593 - accuracy: 0.6364\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5592 - accuracy: 0.6364\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5592 - accuracy: 0.6364\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5591 - accuracy: 0.6364\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5591 - accuracy: 0.6364\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5590 - accuracy: 0.6364\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5590 - accuracy: 0.6364\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5589 - accuracy: 0.6364\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.6364\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5588 - accuracy: 0.6364\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5587 - accuracy: 0.6364\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5587 - accuracy: 0.6364\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.6364\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5586 - accuracy: 0.6364\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5585 - accuracy: 0.6364\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5585 - accuracy: 0.6364\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5584 - accuracy: 0.6364\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5584 - accuracy: 0.6364\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5583 - accuracy: 0.6364\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5582 - accuracy: 0.6364\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5582 - accuracy: 0.6364\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5581 - accuracy: 0.6364\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5581 - accuracy: 0.6364\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5580 - accuracy: 0.6364\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5580 - accuracy: 0.6364\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5579 - accuracy: 0.6364\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5579 - accuracy: 0.6364\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5578 - accuracy: 0.6364\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5578 - accuracy: 0.6364\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5577 - accuracy: 0.6364\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5576 - accuracy: 0.6364\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5576 - accuracy: 0.6364\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5575 - accuracy: 0.6364\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5575 - accuracy: 0.6364\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5574 - accuracy: 0.6364\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5574 - accuracy: 0.6364\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5573 - accuracy: 0.6364\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.6364\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5572 - accuracy: 0.6364\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5571 - accuracy: 0.6364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x782978c83df0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test_scaled,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcDmCES3P5om",
        "outputId": "118cd83b-fa65-4008-c215-7c46e3502d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step - loss: 0.7027 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7027472853660583, 0.6666666865348816]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7HIRnQmQHFj",
        "outputId": "3e3b68f7-d5e5-496d-b462-0b92efe9f278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46081197],\n",
              "       [0.69935626],\n",
              "       [0.44169077],\n",
              "       [0.5753304 ],\n",
              "       [0.69935626],\n",
              "       [0.45123342]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Wv9t5wQQFA",
        "outputId": "5ffbb8d7-32d4-4a53-d283-4faa5f72a159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13    0\n",
              "4     1\n",
              "1     0\n",
              "10    0\n",
              "27    0\n",
              "12    0\n",
              "Name: bought_insurance, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias=model2.get_weights()\n",
        "weight,bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQUC79_oQWwP",
        "outputId": "48ee2f5d-636b-45dd-a478-cce77774c4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.9307189 ],\n",
              "        [0.67308617]], dtype=float32),\n",
              " array([-0.71698266], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_numpy(x):\n",
        "  return 1/(1+np.exp(-x))\n"
      ],
      "metadata": {
        "id": "S6bx-l7cuqp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([1,2,3,4])\n",
        "sigmoid_numpy(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWIPHSUbuxRO",
        "outputId": "adf3ef80-4a62-4d90-a5af-02f983e5dd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.88079708, 0.95257413, 0.98201379])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true,y_pred):\n",
        "  e=1e-10\n",
        "  y_pred_new=[max(i,e)for i in y_pred]\n",
        "  y_pred_new=[min(i,1-e) for i in y_pred_new]\n",
        "  y_pred_new=np.array(y_pred_new)\n",
        "\n",
        "  return -np.mean(y_true*np.log(y_pred_new)+(1-y_true)*np.log(1-y_pred_new))"
      ],
      "metadata": {
        "id": "mgRSpUaqRKqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([1,2,3,4])\n",
        "sigmoid_numpy(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM34j13XSKvD",
        "outputId": "90c7b1c6-cf99-4578-ef17-0144eb2fc37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.88079708, 0.95257413, 0.98201379])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(age,aff,y_t,epochs,loss_thr):\n",
        "  w1=1\n",
        "  w2=1\n",
        "  b=0\n",
        "  n=len(age)\n",
        "  lear_rate=0.5\n",
        "\n",
        "  for i in range(epochs):\n",
        "    weighted_sum=w1*age+w2*aff+b\n",
        "    y_p=sigmoid_numpy(weighted_sum)\n",
        "    loss=log_loss(y_t,y_p)\n",
        "\n",
        "    w1_d = (1/n)*np.dot((age),np.transpose(y_p-y_t))\n",
        "    w2_d = (1/n)*np.dot((aff),(y_p-y_t))\n",
        "\n",
        "    b_d = np.mean(y_p-y_t)\n",
        "\n",
        "    w1=w1-lear_rate*w1_d\n",
        "    w2 = w2 -lear_rate * w2_d\n",
        "    b=b- b-lear_rate* b_d\n",
        "\n",
        "    print ('Epoch:',{i}, 'w1:',{w1}, 'w2:',{w2}, 'b:',{b}, 'loss:',{loss})\n",
        "    if loss<loss_thr:\n",
        "            break\n",
        "\n",
        "  return w1, w2, b\n",
        "\n"
      ],
      "metadata": {
        "id": "KMktRhAESeBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X_train_scaled['age'],X_train_scaled['affordibility'],y_train,100, 0.55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrYCeSIPvHZC",
        "outputId": "4950027c-cd6a-4e86-a4f4-daec9aaf0bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: {0} w1: {0.9899044631276738} w2: {0.9569405919425348} b: {-0.07899372792977674} loss: {0.645879853336323}\n",
            "Epoch: {1} w1: {0.9839956437241003} w2: {0.9213120476683795} b: {-0.0688390953074361} loss: {0.6306399722613678}\n",
            "Epoch: {2} w1: {0.9787178553939094} w2: {0.8874026149929113} b: {-0.06737928527992336} loss: {0.6294794564509504}\n",
            "Epoch: {3} w1: {0.974367907425216} w2: {0.8556628910507127} b: {-0.06518966676249639} loss: {0.6273958016852729}\n",
            "Epoch: {4} w1: {0.9708591802332485} w2: {0.825922920160302} b: {-0.0632060896639361} loss: {0.6256912276053487}\n",
            "Epoch: {5} w1: {0.9681442497574754} w2: {0.7980764627879908} b: {-0.06133280445345248} loss: {0.6242036606799187}\n",
            "Epoch: {6} w1: {0.9661727240114698} w2: {0.7720126668456061} b: {-0.059576974303892104} loss: {0.6229161122023454}\n",
            "Epoch: {7} w1: {0.9648959255052931} w2: {0.7476239745542741} b: {-0.057934416123035515} loss: {0.6218009644418351}\n",
            "Epoch: {8} w1: {0.9642667072247068} w2: {0.7248060153983343} b: {-0.05640145004053357} loss: {0.620834954377282}\n",
            "Epoch: {9} w1: {0.9642397042315037} w2: {0.7034581747310749} b: {-0.054973830153539203} loss: {0.6199974464577408}\n",
            "Epoch: {10} w1: {0.9647714788080795} w2: {0.6834839502210979} b: {-0.05364699545021589} loss: {0.6192703483908892}\n",
            "Epoch: {11} w1: {0.9658206233966699} w2: {0.6647912068708792} b: {-0.052416164978782875} loss: {0.6186378587267434}\n",
            "Epoch: {12} w1: {0.9673478219166367} w2: {0.6472923359223577} b: {-0.051276432269189626} loss: {0.6180862361821071}\n",
            "Epoch: {13} w1: {0.9693158764296079} w2: {0.630904333324423} b: {-0.050222843540261936} loss: {0.6176035771299877}\n",
            "Epoch: {14} w1: {0.9716897049312927} w2: {0.6155488111313043} b: {-0.049250462603489004} loss: {0.6171796065728938}\n",
            "Epoch: {15} w1: {0.9744363155763514} w2: {0.6011519540498308} b: {-0.048354423596885805} loss: {0.6168054844931046}\n",
            "Epoch: {16} w1: {0.9775247620519505} w2: {0.5876444319893038} b: {-0.04752997294760264} loss: {0.6164736286612694}\n",
            "Epoch: {17} w1: {0.980926084233738} w2: {0.5749612781223555} b: {-0.04677250192620414} loss: {0.6161775541785028}\n",
            "Epoch: {18} w1: {0.9846132376969658} w2: {0.5630417406718494} b: {-0.04607757109670721} loss: {0.6159117294561111}\n",
            "Epoch: {19} w1: {0.9885610151309816} w2: {0.551829115431996} b: {-0.04544092787434492} loss: {0.6156714479355939}\n",
            "Epoch: {20} w1: {0.9927459622256429} w2: {0.5412705649299059} b: {-0.044858518294019524} loss: {0.615452714587992}\n",
            "Epoch: {21} w1: {0.997146290167383} w2: {0.5313169291453437} b: {-0.04432649397603437} loss: {0.6152521460752376}\n",
            "Epoch: {22} w1: {1.0017417865014417} w2: {0.521922531832768} b: {-0.043841215158945054} loss: {0.6150668833809986}\n",
            "Epoch: {23} w1: {1.0065137257837713} w2: {0.5130449857272137} b: {-0.04339925055694893} loss: {0.6148945157030843}\n",
            "Epoch: {24} w1: {1.0114447811584975} w2: {0.5046449992574139} b: {-0.04299737469409518} loss: {0.6147330144264861}\n",
            "Epoch: {25} w1: {1.0165189377509305} w2: {0.496686186827181} b: {-0.04263256327143295} loss: {0.6145806760518296}\n",
            "Epoch: {26} w1: {1.0217214085578978} w2: {0.4891348842500063} b: {-0.04230198703677068} loss: {0.614436073027858}\n",
            "Epoch: {27} w1: {1.027038553342472} w2: {0.48195997052245704} b: {-0.042003004550107186} loss: {0.6142980115205522}\n",
            "Epoch: {28} w1: {1.0324578008949177} w2: {0.4751326967898651} b: {-0.04173315417069141} loss: {0.6141654952397482}\n",
            "Epoch: {29} w1: {1.037967574902034} w2: {0.4686265230841632} b: {-0.04149014553348792} loss: {0.6140376945324374}\n",
            "Epoch: {30} w1: {1.0435572235694892} w2: {0.462416963190412} b: {-0.04127185073282476} loss: {0.6139139200374335}\n",
            "Epoch: {31} w1: {1.049216953063015} w2: {0.45648143781821415} b: {-0.04107629538837558} loss: {0.6137936002768902}\n",
            "Epoch: {32} w1: {1.0549377647715956} w2: {0.4507991361102948} b: {-0.040901649732554675} loss: {0.6136762626351117}\n",
            "Epoch: {33} w1: {1.0607113963465127} w2: {0.44535088540727363} b: {-0.04074621982808956} loss: {0.6135615172436454}\n",
            "Epoch: {34} w1: {1.0665302664321124} w2: {0.4401190291000449} b: {-0.04060843899923277} loss: {0.6134490433536194}\n",
            "Epoch: {35} w1: {1.0723874229755073} w2: {0.4350873123348749} b: {-0.0404868595390988} loss: {0.6133385778317479}\n",
            "Epoch: {36} w1: {1.0782764949815102} w2: {0.4302407752875931} b: {-0.040380144738344365} loss: {0.6132299054657219}\n",
            "Epoch: {37} w1: {1.0841916475644908} w2: {0.42556565368892} b: {-0.04028706126630167} loss: {0.6131228508081555}\n",
            "Epoch: {38} w1: {1.0901275401393826} w2: {0.4210492862603427} b: {-0.04020647192423949} loss: {0.6130172713264076}\n",
            "Epoch: {39} w1: {1.0960792875887422} w2: {0.4166800287067486} b: {-0.04013732878124492} loss: {0.6129130516588596}\n",
            "Epoch: {40} w1: {1.102042424240726} w2: {0.41244717390635416} b: {-0.04007866669592311} loss: {0.6128100988071694}\n",
            "Epoch: {41} w1: {1.108012870493417} w2: {0.40834087793872464} b: {-0.04002959722138903} loss: {0.6127083381190443}\n",
            "Epoch: {42} w1: {1.1139869019235038} w2: {0.404352091596554} b: {-0.03998930288660619} loss: {0.612607709937684}\n",
            "Epoch: {43} w1: {1.1199611207214324} w2: {0.4004724970352708} b: {-0.03995703184378261} loss: {0.6125081668126289}\n",
            "Epoch: {44} w1: {1.1259324293003798} w2: {0.3966944492255582} b: {-0.039932092869071976} loss: {0.6124096711826859}\n",
            "Epoch: {45} w1: {1.1318980059324733} w2: {0.3930109218867905} b: {-0.039913850702083246} loss: {0.6123121934552571}\n",
            "Epoch: {46} w1: {1.1378552822722736} w2: {0.3894154575936052} b: {-0.039901721708539714} loss: {0.6122157104180476}\n",
            "Epoch: {47} w1: {1.1438019226345055} w2: {0.3859021217628635} b: {-0.03989516984973183} loss: {0.6121202039290613}\n",
            "Epoch: {48} w1: {1.1497358049001332} w2: {0.38246546024372724} b: {-0.03989370294208456} loss: {0.6120256598392527}\n",
            "Epoch: {49} w1: {1.1556550029320491} w2: {0.3791004602491897} b: {-0.0398968691901277} loss: {0.6119320671093773}\n",
            "Epoch: {50} w1: {1.16155777038875} w2: {0.37580251438290746} b: {-0.03990425397635247} loss: {0.6118394170886795}\n",
            "Epoch: {51} w1: {1.1674425258313255} w2: {0.37256738753040974} b: {-0.039915476891806675} loss: {0.6117477029282136}\n",
            "Epoch: {52} w1: {1.1733078390258553} w2: {0.3693911863985699} b: {-0.03993018899177809} loss: {0.611656919105958}\n",
            "Epoch: {53} w1: {1.1791524183498183} w2: {0.3662703315015165} b: {-0.039948070261506666} loss: {0.6115670610445721}\n",
            "Epoch: {54} w1: {1.1849750992173549} w2: {0.363201531404862} b: {-0.03996882727752247} loss: {0.6114781248057597}\n",
            "Epoch: {55} w1: {1.1907748334441726} w2: {0.36018175905319205} b: {-0.03999219105090241} loss: {0.6113901068478141}\n",
            "Epoch: {56} w1: {1.196550679478519} w2: {0.35720823001816004} b: {-0.040017915039458556} loss: {0.611303003835152}\n",
            "Epoch: {57} w1: {1.2023017934299698} w2: {0.3542783825162539} b: {-0.04004577331659876} loss: {0.6112168124904745}\n",
            "Epoch: {58} w1: {1.2080274208327964} w2: {0.3513898590563492} b: {-0.04007555888532308} loss: {0.6111315294817792}\n",
            "Epoch: {59} w1: {1.2137268890853865} w2: {0.3485404895875378} b: {-0.04010708212653213} loss: {0.611047151337739}\n",
            "Epoch: {60} w1: {1.2193996005115955} w2: {0.34572827602744377} b: {-0.04014016937151565} loss: {0.6109636743860795}\n",
            "Epoch: {61} w1: {1.2250450259940293} w2: {0.3429513780603265} b: {-0.04017466158915855} loss: {0.6108810947104903}\n",
            "Epoch: {62} w1: {1.2306626991331024} w2: {0.34020810010274904} b: {-0.04021041317904313} loss: {0.6107994081223945}\n",
            "Epoch: {63} w1: {1.2362522108892842} w2: {0.3374968793424863} b: {-0.04024729086223864} loss: {0.6107186101445268}\n",
            "Epoch: {64} w1: {1.241813204669278} w2: {0.3348162747636888} b: {-0.04028517266214977} loss: {0.6106386960038239}\n",
            "Epoch: {65} w1: {1.2473453718199594} w2: {0.33216495707813454} b: {-0.040323946968345785} loss: {0.6105596606315675}\n",
            "Epoch: {66} w1: {1.2528484474967574} w2: {0.329541699488722} b: {-0.040363511676809655} loss: {0.6104814986691018}\n",
            "Epoch: {67} w1: {1.2583222068758158} w2: {0.3269453692172135} b: {-0.0404037734005327} loss: {0.6104042044777519}\n",
            "Epoch: {68} w1: {1.2637664616817177} w2: {0.32437491973365495} b: {-0.04044464674483705} loss: {0.6103277721518324}\n",
            "Epoch: {69} w1: {1.2691810570048216} w2: {0.32182938362990643} b: {-0.04048605364223323} loss: {0.610252195533846}\n",
            "Epoch: {70} w1: {1.2745658683843482} w2: {0.31930786608434597} b: {-0.040527922742019044} loss: {0.6101774682311475}\n",
            "Epoch: {71} w1: {1.2799207991352872} w2: {0.31680953886907887} b: {-0.04057018885019539} loss: {0.6101035836335007}\n",
            "Epoch: {72} w1: {1.285245777898973} w2: {0.31433363485492316} b: {-0.040612792415619645} loss: {0.6100305349310694}\n",
            "Epoch: {73} w1: {1.2905407563988145} w2: {0.3118794429730753} b: {-0.04065567905863654} loss: {0.6099583151324836}\n",
            "Epoch: {74} w1: {1.2958057073841807} w2: {0.30944630359570446} b: {-0.04069879913872327} loss: {0.6098869170827074}\n",
            "Epoch: {75} w1: {1.3010406227468296} w2: {0.3070336043008058} b: {-0.040742107357960015} loss: {0.6098163334804968}\n",
            "Epoch: {76} w1: {1.30624551179555} w2: {0.30464077598947886} b: {-0.040785562397391624} loss: {0.6097465568952913}\n",
            "Epoch: {77} w1: {1.311420399675864} w2: {0.302267289326408} b: {-0.04082912658358038} loss: {0.6096775797834239}\n",
            "Epoch: {78} w1: {1.3165653259227172} w2: {0.2999126514767203} b: {-0.040872765582867746} loss: {0.6096093945035748}\n",
            "Epoch: {79} w1: {1.3216803431350836} w2: {0.2975764031146049} b: {-0.04091644812106285} loss: {0.6095419933314172}\n",
            "Epoch: {80} w1: {1.326765515762323} w2: {0.2952581156811055} b: {-0.04096014572645972} loss: {0.6094753684734268}\n",
            "Epoch: {81} w1: {1.3318209189929704} w2: {0.2929573888703615} b: {-0.04100383249425706} loss: {0.6094095120798464}\n",
            "Epoch: {82} w1: {1.3368466377374093} w2: {0.2906738483252875} b: {-0.04104748487060965} loss: {0.6093444162568086}\n",
            "Epoch: {83} w1: {1.3418427656965883} w2: {0.28840714352525065} b: {-0.04109108145468635} loss: {0.6092800730776303}\n",
            "Epoch: {84} w1: {1.3468094045095922} w2: {0.2861569458497531} b: {-0.041134602817241656} loss: {0.6092164745933025}\n",
            "Epoch: {85} w1: {1.3517466629734745} w2: {0.28392294680344965} b: {-0.041178031334331136} loss: {0.6091536128422013}\n",
            "Epoch: {86} w1: {1.3566546563293085} w2: {0.28170485638905063} b: {-0.04122135103491271} loss: {0.6090914798590527}\n",
            "Epoch: {87} w1: {1.3615335056089157} w2: {0.2795024016157749} b: {-0.04126454746118009} loss: {0.6090300676831881}\n",
            "Epoch: {88} w1: {1.36638333703719} w2: {0.27731532513204427} b: {-0.04130760754056916} loss: {0.6089693683661231}\n",
            "Epoch: {89} w1: {1.371204281485365} w2: {0.2751433839720509} b: {-0.041350519468465886} loss: {0.6089093739784996}\n",
            "Epoch: {90} w1: {1.375996473970953} w2: {0.27298634840669156} b: {-0.04139327260072479} loss: {0.6088500766164275}\n",
            "Epoch: {91} w1: {1.3807600532004447} w2: {0.270844000890155} b: {-0.041435857355180024} loss: {0.6087914684072635}\n",
            "Epoch: {92} w1: {1.3854951611511874} w2: {0.2687161350941742} b: {-0.04147826512139999} loss: {0.6087335415148613}\n",
            "Epoch: {93} w1: {1.3902019426891494} w2: {0.266602555022621} b: {-0.04152048817799739} loss: {0.6086762881443313}\n",
            "Epoch: {94} w1: {1.394880545219565} w2: {0.26450307419973107} b: {-0.041562519616864635} loss: {0.6086197005463403}\n",
            "Epoch: {95} w1: {1.3995311183676975} w2: {0.26241751492580834} b: {-0.0416043532737564} loss: {0.6085637710209865}\n",
            "Epoch: {96} w1: {1.4041538136871932} w2: {0.26034570759476877} b: {-0.04164598366468938} loss: {0.6085084919212771}\n",
            "Epoch: {97} w1: {1.4087487843937057} w2: {0.2582874900683572} b: {-0.04168740592767314} loss: {0.6084538556562397}\n",
            "Epoch: {98} w1: {1.4133161851216707} w2: {0.2562427071023001} b: {-0.04172861576932694} loss: {0.608399854693698}\n",
            "Epoch: {99} w1: {1.4178561717022837} w2: {0.2542112098200537} b: {-0.041769609415973956} loss: {0.6083464815627292}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4178561717022837, 0.2542112098200537, -0.041769609415973956)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgNzDXOKvEto",
        "outputId": "0b42f0db-0518-43f9-e621-62ec9b63ec86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.9307189 ],\n",
              "        [0.67308617]], dtype=float32),\n",
              " array([-0.71698266], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "Wgo6DuaRwQr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss_sto(y_true,y_pred):\n",
        "  e=1e-10\n",
        "  y_pred_new=max(y_pred,e)\n",
        "  y_pred_new=min(y_pred_new,1-e)\n",
        "  y_pred_new=np.array(y_pred_new)\n",
        "\n",
        "  return -(y_true*math.log(y_pred_new)+(1-y_true)*math.log(1-y_pred_new))"
      ],
      "metadata": {
        "id": "2464jafJxzFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SGD**"
      ],
      "metadata": {
        "id": "8dylZ--Pc7lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN:\n",
        "  def __init__(self):\n",
        "    self.w1=1\n",
        "    self.w2=1\n",
        "    self.b=0\n",
        "\n",
        "  def fit(self,X,y,epochs):\n",
        "      self.sto_gradient_descent(X[\"age\"],X[\"affordibility\"],y,epochs)\n",
        "\n",
        "  def sto_gradient_descent(self,age,aff,y_t,Epochs):\n",
        "          w1=1\n",
        "          w2=1\n",
        "          b=0\n",
        "          n=len(age)\n",
        "          learning_rate=0.5\n",
        "\n",
        "          age_new=np.array(age)\n",
        "          aff_new=np.array(aff)\n",
        "          y_t=np.array(y_t)\n",
        "\n",
        "          for i in range(Epochs):\n",
        "            r=random.randint(0,len(age_new)-1)\n",
        "            weighted_sum = w1 * age_new[r] + w2 * aff_new[r] + b\n",
        "            y_p= sigmoid_numpy(weighted_sum)\n",
        "            loss=log_loss_sto(y_t[r],y_p)\n",
        "\n",
        "            w1_d=(age_new[r]*(y_p-y_t[r]))\n",
        "            w2_d=(aff_new[r]*(y_p-y_t[r]))\n",
        "            b_d=(y_p-y_t[r])\n",
        "\n",
        "            w1=1-learning_rate*w1_d\n",
        "            w2=2-learning_rate*w2_d\n",
        "            b=b-learning_rate*b_d\n",
        "\n",
        "\n",
        "\n",
        "            print(\"Epochs:\",i,\"w1:\",w1,\"w2:\",w2,\"b:\",b,\"loss:\",loss)\n",
        "          return w1,w2,b\n",
        "\n",
        "  def predict(self, X):\n",
        "        W_S = self.w1 * X[\"age_new\"] + self.w2 * X[\"affordibility_new\"] + self.b\n",
        "        y_pred = self.sigmoid(W_S)\n",
        "        return y_pred\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "oz2cWSYjWdwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sto_model2=ANN()\n",
        "sto_model2.fit(X_train_scaled,y_train,1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUnRPaG0wFGq",
        "outputId": "d1f72613-5156-4a29-fecb-f8cda32ba249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0 w1: 0.9191186103501068 w2: 1.6148505254766992 b: -0.38514947452330095 loss: 1.4709765939671287\n",
            "Epochs: 1 w1: 1.0389682838137893 w2: 2.0779365676275785 b: -0.30721290689572234 loss: 0.16945248200342533\n",
            "Epochs: 2 w1: 1.0239020252533215 w2: 2.044263009728373 b: -0.26294989716734923 loss: 0.09269223102702416\n",
            "Epochs: 3 w1: 1.0221540756068002 w2: 2.047136331078298 b: -0.21581356608905095 loss: 0.09901696984190328\n",
            "Epochs: 4 w1: 1.0216807367578054 w2: 2.0442464015465416 b: -0.17156716454250948 loss: 0.09265578922051752\n",
            "Epochs: 5 w1: 0.9519644085332518 w2: 2.0 b: -0.424386066999079 loss: 0.7044868420106072\n",
            "Epochs: 6 w1: 1.1390102834809248 w2: 2.0 b: -0.19270226119753764 loss: 0.6224419842640044\n",
            "Epochs: 7 w1: 0.9316411809838185 w2: 2.0 b: -0.4556207958751584 loss: 0.7462042808131208\n",
            "Epochs: 8 w1: 1.0256384983393556 w2: 2.064096245848389 b: -0.3915245500267693 loss: 0.1371866268001325\n",
            "Epochs: 9 w1: 1.0252675198987764 w2: 2.050535039797553 b: -0.3409895102292166 loss: 0.1065502003800371\n",
            "Epochs: 10 w1: 1.0244440967859882 w2: 2.0488881935719765 b: -0.2921013166572402 loss: 0.10289288182091116\n",
            "Epochs: 11 w1: 1.024380794291897 w2: 2.0451496190590683 b: -0.24695169759817165 loss: 0.09463956664555338\n",
            "Epochs: 12 w1: 1.0198077646702004 w2: 2.049519411675501 b: -0.1974322859226707 loss: 0.10429311148196684\n",
            "Epochs: 13 w1: 0.9068042052345863 w2: 1.5562105011170777 b: -0.6412217848055931 loss: 2.1855045063602834\n",
            "Epochs: 14 w1: 1.0507199895648822 w2: 2.1014399791297644 b: -0.5397818056758286 loss: 0.2267499945442233\n",
            "Epochs: 15 w1: 1.0272932157192107 w2: 2.055700440243287 b: -0.48408136543254143 loss: 0.11810907935024847\n",
            "Epochs: 16 w1: 0.90563546500404 w2: 1.5710702954729092 b: -0.9130110699596322 loss: 1.9509386341006947\n",
            "Epochs: 17 w1: 1.0594091688128942 w2: 2.126402486835945 b: -0.7866085831236871 loss: 0.29142904850278756\n",
            "Epochs: 18 w1: 1.0314664758183518 w2: 2.0699255018185596 b: -0.7166830813051276 loss: 0.15064965315616088\n",
            "Epochs: 19 w1: 1.033040504096515 w2: 2.067429600196969 b: -0.6492534811081583 loss: 0.14486301118547218\n",
            "Epochs: 20 w1: 1.1522070291130535 w2: 2.0 b: -0.39557509925306916 loss: 0.7079700255480876\n",
            "Epochs: 21 w1: 0.9003648508446175 w2: 1.5668036993244239 b: -0.8287713999286452 loss: 2.012849640304816\n",
            "Epochs: 22 w1: 1.05439014246181 w2: 2.1208669832484666 b: -0.7079044166801784 loss: 0.27672098723236976\n",
            "Epochs: 23 w1: 0.9077975126691676 w2: 1.5808977848598529 b: -1.1270066318203256 loss: 1.8214216559458078\n",
            "Epochs: 24 w1: 0.9111126296058708 w2: 2.0 b: -1.2979438825782663 loss: 0.41835963866342496\n",
            "Epochs: 25 w1: 1.0512138068548755 w2: 2.1280345171371886 b: -1.1699093654410777 loss: 0.29580703645731343\n",
            "Epochs: 26 w1: 0.9623323725775675 w2: 2.0 b: -1.3147848555273565 loss: 0.34213963828759175\n",
            "Epochs: 27 w1: 0.9218650363203343 w2: 1.644841074183338 b: -1.6699437813440186 loss: 1.2389709972077483\n",
            "Epochs: 28 w1: 1.1088347437082997 w2: 2.187646109841896 b: -1.4822976715021223 loss: 0.47047129007608446\n",
            "Epochs: 29 w1: 1.0581946028765374 w2: 2.1058083688664313 b: -1.3764893026356908 loss: 0.23777093393002627\n",
            "Epochs: 30 w1: 0.9675668979452626 w2: 2.0 b: -1.501232002846219 loss: 0.28699617496132973\n",
            "Epochs: 31 w1: 0.9043165627882401 w2: 1.658273438529429 b: -1.8429585643167898 loss: 1.1502839375947391\n",
            "Epochs: 32 w1: 0.9276026150849086 w2: 1.7414379110175306 b: -2.101520653299259 loss: 0.7279957556206224\n",
            "Epochs: 33 w1: 1.108301787765402 w2: 2.0 b: -1.6683135022376505 loss: 2.013012075430531\n",
            "Epochs: 34 w1: 0.9346769507193424 w2: 2.0 b: -1.7939347508542998 loss: 0.28934010921309705\n",
            "Epochs: 35 w1: 1.0961163350258094 w2: 2.1575677623373926 b: -1.6363669885169072 loss: 0.37853430653462294\n",
            "Epochs: 36 w1: 0.9249950767471247 w2: 1.6590685306687485 b: -1.9772984578481587 loss: 1.1452729785650295\n",
            "Epochs: 37 w1: 1.2417096854985457 w2: 2.0 b: -1.5744489820172496 loss: 1.638346527151736\n",
            "Epochs: 38 w1: 0.9265303945291534 w2: 1.666047247859788 b: -1.9084017341574615 loss: 1.102335724902473\n",
            "Epochs: 39 w1: 1.238360605917563 w2: 2.0 b: -1.5111340576281902 loss: 1.5824812941935935\n",
            "Epochs: 40 w1: 1.068226766071301 w2: 2.111847157493936 b: -1.3992869001342543 loss: 0.2532089123819001\n",
            "Epochs: 41 w1: 0.9207311122485791 w2: 1.6396868738571775 b: -1.7596000262770768 loss: 1.2752047960785604\n",
            "Epochs: 42 w1: 0.9398610238867127 w2: 1.7385261908117942 b: -2.0210738354652826 loss: 0.740128979398488\n",
            "Epochs: 43 w1: 1.131910225709067 w2: 2.2127584285630113 b: -1.8083154069022715 loss: 0.5542845243797325\n",
            "Epochs: 44 w1: 0.9276430474176518 w2: 1.6711047609893264 b: -2.137210645912945 loss: 1.0723320921407091\n",
            "Epochs: 45 w1: 1.1448998780500976 w2: 2.2375407836886847 b: -1.8996698622242603 loss: 0.6445123948942126\n",
            "Epochs: 46 w1: 1.069093005027586 w2: 2.147006393675715 b: -1.7526634685485454 loss: 0.3481581540487196\n",
            "Epochs: 47 w1: 0.9833604342650918 w2: 2.0 b: -1.8402401303112204 loss: 0.1925577566164875\n",
            "Epochs: 48 w1: 0.9347774881874312 w2: 1.7035340372155967 b: -2.136706093095624 loss: 0.8987748484810756\n",
            "Epochs: 49 w1: 0.9546663671657377 w2: 2.0 b: -2.2191308800670098 loss: 0.18014341938977796\n",
            "Epochs: 50 w1: 0.9283141764435999 w2: 1.7439792015842854 b: -2.4751516784827245 loss: 0.717525116170741\n",
            "Epochs: 51 w1: 1.1504491148368152 w2: 2.2786094719200283 b: -2.1965422065626963 loss: 0.8146798609961085\n",
            "Epochs: 52 w1: 0.9562632849615875 w2: 2.0 b: -2.2806512739442586 loss: 0.18418505374210836\n",
            "Epochs: 53 w1: 1.1295960473689375 w2: 2.2124525366703893 b: -2.0681987372738693 loss: 0.5532201619684914\n",
            "Epochs: 54 w1: 0.951820625373963 w2: 2.0 b: -2.1608513807854792 loss: 0.2049418212204381\n",
            "Epochs: 55 w1: 1.1142448214514349 w2: 2.204008609734705 b: -1.956842771050774 loss: 0.5242777314627359\n",
            "Epochs: 56 w1: 1.0722546236382973 w2: 2.160565830307327 b: -1.796276940743447 loss: 0.38732807392866164\n",
            "Epochs: 57 w1: 1.2280133867587522 w2: 2.0 b: -1.4162546294788598 loss: 1.4273023001316434\n",
            "Epochs: 58 w1: 1.063650770651356 w2: 2.1043455256579606 b: -1.3119091038208992 loss: 0.23406680759221443\n",
            "Epochs: 59 w1: 1.0553904347363892 w2: 2.1007098813388896 b: -1.2111992224820098 loss: 0.2249198313130874\n",
            "Epochs: 60 w1: 1.0545525287670192 w2: 2.0879879496242246 b: -1.1232112728577852 loss: 0.1935555010155024\n",
            "Epochs: 61 w1: 1.04835638368967 w2: 2.087920697617582 b: -1.0352905752402033 loss: 0.19339228608413137\n",
            "Epochs: 62 w1: 1.042811994404931 w2: 2.085623988809862 b: -0.9496665864303414 loss: 0.18783429720718256\n",
            "Epochs: 63 w1: 0.9289188476272375 w2: 1.6051047090402086 b: -1.3445618773901329 loss: 1.5596510162127724\n",
            "Epochs: 64 w1: 0.9774655718163222 w2: 2.0 b: -1.4631641309884373 loss: 0.27076531402609433\n",
            "Epochs: 65 w1: 1.0566733544952887 w2: 2.1416833862382214 b: -1.321480744750216 loss: 0.3331911068865712\n",
            "Epochs: 66 w1: 0.9766414865414853 w2: 2.0 b: -1.4444202892687144 loss: 0.28220256446299175\n",
            "Epochs: 67 w1: 1.2107000981175937 w2: 2.0 b: -1.093253459072725 loss: 1.2117820855156012\n",
            "Epochs: 68 w1: 1.085994439774956 w2: 2.0 b: -0.7492756999729013 loss: 1.164609531461848\n",
            "Epochs: 69 w1: 1.0392302941409755 w2: 2.0643119576081568 b: -0.6849637423647447 loss: 0.137681610266079\n",
            "Epochs: 70 w1: 0.9040244070463 w2: 1.5827148132447828 b: -1.102248929119962 loss: 1.7992093921813601\n",
            "Epochs: 71 w1: 0.9615412264733085 w2: 2.0 b: -1.250167288838006 loss: 0.3507450170971137\n",
            "Epochs: 72 w1: 1.06174129695976 w2: 2.106450511999586 b: -1.14371677683842 loss: 0.23940127481180157\n",
            "Epochs: 73 w1: 0.8909358316199147 w2: 1.610485112928267 b: -1.533231663910153 loss: 1.5097273111716314\n",
            "Epochs: 74 w1: 0.9283543167998246 w2: 2.0 b: -1.6634965424559265 loss: 0.3018212371156201\n",
            "Epochs: 75 w1: 1.0742288017650925 w2: 2.1579336207767925 b: -1.505562921679134 loss: 0.3796032888969368\n",
            "Epochs: 76 w1: 0.9213413476988488 w2: 2.0 b: -1.6485786531357727 loss: 0.3369163833183444\n",
            "Epochs: 77 w1: 0.9093075491900109 w2: 1.6760983899643245 b: -1.9724802631714482 loss: 1.0435652256970644\n",
            "Epochs: 78 w1: 1.1235413128297131 w2: 2.2246205687812965 b: -1.7478596943901517 loss: 0.5964582018496579\n",
            "Epochs: 79 w1: 0.9259178563612377 w2: 1.6632629834601715 b: -2.08459671092998 loss: 1.1192458022784895\n",
            "Epochs: 80 w1: 1.116686462680214 w2: 2.24826906953237 b: -1.8363276413976097 loss: 0.6862473175867584\n",
            "Epochs: 81 w1: 1.2287435281652492 w2: 2.0 b: -1.455088427788861 loss: 1.4374968268640564\n",
            "Epochs: 82 w1: 1.0620941726624409 w2: 2.11498920863415 b: -1.340099219154711 loss: 0.26133673500553867\n",
            "Epochs: 83 w1: 1.093183263570472 w2: 2.0 b: -0.9673661648728231 loss: 1.3683212831495741\n",
            "Epochs: 84 w1: 1.0444954723687463 w2: 2.082399022905086 b: -0.8849671419677374 loss: 0.1800817220698281\n",
            "Epochs: 85 w1: 1.0419967513072055 w2: 2.0688471332905007 b: -0.8161200086772366 loss: 0.1481453920618524\n",
            "Epochs: 86 w1: 1.0316974817806213 w2: 2.079243704451553 b: -0.7368763042256833 loss: 0.1725543027812275\n",
            "Epochs: 87 w1: 0.9499578804231192 w2: 2.0 b: -0.9293459949059938 loss: 0.48603444913971705\n",
            "Epochs: 88 w1: 0.9139371773259438 w2: 1.608805351481563 b: -1.320540643424431 loss: 1.5250475787985367\n",
            "Epochs: 89 w1: 1.0935960934669704 w2: 2.0 b: -0.9461562695565497 loss: 1.3813814402466826\n",
            "Epochs: 90 w1: 1.0419729841915255 w2: 2.083945968383051 b: -0.8622103011734988 loss: 0.18379296290049604\n",
            "Epochs: 91 w1: 0.915103320297114 w2: 1.595730096652924 b: -1.2664802045205747 loss: 1.653075359823532\n",
            "Epochs: 92 w1: 1.2016114710014398 w2: 2.0 b: -0.9304610861848417 loss: 1.114858252611297\n",
            "Epochs: 93 w1: 1.0383620251472254 w2: 2.08162133010048 b: -0.8488397560843619 loss: 0.17822116713468206\n",
            "Epochs: 94 w1: 1.0369499573630014 w2: 2.073899914726003 b: -0.774939841358359 loss: 0.15993383778962136\n",
            "Epochs: 95 w1: 1.036746808811038 w2: 2.0668123796564326 b: -0.7081274617019262 loss: 0.14343716093460895\n",
            "Epochs: 96 w1: 1.03123192939601 w2: 2.0694042875466887 b: -0.6387231741552373 loss: 0.14943847068662225\n",
            "Epochs: 97 w1: 0.9119556462268716 w2: 1.5807411725089124 b: -1.0579820016463248 loss: 1.8233594610702362\n",
            "Epochs: 98 w1: 1.0654728128524258 w2: 2.1393038571328207 b: -0.9186781445135042 loss: 0.3265722040348607\n",
            "Epochs: 99 w1: 1.1708193282127084 w2: 2.0 b: -0.6339792641589903 loss: 0.8425704936683406\n",
            "Epochs: 100 w1: 0.8716348726811511 w2: 2.0 b: -0.8808352782336996 loss: 0.6806496572496015\n",
            "Epochs: 101 w1: 1.0430284326791377 w2: 2.0878131279166077 b: -0.7930221503170921 loss: 0.19313127888786985\n",
            "Epochs: 102 w1: 0.9266540196356354 w2: 1.5925223313090855 b: -1.2004998190080067 loss: 1.6871580634831438\n",
            "Epochs: 103 w1: 1.0803056044482409 w2: 2.1434028650861445 b: -1.0570969539218624 loss: 0.3380014274790019\n",
            "Epochs: 104 w1: 1.0858989034683009 w2: 2.0 b: -0.7135013400486591 loss: 1.162163226415234\n",
            "Epochs: 105 w1: 1.1546456636055027 w2: 2.0 b: -0.4557585673728214 loss: 0.7246080139408768\n",
            "Epochs: 106 w1: 1.0259379282193148 w2: 2.0551870813176913 b: -0.40057148605513015 loss: 0.11695431210742752\n",
            "Epochs: 107 w1: 1.0669949449110219 w2: 2.0 b: -0.13259170641104256 loss: 0.7677835738472877\n",
            "Epochs: 108 w1: 1.0228946670336525 w2: 2.0369268823123425 b: -0.09566482409869992 loss: 0.07672313523264225\n",
            "Epochs: 109 w1: 1.0198101605589263 w2: 2.0396203211178525 b: -0.056044502980847566 loss: 0.08255656051089318\n",
            "Epochs: 110 w1: 1.0211186774762744 w2: 2.034062383026249 b: -0.0219821199545987 loss: 0.07055634241286146\n",
            "Epochs: 111 w1: 1.0183729130446335 w2: 2.0374957409074153 b: 0.015513620952816554 loss: 0.07795233266328117\n",
            "Epochs: 112 w1: 0.8723216787162866 w2: 1.5440059954153091 b: -0.44048038363187425 loss: 2.4302822143475593\n",
            "Epochs: 113 w1: 1.0411777778873519 w2: 2.0915061730830042 b: -0.3489742105488702 loss: 0.20213129582261663\n",
            "Epochs: 114 w1: 1.024496789361924 w2: 2.0453644247443035 b: -0.30360978580456666 loss: 0.09511193389381174\n",
            "Epochs: 115 w1: 1.0263338544895622 w2: 2.0424739588541327 b: -0.26113582695043397 loss: 0.08877429478911317\n",
            "Epochs: 116 w1: 0.8523926108494314 w2: 2.0 b: -0.5449961907015273 loss: 0.8386834354906322\n",
            "Epochs: 117 w1: 1.0727776408660543 w2: 2.0 b: -0.25388562723731045 loss: 0.8728029982239971\n",
            "Epochs: 118 w1: 1.024829843927343 w2: 2.0428100757367984 b: -0.21107555150051183 loss: 0.08950920466388172\n",
            "Epochs: 119 w1: 1.0240757327290018 w2: 2.039468414309839 b: -0.17160713719067272 loss: 0.08222665508952436\n",
            "Epochs: 120 w1: 0.951954551740882 w2: 2.0 b: -0.4244779175018201 loss: 0.7046967419579068\n",
            "Epochs: 121 w1: 1.027451585201304 w2: 2.058407628087881 b: -0.3660702894139392 loss: 0.12422087735822945\n",
            "Epochs: 122 w1: 1.0262731634069375 w2: 2.046916363226674 b: -0.319153926187265 loss: 0.09853136134223896\n",
            "Epochs: 123 w1: 0.95544506559007 w2: 2.0 b: -0.5536535809763702 loss: 0.6329919575116845\n",
            "Epochs: 124 w1: 1.0345534875138294 w2: 2.05957497847212 b: -0.49407860250425045 loss: 0.1268678797292018\n",
            "Epochs: 125 w1: 0.9595142817081203 w2: 2.0 b: -0.7071613303562493 loss: 0.5554141745700859\n",
            "Epochs: 126 w1: 1.031508063885442 w2: 2.0787701597136046 b: -0.6283911706426446 loss: 0.17142947478769313\n",
            "Epochs: 127 w1: 1.033884148760202 w2: 2.05554778485279 b: -0.5728433857898543 loss: 0.11776555172800633\n",
            "Epochs: 128 w1: 1.0294808820728256 w2: 2.060165065454746 b: -0.5126783203351082 loss: 0.1282085906565717\n",
            "Epochs: 129 w1: 1.0296373685029248 w2: 2.0538861245507722 b: -0.4587921957843359 loss: 0.11403385287294936\n",
            "Epochs: 130 w1: 1.0261208155709924 w2: 2.055576203342537 b: -0.403215992441799 loss: 0.11782949425627547\n",
            "Epochs: 131 w1: 0.8615381370227182 w2: 2.0 b: -0.6694888058596487 loss: 0.7604535325258591\n",
            "Epochs: 132 w1: 0.8840755502115993 w2: 1.5859841078985693 b: -1.0835046979610794 loss: 1.7604456111219091\n",
            "Epochs: 133 w1: 0.9611730581426287 w2: 2.0 b: -1.2328390897201997 loss: 0.35477501212168905\n",
            "Epochs: 134 w1: 1.0520943814650274 w2: 2.1157652921445056 b: -1.1170737975756944 loss: 0.2633545141786514\n",
            "Epochs: 135 w1: 1.0431096989765596 w2: 2.0917227637799143 b: -1.0253510337957803 loss: 0.20266165423456878\n",
            "Epochs: 136 w1: 1.0424189531695027 w2: 2.0848379063390055 b: -0.9405131274567748 loss: 0.18593906731586518\n",
            "Epochs: 137 w1: 1.0440049113544103 w2: 2.0721391989416564 b: -0.8683739285151186 loss: 0.15581018691161663\n",
            "Epochs: 138 w1: 1.0364700812965582 w2: 2.077595917652251 b: -0.7907780108628674 loss: 0.1686457014278161\n",
            "Epochs: 139 w1: 1.037143574201255 w2: 2.067533771275009 b: -0.7232442395878587 loss: 0.14510385897181466\n",
            "Epochs: 140 w1: 0.8819218319787924 w2: 2.0 b: -0.9503176396286425 loss: 0.605405204006059\n",
            "Epochs: 141 w1: 1.0517628075845236 w2: 2.084857061613973 b: -0.8654605780146692 loss: 0.1859852076479885\n",
            "Epochs: 142 w1: 1.0401091784336804 w2: 2.069153755920139 b: -0.7963068220945304 loss: 0.14885681424021072\n",
            "Epochs: 143 w1: 1.0385225260169382 w2: 2.0664181483050656 b: -0.7298886737894648 loss: 0.14252750411980517\n",
            "Epochs: 144 w1: 1.0295605730408495 w2: 2.0739014326021237 b: -0.6559872411873411 loss: 0.15993740004852916\n",
            "Epochs: 145 w1: 0.9034543920666821 w2: 1.5802364872464438 b: -1.0757507539408973 loss: 1.8296297338119965\n",
            "Epochs: 146 w1: 0.9299751783187592 w2: 1.6665484681845677 b: -1.4092022857563296 loss: 1.0993217311555241\n",
            "Epochs: 147 w1: 1.069532211096394 w2: 2.1738305277409853 b: -1.2353717580153443 loss: 0.4271909985772724\n",
            "Epochs: 148 w1: 0.9054998820654616 w2: 2.0 b: -1.4071901542599594 loss: 0.4210409732707928\n",
            "Epochs: 149 w1: 0.921028060358801 w2: 2.0 b: -1.5507754990621394 loss: 0.3385132835872749\n",
            "Epochs: 150 w1: 1.061253152035897 w2: 2.1531328800897422 b: -1.3976426189723972 loss: 0.3656663315553701\n",
            "Epochs: 151 w1: 0.9236879553799028 w2: 1.6366093113328704 b: -1.7610333076395268 loss: 1.2974829886535004\n",
            "Epochs: 152 w1: 1.1025772781672027 w2: 2.2093413840146994 b: -1.5516919236248274 loss: 0.5424586608631765\n",
            "Epochs: 153 w1: 1.097722030021048 w2: 2.0 b: -1.1608038035406358 loss: 1.5222343213572036\n",
            "Epochs: 154 w1: 1.043568458897012 w2: 2.1089211472425298 b: -1.0518826562981058 loss: 0.24569888931293218\n",
            "Epochs: 155 w1: 0.9301228797066018 w2: 1.6117937761477874 b: -1.4400888801503184 loss: 1.497952208769694\n",
            "Epochs: 156 w1: 0.92211317788251 w2: 2.0 b: -1.5817012840003004 loss: 0.3329930268767427\n",
            "Epochs: 157 w1: 0.9284468536772899 w2: 1.6747584258058628 b: -1.9069428581944377 loss: 1.0512035021280797\n",
            "Epochs: 158 w1: 0.9454387995957955 w2: 2.0 b: -2.006145040747537 loss: 0.22115099415812792\n",
            "Epochs: 159 w1: 1.08161009549982 w2: 2.20402523874955 b: -1.802119801997987 loss: 0.5243339137792641\n",
            "Epochs: 160 w1: 1.0605367935685481 w2: 2.15134198392137 b: -1.6507778180766168 loss: 0.3605165532551597\n",
            "Epochs: 161 w1: 0.9256777708015008 w2: 1.6621716854613675 b: -1.9886061326152493 loss: 1.1259525375688215\n",
            "Epochs: 162 w1: 1.123322625602105 w2: 2.2283752325964907 b: -1.7602309000187586 loss: 0.610186516160703\n",
            "Epochs: 163 w1: 1.2243017570021169 w2: 2.0 b: -1.386394638348564 loss: 1.3770275245497485\n",
            "Epochs: 164 w1: 1.093319298006337 w2: 2.0 b: -1.0131174463232153 loss: 1.3726060117107073\n",
            "Epochs: 165 w1: 1.0493292660474574 w2: 2.0795633323346085 b: -0.9335541139886068 loss: 0.17331424232522089\n",
            "Epochs: 166 w1: 0.8949022182102395 w2: 2.0 b: -1.1356652328150691 loss: 0.5178875634225498\n",
            "Epochs: 167 w1: 1.0891746146095331 w2: 2.0 b: -0.7789667743769363 loss: 1.2496570060613699\n",
            "Epochs: 168 w1: 1.0352996394914775 w2: 2.075105615939314 b: -0.7038611584376223 loss: 0.162767468473531\n",
            "Epochs: 169 w1: 0.904167857231341 w2: 1.5833385097014823 b: -1.1205226487361402 loss: 1.7916973547394126\n",
            "Epochs: 170 w1: 1.1921836379717603 w2: 2.0 b: -0.8002165854498728 loss: 1.0233530463608964\n",
            "Epochs: 171 w1: 1.0374757953281273 w2: 2.0669210630859416 b: -0.7332955223639313 loss: 0.14368808469281816\n",
            "Epochs: 172 w1: 0.8825582427016879 w2: 2.0 b: -0.959145055629916 loss: 0.6009309940967816\n",
            "Epochs: 173 w1: 1.0525945024486965 w2: 2.084829842659188 b: -0.8743152129707281 loss: 0.18591964453707244\n",
            "Epochs: 174 w1: 0.967934679291903 w2: 2.0 b: -1.0430800588028175 loss: 0.41177953973240633\n",
            "Epochs: 175 w1: 0.9120404135832076 w2: 1.6175670155791635 b: -1.425513043223654 loss: 1.4475995820684897\n",
            "Epochs: 176 w1: 0.9145962341335878 w2: 1.6949865504770993 b: -1.7305264927465547 loss: 0.9416775141494275\n",
            "Epochs: 177 w1: 1.1045923881676931 w2: 2.19368960771795 b: -1.5368368850286045 loss: 0.4900091567161529\n",
            "Epochs: 178 w1: 1.0567941495752626 w2: 2.115906427704618 b: -1.420930457323987 loss: 0.2637218976665323\n",
            "Epochs: 179 w1: 0.9170601915394812 w2: 2.0 b: -1.5717301090703848 loss: 0.3589622771674302\n",
            "Epochs: 180 w1: 1.0827682267678398 w2: 2.135685617652196 b: -1.4360444914181887 loss: 0.3165909157804214\n",
            "Epochs: 181 w1: 0.9247705643537427 w2: 1.6417645921606796 b: -1.794279899257509 loss: 1.2604402181801069\n",
            "Epochs: 182 w1: 0.9773107868132311 w2: 2.0 b: -1.8815461038220045 loss: 0.1918052763914259\n",
            "Epochs: 183 w1: 0.9474591920967551 w2: 2.0 b: -1.9825861190205525 loss: 0.2257469752797433\n",
            "Epochs: 184 w1: 1.0935552393587482 w2: 2.1909290599158124 b: -1.7916570591047398 loss: 0.481037268313324\n",
            "Epochs: 185 w1: 1.0604463003919418 w2: 2.151115750979854 b: -1.6405413081248854 loss: 0.35986789593138824\n",
            "Epochs: 186 w1: 1.065249031779772 w2: 2.130498063559544 b: -1.5100432445653413 loss: 0.3024521173427804\n",
            "Epochs: 187 w1: 1.097026597341105 w2: 2.0 b: -1.1219368552009212 loss: 1.4970595836122642\n",
            "Epochs: 188 w1: 1.0455267860554878 w2: 2.1011706356788618 b: -1.0207662195220597 loss: 0.22607443134724917\n",
            "Epochs: 189 w1: 0.9297547420418786 w2: 1.6097485668993254 b: -1.4110176526227343 loss: 1.516416104417083\n",
            "Epochs: 190 w1: 0.9308039208735785 w2: 1.699147482059037 b: -1.7118701705636972 loss: 0.9205624323138999\n",
            "Epochs: 191 w1: 1.1112302866117614 w2: 2.1823447321504283 b: -1.5295254384132688 loss: 0.45364136702983976\n",
            "Epochs: 192 w1: 1.0554446823094303 w2: 2.1179674091690006 b: -1.4115580292442682 loss: 0.2691021771433295\n",
            "Epochs: 193 w1: 0.9165594297674085 w2: 2.0 b: -1.5632681569398892 loss: 0.36157299897980244\n",
            "Epochs: 194 w1: 1.220101545407376 w2: 2.0 b: -1.196432247927596 loss: 1.3230259638404374\n",
            "Epochs: 195 w1: 0.9180527288744265 w2: 1.6275124039746658 b: -1.5689198439529302 loss: 1.3663944524798846\n",
            "Epochs: 196 w1: 1.1009717985283989 w2: 2.1803067830864267 b: -1.3886130608665037 loss: 0.44724625961753445\n",
            "Epochs: 197 w1: 0.9675912744157941 w2: 2.0 b: -1.513262005421142 loss: 0.28674636251060587\n",
            "Epochs: 198 w1: 1.2152872609099943 w2: 2.0 b: -1.154449903904485 loss: 1.2645164818281038\n",
            "Epochs: 199 w1: 1.050757566336304 w2: 2.0875130454074204 b: -1.0669368584970644 loss: 0.19240351837765476\n",
            "Epochs: 200 w1: 0.9103674747532149 w2: 1.6102933684922387 b: -1.4566434900048257 loss: 1.511464296434\n",
            "Epochs: 201 w1: 1.0940526118486438 w2: 2.171004748815716 b: -1.28563874118911 loss: 0.4185647818513141\n",
            "Epochs: 202 w1: 1.0476363520521372 w2: 2.0972170450043617 b: -1.1884216961847485 loss: 0.2162102547699704\n",
            "Epochs: 203 w1: 1.0419030482166072 w2: 2.104757620541518 b: -1.0836640756432308 loss: 0.23510890282592306\n",
            "Epochs: 204 w1: 0.9043845746855763 w2: 2.0 b: -1.267539893555584 loss: 0.4584729807421816\n",
            "Epochs: 205 w1: 1.0615035187120114 w2: 2.1138954050222436 b: -1.1536444885333406 loss: 0.258499794218527\n",
            "Epochs: 206 w1: 0.9006482957475962 w2: 2.0 b: -1.3342839508104385 loss: 0.4482874215489378\n",
            "Epochs: 207 w1: 1.206600113328671 w2: 2.0 b: -0.9899504285959869 loss: 1.1668923427912083\n",
            "Epochs: 208 w1: 1.0392963779534816 w2: 2.0873252843410706 b: -0.9026251442549165 loss: 0.19194842920819913\n",
            "Epochs: 209 w1: 1.033584621024271 w2: 2.0839615525606776 b: -0.8186635916942389 loss: 0.18383042070241312\n",
            "Epochs: 210 w1: 1.0375360402561378 w2: 2.0695111856595148 b: -0.7491524060347243 loss: 0.1496867578408993\n",
            "Epochs: 211 w1: 1.0775064838543682 w2: 2.0 b: -0.4391264706172515 loss: 0.9677205377762039\n",
            "Epochs: 212 w1: 1.0257585351254779 w2: 2.057241189167729 b: -0.38188528144952266 loss: 0.12158292171497223\n",
            "Epochs: 213 w1: 1.0277655217420876 w2: 2.0455172487575206 b: -0.336368032692002 loss: 0.09544813658646961\n",
            "Epochs: 214 w1: 0.9558454009260265 w2: 2.0 b: -0.5687606593971257 loss: 0.6250872171288867\n",
            "Epochs: 215 w1: 1.0343739042332885 w2: 2.061381971845158 b: -0.5073786875519679 loss: 0.13097915941893531\n",
            "Epochs: 216 w1: 0.9234359855246146 w2: 1.5746443640256365 b: -0.9327343235263313 loss: 1.901873075939047\n",
            "Epochs: 217 w1: 1.066875990082855 w2: 2.119421410862241 b: -0.8133129126640903 loss: 0.27291540069231174\n",
            "Epochs: 218 w1: 0.9051101849551171 w2: 1.5874355867613785 b: -1.2258773259027118 loss: 1.7437057274495729\n",
            "Epochs: 219 w1: 1.0873057348080493 w2: 2.1431241554230316 b: -1.0827531704796804 loss: 0.33722015142426276\n",
            "Epochs: 220 w1: 0.8951879725699688 w2: 2.0 b: -1.273320493079737 loss: 0.47986755047570595\n",
            "Epochs: 221 w1: 0.9174763510763025 w2: 1.641201526418707 b: -1.63211896666103 loss: 1.2644199630906956\n",
            "Epochs: 222 w1: 0.9422218856987477 w2: 1.7248661223749888 b: -1.9072528442860412 loss: 0.7991028849741799\n",
            "Epochs: 223 w1: 1.1052252492291883 w2: 2.0 b: -1.4863518473692876 loss: 1.843907826973942\n",
            "Epochs: 224 w1: 1.060026465176317 w2: 2.13339214483626 b: -1.3529597025330276 loss: 0.3103153361764763\n",
            "Epochs: 225 w1: 0.9153833000447477 w2: 1.6321013045423811 b: -1.7208583979906464 loss: 1.331039011527222\n",
            "Epochs: 226 w1: 0.9390031150472016 w2: 1.7347961523791375 b: -1.986062245611509 loss: 0.7558903974034632\n",
            "Epochs: 227 w1: 0.9806210246818575 w2: 2.0 b: -2.060596766065903 loss: 0.16142428285242325\n",
            "Epochs: 228 w1: 1.0913415062232865 w2: 2.202981124940637 b: -1.8576156411252664 loss: 0.5208124092504308\n",
            "Epochs: 229 w1: 1.0727240077014737 w2: 2.1454480154029474 b: -1.7121676257223193 loss: 0.34375312117818424\n",
            "Epochs: 230 w1: 1.0661321866011142 w2: 2.1407067800023705 b: -1.5714608457199488 loss: 0.330469274512406\n",
            "Epochs: 231 w1: 1.0658526860703283 w2: 2.119732156491506 b: -1.4517286892284427 loss: 0.2737322426546575\n",
            "Epochs: 232 w1: 1.0627841386106793 w2: 2.108248514845999 b: -1.343480174382444 loss: 0.24398042611730297\n",
            "Epochs: 233 w1: 0.9188826103586619 w2: 2.0 b: -1.4994751544619405 loss: 0.3739518483631056\n",
            "Epochs: 234 w1: 0.9046770097470349 w2: 1.6595607490965534 b: -1.839914405365387 loss: 1.142183376631947\n",
            "Epochs: 235 w1: 0.9472970921354282 w2: 2.0 b: -1.9412661512587943 loss: 0.2265286389976565\n",
            "Epochs: 236 w1: 1.2393539007782588 w2: 2.0 b: -1.5423429832950295 loss: 1.5987271575465347\n",
            "Epochs: 237 w1: 0.9220773998209525 w2: 1.6612060861780542 b: -1.8811368971169753 loss: 1.131924513615396\n",
            "Epochs: 238 w1: 1.2371474432753327 w2: 2.0 b: -1.4858911583247543 loss: 1.5629908606594791\n",
            "Epochs: 239 w1: 1.063923187735567 w2: 2.116223977701031 b: -1.3696671806237233 loss: 0.26454899126875714\n",
            "Epochs: 240 w1: 0.967364161149281 w2: 2.0 b: -1.4951896377418732 loss: 0.28907626286546295\n",
            "Epochs: 241 w1: 1.0678024878091532 w2: 2.1356049756183064 b: -1.3595846621235668 loss: 0.31636958740597126\n",
            "Epochs: 242 w1: 1.0565532839289289 w2: 2.1009880070159443 b: -1.2585966551076224 loss: 0.22561662437989938\n",
            "Epochs: 243 w1: 0.9142576997421475 w2: 2.0 b: -1.4234856940650311 loss: 0.4001463944478654\n",
            "Epochs: 244 w1: 0.9390491084275272 w2: 1.6613839357084843 b: -1.7621017583565468 loss: 1.1308218784662416\n",
            "Epochs: 245 w1: 1.1106798382081906 w2: 2.1976425682289116 b: -1.5644591901276352 loss: 0.5029982319783021\n",
            "Epochs: 246 w1: 0.8992081255279449 w2: 1.6400290197426604 b: -1.9244301703849749 loss: 1.2727584134170769\n",
            "Epochs: 247 w1: 1.127887500378391 w2: 2.2204956903075708 b: -1.703934480077404 loss: 0.5815903866527867\n",
            "Epochs: 248 w1: 0.9745035892424075 w2: 2.0 b: -1.8019975983758363 loss: 0.21831303282325776\n",
            "Epochs: 249 w1: 0.9370710071645539 w2: 1.7003381293550186 b: -2.101659469020818 loss: 0.9146015126335768\n",
            "Epochs: 250 w1: 1.1013245693673175 w2: 2.2533114234182934 b: -1.8483480456025243 loss: 0.7064813808568114\n",
            "Epochs: 251 w1: 0.9384054044772933 w2: 2.0 b: -1.9603382192801728 loss: 0.2535774335465345\n",
            "Epochs: 252 w1: 1.2405262873898717 w2: 2.0 b: -1.5594610736303867 loss: 1.6182480646009383\n",
            "Epochs: 253 w1: 1.0621174149453767 w2: 2.1321647126497374 b: -1.4272963609806493 loss: 0.3069728491731049\n",
            "Epochs: 254 w1: 0.9172592087343164 w2: 2.0 b: -1.5777341632818922 loss: 0.3579265906395941\n",
            "Epochs: 255 w1: 1.0702003269648643 w2: 2.1493623977975833 b: -1.4283717654843087 loss: 0.3548548806808543\n",
            "Epochs: 256 w1: 0.9205351853430938 w2: 1.6387962970140624 b: -1.7895754684702463 loss: 1.2816007292784046\n",
            "Epochs: 257 w1: 0.9262595922098458 w2: 1.7366414007494493 b: -2.052934067720797 loss: 0.7480621801506104\n",
            "Epochs: 258 w1: 0.981750116408916 w2: 2.0 b: -2.123125927686505 loss: 0.15126917527192396\n",
            "Epochs: 259 w1: 1.2467805635145246 w2: 2.0 b: -1.7118249884956307 loss: 1.7293587975603948\n",
            "Epochs: 260 w1: 1.06918142455595 w2: 2.147194520331809 b: -1.5646304681638217 loss: 0.3486912424708577\n",
            "Epochs: 261 w1: 0.9718652037795532 w2: 2.0 b: -1.6728412228578478 loss: 0.24388404273725953\n",
            "Epochs: 262 w1: 1.0757796080158248 w2: 2.1546522612567856 b: -1.5181889616010622 loss: 0.37005625063352104\n",
            "Epochs: 263 w1: 1.0640616899877042 w2: 2.110451189633973 b: -1.4077377719670894 loss: 0.24961892551720066\n",
            "Epochs: 264 w1: 1.0488935860440178 w2: 2.122233965110045 b: -1.2855038068570448 loss: 0.28033304975210355\n",
            "Epochs: 265 w1: 1.0443227248811078 w2: 2.1108068122027697 b: -1.1746969946542754 loss: 0.25053225135388635\n",
            "Epochs: 266 w1: 0.9121074997966213 w2: 1.617858694767919 b: -1.5568382998863564 loss: 1.4451216935017208\n",
            "Epochs: 267 w1: 1.0933841626549476 w2: 2.1867683253098953 b: -1.3700699745764613 loss: 0.46766500694748797\n",
            "Epochs: 268 w1: 0.8943677287740864 w2: 1.62274188847888 b: -1.7473280860975813 loss: 1.4045244155695011\n",
            "Epochs: 269 w1: 0.9256015157702677 w2: 1.734291127750956 b: -2.013036958346625 loss: 0.7580436206721253\n",
            "Epochs: 270 w1: 1.106987354086609 w2: 2.0 b: -1.5850875420001893 loss: 1.9372396753354393\n",
            "Epochs: 271 w1: 0.9310759247328902 w2: 1.671790117775668 b: -1.9132974242245213 loss: 1.0683346122047719\n",
            "Epochs: 272 w1: 1.109398703565853 w2: 2.2232626603384755 b: -1.6900347638860458 loss: 0.5915392743603374\n",
            "Epochs: 273 w1: 0.920939174221388 w2: 1.6562572792234262 b: -2.0337774846626195 loss: 1.1631042238608944\n",
            "Epochs: 274 w1: 1.128643778862047 w2: 2.233897779749176 b: -1.7998797049134434 loss: 0.6307275768024664\n",
            "Epochs: 275 w1: 1.1025252888459338 w2: 2.0 b: -1.3897785495297086 loss: 1.7159230089041209\n",
            "Epochs: 276 w1: 0.9228735704128882 w2: 1.6494253200585829 b: -1.7403532294711257 loss: 1.2078113617795327\n",
            "Epochs: 277 w1: 1.1106308753616503 w2: 2.1975551345743756 b: -1.5427980948967501 loss: 0.5027091006190119\n",
            "Epochs: 278 w1: 0.8986024359757652 w2: 1.6378658427705899 b: -1.9049322521261605 loss: 1.2883270399493125\n",
            "Epochs: 279 w1: 1.1047887223487303 w2: 2.232863827441623 b: -1.6720684246845376 loss: 0.6268495604506898\n",
            "Epochs: 280 w1: 0.9013316334254894 w2: 1.6476129765196053 b: -2.0244554481649324 loss: 1.2200142733207822\n",
            "Epochs: 281 w1: 0.9343508207919378 w2: 1.7655386456854918 b: -2.2589168024794404 loss: 0.6328477101953105\n",
            "Epochs: 282 w1: 0.9591141176828981 w2: 2.0 b: -2.3332547703287165 loss: 0.16096241878173834\n",
            "Epochs: 283 w1: 0.9900976124795475 w2: 2.0 b: -2.3853725993837296 loss: 0.11007791188425103\n",
            "Epochs: 284 w1: 0.9337813996794788 w2: 1.7635049988552818 b: -2.621867600528448 loss: 0.6405357596329354\n",
            "Epochs: 285 w1: 0.9623437641942425 w2: 1.8288352917920112 b: -2.7930323087364366 loss: 0.41905110586631616\n",
            "Epochs: 286 w1: 0.964769105489437 w2: 1.8398595704065313 b: -2.953172738329905 loss: 0.38607559434771627\n",
            "Epochs: 287 w1: 1.1841513067473803 w2: 2.3175022530127247 b: -2.6356704853171804 loss: 1.0078702707510532\n",
            "Epochs: 288 w1: 0.99217563100275 w2: 2.0 b: -2.676851374776391 loss: 0.08595206071974063\n",
            "Epochs: 289 w1: 1.1362670594496322 w2: 2.2725341188992645 b: -2.4043172558771264 loss: 0.7876078444618693\n",
            "Epochs: 290 w1: 1.0914036765161124 w2: 2.2031192811469165 b: -2.20119797473021 loss: 0.5212776603137009\n",
            "Epochs: 291 w1: 1.0879017490650633 w2: 2.1870249980107728 b: -2.014172976719437 loss: 0.4684847769205999\n",
            "Epochs: 292 w1: 0.9305149872506954 w2: 1.697891248916067 b: -2.3162817278033705 loss: 0.9268904665181895\n",
            "Epochs: 293 w1: 0.9584406508652696 w2: 1.8020983374536648 b: -2.5141833903497055 loss: 0.5038555133427397\n",
            "Epochs: 294 w1: 1.1133436496757123 w2: 2.0 b: -2.0608087916468563 loss: 2.3724626135858538\n",
            "Epochs: 295 w1: 1.1005151015499504 w2: 2.182754730090819 b: -1.8780540615560375 loss: 0.4549329016025762\n",
            "Epochs: 296 w1: 0.984936477462124 w2: 2.0 b: -1.957335759123806 loss: 0.17264460406027352\n",
            "Epochs: 297 w1: 0.9379075777320928 w2: 1.7177617169640578 b: -2.2395740421597483 loss: 0.8312066748878408\n",
            "Epochs: 298 w1: 1.252745274247436 w2: 2.0 b: -1.8183319184140214 loss: 1.8482298097904313\n",
            "Epochs: 299 w1: 1.2231897809802557 w2: 2.0 b: -1.4463489501135953 loss: 1.3624447832013702\n",
            "Epochs: 300 w1: 1.057440755526096 w2: 2.1222143734597787 b: -1.3241345766538166 loss: 0.2802811892340994\n",
            "Epochs: 301 w1: 0.9179551432888917 w2: 2.0 b: -1.4819131472521017 loss: 0.37915011647677493\n",
            "Epochs: 302 w1: 0.9708966809952417 w2: 2.0 b: -1.593848989578095 loss: 0.2534374176386071\n",
            "Epochs: 303 w1: 0.9422850407031322 w2: 1.6793613372396239 b: -1.914487652338471 loss: 1.0252056835082504\n",
            "Epochs: 304 w1: 1.1086802372665343 w2: 2.2217964025847636 b: -1.6926912497537072 loss: 0.5862548879767844\n",
            "Epochs: 305 w1: 0.9824136774576167 w2: 2.0 b: -1.7852508420820408 loss: 0.20471341527775266\n",
            "Epochs: 306 w1: 1.102926683126791 w2: 2.0 b: -1.3735441095748766 loss: 1.7339442395533873\n",
            "Epochs: 307 w1: 1.0614461405300064 w2: 2.1137891491296417 b: -1.259754960445235 loss: 0.2582246323171474\n",
            "Epochs: 308 w1: 1.0555708404256279 w2: 2.0910997384026686 b: -1.1686552220425663 loss: 0.20113683129310217\n",
            "Epochs: 309 w1: 0.8919602973585803 w2: 1.6141439191377867 b: -1.5545113029047797 loss: 1.4771479976687727\n",
            "Epochs: 310 w1: 0.9294464002914277 w2: 2.0 b: -1.6827905751021839 loss: 0.29646525780266686\n",
            "Epochs: 311 w1: 0.9397923171704959 w2: 2.0 b: -1.7985745805435378 loss: 0.2634032181405151\n",
            "Epochs: 312 w1: 1.0784792927160405 w2: 2.174398428257868 b: -1.6241761522856701 loss: 0.4289336370876065\n",
            "Epochs: 313 w1: 1.0621703276193633 w2: 2.1268782196313536 b: -1.4972979326543168 loss: 0.29270324314030166\n",
            "Epochs: 314 w1: 0.9188614864520692 w2: 1.6472238541394313 b: -1.8500740785148855 loss: 1.2226538526788586\n",
            "Epochs: 315 w1: 1.104355574241761 w2: 2.0 b: -1.4326517815478412 loss: 1.8008683934037004\n",
            "Epochs: 316 w1: 1.061524803808655 w2: 2.12304960761731 b: -1.3096021739305308 loss: 0.28249450482407656\n",
            "Epochs: 317 w1: 1.051098522972207 w2: 2.1042826999432798 b: -1.205319473987251 loss: 0.23390803085327733\n",
            "Epochs: 318 w1: 0.9326768265783412 w2: 1.6259823698796732 b: -1.5793371041075779 loss: 1.378466122850548\n",
            "Epochs: 319 w1: 1.108086687063592 w2: 2.1743333662316 b: -1.4050037378759779 loss: 0.428733836065743\n",
            "Epochs: 320 w1: 0.9679437508961575 w2: 2.0 b: -1.5282970036599877 loss: 0.2831411070164775\n",
            "Epochs: 321 w1: 0.9304253835029335 w2: 1.6686923023949212 b: -1.8596047012650665 loss: 1.0865317388684972\n",
            "Epochs: 322 w1: 1.1044697535660561 w2: 2.0 b: -1.441725687000842 loss: 1.8064145027417535\n",
            "Epochs: 323 w1: 1.0659769956853025 w2: 2.117816063723754 b: -1.3239096232770877 loss: 0.2687060971271126\n",
            "Epochs: 324 w1: 1.0491945135755911 w2: 2.1093211412790915 b: -1.2145884819979962 loss: 0.24672220911034284\n",
            "Epochs: 325 w1: 1.0518232529890297 w2: 2.0925415231946958 b: -1.1220469588033004 loss: 0.2046690683434644\n",
            "Epochs: 326 w1: 0.931482954451957 w2: 1.6193497469553166 b: -1.5026972118479838 loss: 1.4325498658296574\n",
            "Epochs: 327 w1: 0.933072669017971 w2: 1.7090116044259611 b: -1.7936856074220227 loss: 0.8722183244295652\n",
            "Epochs: 328 w1: 0.9238354884912241 w2: 1.7279838874686575 b: -2.065701719953365 loss: 0.7853331409620384\n",
            "Epochs: 329 w1: 1.1258138319306878 w2: 2.22875242169216 b: -1.8369492982612052 loss: 0.6115761215047402\n",
            "Epochs: 330 w1: 1.2284794253882891 w2: 2.0 b: -1.45615025594739 loss: 1.433797309543144\n",
            "Epochs: 331 w1: 0.927511581526607 w2: 1.6548170548886043 b: -1.8013332010587857 loss: 1.1723639696362462\n",
            "Epochs: 332 w1: 1.1053371536305785 w2: 2.210674307261157 b: -1.590658893797629 loss: 0.5470550803632811\n",
            "Epochs: 333 w1: 0.972230051502546 w2: 2.0 b: -1.6974663880186056 loss: 0.24030876989586386\n",
            "Epochs: 334 w1: 1.066743201851042 w2: 2.1668580046276054 b: -1.5306083833910005 loss: 0.4060392868000201\n",
            "Epochs: 335 w1: 0.9800972680603056 w2: 2.0 b: -1.635359604126234 loss: 0.23509271085156946\n",
            "Epochs: 336 w1: 1.069482460459439 w2: 2.1544054676876425 b: -1.4809541364385916 loss: 0.369341882472889\n",
            "Epochs: 337 w1: 1.049901363956442 w2: 2.124753409891105 b: -1.3562007265474865 loss: 0.2870247149348645\n",
            "Epochs: 338 w1: 0.9157020077380064 w2: 1.6334869901652451 b: -1.7227137363822413 loss: 1.3206040772763659\n",
            "Epochs: 339 w1: 0.9372728269976341 w2: 2.0 b: -1.8367631418410884 loss: 0.2588987305659192\n",
            "Epochs: 340 w1: 0.9848057859247871 w2: 2.0 b: -1.9167326896053667 loss: 0.1742808844500151\n",
            "Epochs: 341 w1: 0.944505328793857 w2: 2.0 b: -2.017632091798354 loss: 0.22539458848084618\n",
            "Epochs: 342 w1: 1.1074376554315053 w2: 2.1852373369508715 b: -1.8323947548474828 loss: 0.4627891942208328\n",
            "Epochs: 343 w1: 1.0760351032397568 w2: 2.138245642254103 b: -1.6941491125933796 loss: 0.32364268669180185\n",
            "Epochs: 344 w1: 1.0741663797675074 w2: 2.127873068564668 b: -1.5662760440287118 loss: 0.2953730888133059\n",
            "Epochs: 345 w1: 1.0624968160344632 w2: 2.1249936320689264 b: -1.4412824119597851 loss: 0.28766509144643\n",
            "Epochs: 346 w1: 0.9180539835686505 w2: 2.0 b: -1.5902751691076933 loss: 0.3538012402629778\n",
            "Epochs: 347 w1: 1.221622742680374 w2: 2.0 b: -1.22090393130707 loss: 1.342248674591544\n",
            "Epochs: 348 w1: 0.8944117132415168 w2: 1.62289897586256 b: -1.59800495544451 loss: 1.403245414980447\n",
            "Epochs: 349 w1: 0.9816269915603278 w2: 2.0 b: -1.6947049998638373 loss: 0.21492750668254143\n",
            "Epochs: 350 w1: 1.081677715172126 w2: 2.15125502809653 b: -1.5434499717673076 loss: 0.3602671828716381\n",
            "Epochs: 351 w1: 0.9802542046981805 w2: 2.0 b: -1.6473752101979369 loss: 0.2330051131448029\n",
            "Epochs: 352 w1: 1.0721869031086944 w2: 2.1535891555504136 b: -1.4937860546475235 loss: 0.3669826160761716\n",
            "Epochs: 353 w1: 0.9794951172628281 w2: 2.0 b: -1.601706490106323 loss: 0.24314330845913995\n",
            "Epochs: 354 w1: 1.0774134696731692 w2: 2.140751763042126 b: -1.460954727064197 loss: 0.3305944810384287\n",
            "Epochs: 355 w1: 0.9175923159048001 w2: 1.6417057213252177 b: -1.8192490057389792 loss: 1.2608555762159042\n",
            "Epochs: 356 w1: 0.9272230683628758 w2: 1.7400823870102706 b: -2.0791666187287086 loss: 0.7336259547775665\n",
            "Epochs: 357 w1: 0.9821539243675432 w2: 2.0 b: -2.1478053711612346 loss: 0.14766219797011515\n",
            "Epochs: 358 w1: 1.1122194311587679 w2: 2.2003918413549424 b: -1.947413529806292 loss: 0.5121326153573242\n",
            "Epochs: 359 w1: 0.9427397031247886 w2: 2.0 b: -2.0515231604884945 loss: 0.23347077065348315\n",
            "Epochs: 360 w1: 1.1134670009526542 w2: 2.186011476971564 b: -1.8655116835169303 loss: 0.46525166404679175\n",
            "Epochs: 361 w1: 1.0768411846025552 w2: 2.1422984900047317 b: -1.7232131935121984 loss: 0.3349092307647652\n",
            "Epochs: 362 w1: 0.9311270420728679 w2: 1.6720335336803231 b: -2.0511796598318752 loss: 1.066918677353912\n",
            "Epochs: 363 w1: 0.9597420523724645 w2: 1.7763447354025805 b: -2.2748349244292947 loss: 0.5929589707945092\n",
            "Epochs: 364 w1: 1.145874048929037 w2: 2.2391377851295693 b: -2.0356971392997254 loss: 0.6506157428681248\n",
            "Epochs: 365 w1: 0.9293127798000037 w2: 1.692664260000016 b: -2.3430328792997095 loss: 0.9536590098453394\n",
            "Epochs: 366 w1: 0.9548573184702638 w2: 1.8037274716098424 b: -2.5393054076898673 loss: 0.4984772740575951\n",
            "Epochs: 367 w1: 0.9880572199391066 w2: 2.0 b: -2.585239177154842 loss: 0.09636502878488365\n",
            "Epochs: 368 w1: 1.1384881822174069 w2: 2.2564595966989014 b: -2.3287795804559406 loss: 0.7193252423493888\n",
            "Epochs: 369 w1: 0.9849453868539053 w2: 2.0 b: -2.386681938710151 loss: 0.12307733181415212\n",
            "Epochs: 370 w1: 1.1183942374817817 w2: 2.2367884749635634 b: -2.149893463746588 loss: 0.6416501117973437\n",
            "Epochs: 371 w1: 1.0825977855489208 w2: 2.1757399692530233 b: -1.9741534944935646 loss: 0.4330623404782882\n",
            "Epochs: 372 w1: 1.0880881504899236 w2: 2.151876121534351 b: -1.8222773729592137 loss: 0.3620497093884927\n",
            "Epochs: 373 w1: 0.9262809788033824 w2: 1.6794825165364455 b: -2.142794856422768 loss: 1.0245302961488023\n",
            "Epochs: 374 w1: 1.1151143610700673 w2: 2.2558096912668164 b: -1.886985165155952 loss: 0.7166602233103867\n",
            "Epochs: 375 w1: 1.074164668963236 w2: 2.137341979561548 b: -1.7496431855944037 loss: 0.3211478006614059\n",
            "Epochs: 376 w1: 1.0773836243559511 w2: 2.1334200419930194 b: -1.6162231436013843 loss: 0.31039143443198897\n",
            "Epochs: 377 w1: 0.9215197165701672 w2: 1.6587813763920312 b: -1.9574417672093531 loss: 1.1470798336149237\n",
            "Epochs: 378 w1: 1.114890909334074 w2: 2.229781818668148 b: -1.7276599485412052 loss: 0.6153783867370153\n",
            "Epochs: 379 w1: 1.1012293521758738 w2: 2.0 b: -1.3227425398377095 loss: 1.6598622024468828\n",
            "Epochs: 380 w1: 1.0531781466658137 w2: 2.118173659257364 b: -1.2045688805803456 loss: 0.269642198565742\n",
            "Epochs: 381 w1: 0.9324230610422418 w2: 1.6245725613457878 b: -1.5799963192345579 loss: 1.3897197302377213\n",
            "Epochs: 382 w1: 1.093752217850355 w2: 2.18750443570071 b: -1.392491883533848 loss: 0.4700178235887466\n",
            "Epochs: 383 w1: 1.0486735612493596 w2: 2.1081634694430216 b: -1.2843284140908264 loss: 0.24376335949145883\n",
            "Epochs: 384 w1: 0.9339824852986528 w2: 1.6332360294369597 b: -1.6510923846538668 loss: 1.3224858856236041\n",
            "Epochs: 385 w1: 1.0973916184979096 w2: 2.194783236995819 b: -1.4563091476580474 loss: 0.4935858758669145\n",
            "Epochs: 386 w1: 1.057505883433994 w2: 2.102689077560704 b: -1.3536200700973435 loss: 0.22988894431253495\n",
            "Epochs: 387 w1: 1.0606176648557113 w2: 2.0993732210749365 b: -1.2542468490224072 loss: 0.22157783038254197\n",
            "Epochs: 388 w1: 0.9754233757533946 w2: 2.0 b: -1.3835975029519096 loss: 0.29935164159864636\n",
            "Epochs: 389 w1: 0.9779805541943623 w2: 2.0 b: -1.499489322981582 loss: 0.26368386683699085\n",
            "Epochs: 390 w1: 0.9403329134918298 w2: 1.6685161860657212 b: -1.8309731369158608 loss: 1.087576293505999\n",
            "Epochs: 391 w1: 1.1059184801818083 w2: 2.2118369603636165 b: -1.6191361765522445 loss: 0.551081668617422\n",
            "Epochs: 392 w1: 1.2166710988367442 w2: 2.0 b: -1.258017678491004 loss: 1.2809870329174233\n",
            "Epochs: 393 w1: 0.9093728527334881 w2: 2.0 b: -1.4323006540035268 loss: 0.4285791170501859\n",
            "Epochs: 394 w1: 1.0703481155308996 w2: 2.1279056646016357 b: -1.3043949894018911 loss: 0.2954606865169495\n",
            "Epochs: 395 w1: 0.9097065559537654 w2: 2.0 b: -1.4685648876677722 loss: 0.3980027159436951\n",
            "Epochs: 396 w1: 0.9038193423337295 w2: 1.656497651191891 b: -1.8120672364758812 loss: 1.1615670969131346\n",
            "Epochs: 397 w1: 1.1066131056111135 w2: 2.213226211222227 b: -1.5988410252536545 loss: 0.5559143858614669\n",
            "Epochs: 398 w1: 0.9189804242425549 w2: 1.64774097496763 b: -1.9511000502860245 loss: 1.2191475271310435\n",
            "Epochs: 399 w1: 0.9503943584207506 w2: 1.7637826591464312 b: -2.1873173911395933 loss: 0.6394825951501333\n",
            "Epochs: 400 w1: 1.13068681040128 w2: 2.237612382547782 b: -1.9497050085918115 loss: 0.6447852320533042\n",
            "Epochs: 401 w1: 1.071887877964081 w2: 2.1529529318384704 b: -1.7967520767533411 loss: 0.36514768455722835\n",
            "Epochs: 402 w1: 1.069875327665024 w2: 2.1486709099255825 b: -1.6480811668277584 loss: 0.35288473564897593\n",
            "Epochs: 403 w1: 0.9219781662955546 w2: 1.6607746360676288 b: -1.9873065307601294 loss: 1.134604490016771\n",
            "Epochs: 404 w1: 1.1267554148533392 w2: 2.2263489550952484 b: -1.7609575756648808 loss: 0.6027543624410479\n",
            "Epochs: 405 w1: 0.933424594565652 w2: 2.0 b: -1.8820037673636953 loss: 0.2771937786007562\n",
            "Epochs: 406 w1: 1.0894624705379248 w2: 2.1789249410758496 b: -1.7030788262878458 loss: 0.44293317420163647\n",
            "Epochs: 407 w1: 0.9315209739919216 w2: 2.0 b: -1.8275861463025338 loss: 0.28636912145511906\n",
            "Epochs: 408 w1: 1.2341546797090364 w2: 2.0 b: -1.4373283467874731 loss: 1.5164741151886851\n",
            "Epochs: 409 w1: 1.0587743327380428 w2: 2.1175486654760856 b: -1.3197796813113878 loss: 0.2680066832528622\n",
            "Epochs: 410 w1: 0.9228255947134205 w2: 1.6325028319686692 b: -1.6872768493427186 loss: 1.3280040798758745\n",
            "Epochs: 411 w1: 1.1145663581109153 w2: 2.187813701821173 b: -1.4994631475215459 loss: 0.4710079792641595\n",
            "Epochs: 412 w1: 1.0623435793201004 w2: 2.1005541601937106 b: -1.3989089873278355 loss: 0.22452991235300745\n",
            "Epochs: 413 w1: 1.0628066828293852 w2: 2.1029617751301397 b: -1.2959472121976958 loss: 0.23057553806308495\n",
            "Epochs: 414 w1: 1.0581430598245407 w2: 2.0937791287492593 b: -1.2021680834484365 loss: 0.20771106888556087\n",
            "Epochs: 415 w1: 1.0507620641743138 w2: 2.0940038225450257 b: -1.1081642609034108 loss: 0.20826435400031307\n",
            "Epochs: 416 w1: 0.9606625155254924 w2: 2.0 b: -1.2594622781130551 loss: 0.36039045852114737\n",
            "Epochs: 417 w1: 0.9652847326690994 w2: 2.0 b: -1.3929825370780573 loss: 0.3106648554718804\n",
            "Epochs: 418 w1: 1.0688514896179513 w2: 2.1187094648585365 b: -1.2742730722195206 loss: 0.271046454469793\n",
            "Epochs: 419 w1: 1.0485027270410596 w2: 2.103197291576723 b: -1.1710757806427978 loss: 0.23116889737126775\n",
            "Epochs: 420 w1: 0.8917708318593431 w2: 1.613467256640511 b: -1.5576085240022866 loss: 1.4830937908701303\n",
            "Epochs: 421 w1: 1.1045522773885081 w2: 2.1802625472215658 b: -1.3773459767807208 loss: 0.44710789945738616\n",
            "Epochs: 422 w1: 1.0571210142654088 w2: 2.092130668170014 b: -1.2852153086107068 loss: 0.20366124043644057\n",
            "Epochs: 423 w1: 1.0918943371039567 w2: 2.0 b: -0.9176379601948803 loss: 1.3286093850799536\n",
            "Epochs: 424 w1: 1.0410155285995322 w2: 2.0820310571990643 b: -0.835606902995816 loss: 0.17920096817707398\n",
            "Epochs: 425 w1: 1.0799996796266413 w2: 2.0 b: -0.5156081844892505 loss: 1.0216441281493545\n",
            "Epochs: 426 w1: 0.8800853125012893 w2: 1.571733258933176 b: -0.9438749255560746 loss: 1.9416535959801244\n",
            "Epochs: 427 w1: 1.0545826245577121 w2: 2.1364565613942803 b: -0.807418364161794 loss: 0.3187093076096953\n",
            "Epochs: 428 w1: 1.1630669542428458 w2: 2.0 b: -0.5356401070903843 loss: 0.7842903853902661\n",
            "Epochs: 429 w1: 1.0311481969375835 w2: 2.0510626179304645 b: -0.48457748915991966 loss: 0.10772468127514057\n",
            "Epochs: 430 w1: 1.0261084238558817 w2: 2.0580187196797373 b: -0.4265587694801824 loss: 0.12334056945797421\n",
            "Epochs: 431 w1: 1.0229746131671908 w2: 2.057436532917977 b: -0.3691222365622054 loss: 0.12202421582513169\n",
            "Epochs: 432 w1: 1.1317412995220189 w2: 2.0 b: -0.14955340402550726 loss: 0.5782797958607485\n",
            "Epochs: 433 w1: 1.0181725967699624 w2: 2.0454314919249064 b: -0.10412191210060101 loss: 0.09525946332522099\n",
            "Epochs: 434 w1: 0.9297915940606819 w2: 2.0 b: -0.3741542426364398 loss: 0.7766693669266652\n",
            "Epochs: 435 w1: 1.027173814130134 w2: 2.055456763530886 b: -0.31869747910555396 loss: 0.1175607783018724\n",
            "Epochs: 436 w1: 0.9554302177937334 w2: 2.0 b: -0.5532752801911676 loss: 0.6332863367876727\n",
            "Epochs: 437 w1: 0.9612286201020734 w2: 2.0 b: -0.757335174390781 loss: 0.5244510098416617\n",
            "Epochs: 438 w1: 1.0399783162882892 w2: 2.0726878477968893 b: -0.6846473265938917 loss: 0.1570933166654665\n",
            "Epochs: 439 w1: 0.9082205893377562 w2: 1.5828208606261647 b: -1.101826465967727 loss: 1.7979281288329865\n",
            "Epochs: 440 w1: 1.1907200781091474 w2: 2.0 b: -0.7839596691191483 loss: 1.009869793595573\n",
            "Epochs: 441 w1: 0.9061526221062881 w2: 1.5919679222012528 b: -1.1919917469178956 loss: 1.6931682538987842\n",
            "Epochs: 442 w1: 1.0805077667324803 w2: 2.1437638691651433 b: -1.0482278777527523 loss: 0.3390142985870378\n",
            "Epochs: 443 w1: 0.8931838507898069 w2: 2.0 b: -1.2424390581349216 loss: 0.49171336668837373\n",
            "Epochs: 444 w1: 1.063306663307723 w2: 2.1091494194960743 b: -1.1332896386388476 loss: 0.24628275852240006\n",
            "Epochs: 445 w1: 1.050199456974749 w2: 2.082294191761884 b: -1.0509954468769638 loss: 0.17983072172937098\n",
            "Epochs: 446 w1: 0.902138135956857 w2: 2.0 b: -1.2391913392676233 loss: 0.4722329680259559\n",
            "Epochs: 447 w1: 0.9651559676036828 w2: 2.0 b: -1.373206848484228 loss: 0.3120171408274232\n",
            "Epochs: 448 w1: 1.0657520564765466 w2: 2.119549193593721 b: -1.2536576548905067 loss: 0.2732512161901864\n",
            "Epochs: 449 w1: 1.0477374664502646 w2: 2.1015690775537545 b: -1.1520885773367522 loss: 0.22707395914181794\n",
            "Epochs: 450 w1: 0.8913517140413278 w2: 1.6119704072904568 b: -1.5401181700462954 loss: 1.4963734826604367\n",
            "Epochs: 451 w1: 0.980762797573978 w2: 2.0 b: -1.6413666038674637 loss: 0.22626951660964292\n",
            "Epochs: 452 w1: 0.9432380542592125 w2: 1.6846558569956245 b: -1.9567107468718392 loss: 0.9961142381811003\n",
            "Epochs: 453 w1: 1.1039439284908252 w2: 2.2309865077573896 b: -1.7257242391144496 loss: 0.6198465630424481\n",
            "Epochs: 454 w1: 0.9397838921005681 w2: 1.6654660672253785 b: -2.060258171889071 loss: 1.1058419564978068\n",
            "Epochs: 455 w1: 0.9874415872805506 w2: 2.0 b: -2.1263550809388048 loss: 0.14178688199664402\n",
            "Epochs: 456 w1: 1.1008339119623214 w2: 2.205783493800656 b: -1.9205715871381486 loss: 0.5302921864604359\n",
            "Epochs: 457 w1: 0.9098182594238824 w2: 1.6779223550852942 b: -2.2426492320528544 loss: 1.0332608506822125\n",
            "Epochs: 458 w1: 0.959017445483458 w2: 2.0 b: -2.317162967537476 loss: 0.16137543173972146\n",
            "Epochs: 459 w1: 1.1060722958196363 w2: 2.235716212932525 b: -2.081446754604951 loss: 0.637584621608844\n",
            "Epochs: 460 w1: 1.0874720121930521 w2: 2.1590400221691857 b: -1.9224067324357652 loss: 0.382842995091789\n",
            "Epochs: 461 w1: 1.0733666632463121 w2: 2.1630370294362495 b: -1.759369702999516 loss: 0.3946350537398267\n",
            "Epochs: 462 w1: 1.0606016309778135 w2: 2.151504077444534 b: -1.607865625554982 loss: 0.3609815682743738\n",
            "Epochs: 463 w1: 1.0679744253840278 w2: 2.121382902471478 b: -1.4864827230835038 loss: 0.2780827007920502\n",
            "Epochs: 464 w1: 0.979390362359608 w2: 2.0 b: -1.5949545001381988 loss: 0.24455049632960152\n",
            "Epochs: 465 w1: 1.0818788835927005 w2: 2.13422767802082 b: -1.4607268221173786 loss: 0.3125970296824654\n",
            "Epochs: 466 w1: 1.0620595204544092 w2: 2.106999173197257 b: -1.3537276489201213 loss: 0.2407963827313704\n",
            "Epochs: 467 w1: 1.0602793467833775 w2: 2.0988186012842256 b: -1.254909047635896 loss: 0.22019440752746902\n",
            "Epochs: 468 w1: 1.0473953735815 w2: 2.1053230524033335 b: -1.1495859952325627 loss: 0.23654052233192044\n",
            "Epochs: 469 w1: 1.0488756997983926 w2: 2.08886490872435 b: -1.0607210865082126 loss: 0.19568624869727158\n",
            "Epochs: 470 w1: 1.0464308444141568 w2: 2.082912222168137 b: -0.9778088643400755 loss: 0.18131140037731658\n",
            "Epochs: 471 w1: 1.1759816622205286 w2: 2.0 b: -0.6845060939725279 loss: 0.8833530346668017\n",
            "Epochs: 472 w1: 0.9632604485159709 w2: 2.0 b: -0.8778721544147863 loss: 0.48895344157552645\n",
            "Epochs: 473 w1: 0.9087941790400627 w2: 1.6034529523480985 b: -1.2744192020666878 loss: 1.5754911557485618\n",
            "Epochs: 474 w1: 0.9763058165390419 w2: 2.0 b: -1.3991254308085725 loss: 0.28689898911994205\n",
            "Epochs: 475 w1: 1.0667470791540667 w2: 2.1213583257346666 b: -1.2777671050739057 loss: 0.2780177910472301\n",
            "Epochs: 476 w1: 1.050374228742278 w2: 2.100748457484556 b: -1.1770186475893498 loss: 0.22501644780179897\n",
            "Epochs: 477 w1: 0.8919644844820003 w2: 1.614158873150001 b: -1.5628597744393489 loss: 1.4770169960976935\n",
            "Epochs: 478 w1: 1.0998532356207178 w2: 2.1849133992976255 b: -1.3779463751417234 loss: 0.4617605745162435\n",
            "Epochs: 479 w1: 1.0493900654879769 w2: 2.1050852457191 b: -1.2728611294226235 loss: 0.2359381687589073\n",
            "Epochs: 480 w1: 0.922166324864904 w2: 1.6293634517376383 b: -1.6434976776849852 loss: 1.3519822003179396\n",
            "Epochs: 481 w1: 1.0902498374365504 w2: 2.2005551943034454 b: -1.44294248338154 loss: 0.5126779860082519\n",
            "Epochs: 482 w1: 1.0501766936155452 w2: 2.1115037635901004 b: -1.3314387197914397 loss: 0.2523246161520197\n",
            "Epochs: 483 w1: 1.0513788487414697 w2: 2.109316699449936 b: -1.222122020341504 loss: 0.24671083965994609\n",
            "Epochs: 484 w1: 0.9123052174683128 w2: 2.0 b: -1.3907658329024408 loss: 0.41141420663823947\n",
            "Epochs: 485 w1: 0.9198879196249556 w2: 2.0 b: -1.536424160857067 loss: 0.34434647550115927\n",
            "Epochs: 486 w1: 0.9806225647440201 w2: 2.0 b: -1.6384106622043297 loss: 0.2281221774999882\n",
            "Epochs: 487 w1: 0.9084559970030334 w2: 1.6730571321536907 b: -1.965353530050639 loss: 1.0609863147798968\n",
            "Epochs: 488 w1: 1.10595378330893 w2: 2.235452851797622 b: -1.7299006782530169 loss: 0.636588608935945\n",
            "Epochs: 489 w1: 0.9029491195508429 w2: 1.6533897126815817 b: -2.076510965571435 loss: 1.181626273787458\n",
            "Epochs: 490 w1: 1.1342261590966278 w2: 2.239689569815407 b: -1.8368213957560282 loss: 0.6527332173643128\n",
            "Epochs: 491 w1: 1.0770662641369961 w2: 2.124300426027413 b: -1.712520969728615 loss: 0.28581827979929475\n",
            "Epochs: 492 w1: 1.2231667185953592 w2: 2.0 b: -1.3405764387363495 loss: 1.3621445767493447\n",
            "Epochs: 493 w1: 1.1941546820353306 w2: 2.0 b: -1.0169853020107986 loss: 1.0418037107917484\n",
            "Epochs: 494 w1: 1.037672773456752 w2: 2.0941819336418797 b: -0.9228033683689187 loss: 0.20870315167125653\n",
            "Epochs: 495 w1: 0.9554994515436563 w2: 2.0 b: -1.0939593239702405 loss: 0.41902448922751995\n",
            "Epochs: 496 w1: 0.9328491003263931 w2: 1.6269394462577398 b: -1.4670198777125008 loss: 1.370897926789559\n",
            "Epochs: 497 w1: 0.9291480908482509 w2: 2.0 b: -1.6032735491581722 loss: 0.3181513733088607\n",
            "Epochs: 498 w1: 1.0817171954272857 w2: 2.140891716253941 b: -1.462381832904231 loss: 0.3309841293803096\n",
            "Epochs: 499 w1: 0.9252280934608106 w2: 1.6439433021943362 b: -1.818438530709895 loss: 1.2451886111416297\n",
            "Epochs: 500 w1: 0.9270418604872931 w2: 1.7394352160260467 b: -2.079003314683848 loss: 0.7363252149217901\n",
            "Epochs: 501 w1: 0.9876704710163648 w2: 2.0 b: -2.143895572492454 loss: 0.13901441480331994\n",
            "Epochs: 502 w1: 0.9828952062558647 w2: 2.0 b: -2.2096832407391283 loss: 0.14107444029119365\n",
            "Epochs: 503 w1: 0.9838665230784313 w2: 2.0 b: -2.271735075052854 loss: 0.13250753823087486\n",
            "Epochs: 504 w1: 0.9438063411974383 w2: 1.7556797443366887 b: -2.5160553307161657 loss: 0.6706824357795104\n",
            "Epochs: 505 w1: 0.9679129901766004 w2: 1.8217388343144463 b: -2.6943164964017194 loss: 0.4408679555335218\n",
            "Epochs: 506 w1: 1.1238050265359985 w2: 2.3095125663399965 b: -2.384803930061723 loss: 0.9650218710705759\n",
            "Epochs: 507 w1: 1.2540711510953442 w2: 2.0 b: -1.9613520115694827 loss: 1.876689038582134\n",
            "Epochs: 508 w1: 0.9396321319592507 w2: 1.7125339617107178 b: -2.248818049858765 loss: 0.8555063030124042\n",
            "Epochs: 509 w1: 1.1188747057777244 w2: 2.2641660128393872 b: -1.9846520370193779 loss: 0.7514799851642601\n",
            "Epochs: 510 w1: 0.9342851666807536 w2: 1.6870722222893024 b: -2.297579814730075 loss: 0.9831133406787795\n",
            "Epochs: 511 w1: 0.9559867926778751 w2: 1.7999399667176141 b: -2.497639848012461 loss: 0.5110257547321428\n",
            "Epochs: 512 w1: 1.1513394146137041 w2: 2.270248954667329 b: -2.2273908933451323 loss: 0.777611787326577\n",
            "Epochs: 513 w1: 1.0936783027349881 w2: 2.1672826834553356 b: -2.0601082098897967 loss: 0.40731486822604573\n",
            "Epochs: 514 w1: 1.0935756044091378 w2: 2.161337248981272 b: -1.8987709609085248 loss: 0.38960332097128875\n",
            "Epochs: 515 w1: 1.082382016355174 w2: 2.1471107434913823 b: -1.7516602174171423 loss: 0.34845381164836375\n",
            "Epochs: 516 w1: 1.0793798530023124 w2: 2.128032020971472 b: -1.6236281964456705 loss: 0.29580032573425913\n",
            "Epochs: 517 w1: 1.0732224327436453 w2: 2.1181006979736217 b: -1.505527498472049 loss: 0.2694511318269069\n",
            "Epochs: 518 w1: 1.0563804175636753 w2: 2.1252898168081673 b: -1.380237681663882 loss: 0.28845521607207897\n",
            "Epochs: 519 w1: 1.0941590629156923 w2: 2.0 b: -1.0036014300011122 loss: 1.3994708037151142\n",
            "Epochs: 520 w1: 0.9188194728251983 w2: 1.6134260610723727 b: -1.3901753689287395 loss: 1.4834569180790431\n",
            "Epochs: 521 w1: 0.9687668574656781 w2: 2.0 b: -1.5103028402145928 loss: 0.27477235273019496\n",
            "Epochs: 522 w1: 0.9405842293656251 w2: 1.6699123853645839 b: -1.840390454850009 loss: 1.0793251744342889\n",
            "Epochs: 523 w1: 0.984844015457352 w2: 2.0 b: -1.9201587945481562 loss: 0.17380196705751405\n",
            "Epochs: 524 w1: 1.1025191261040437 w2: 2.16806414115417 b: -1.752094653393986 loss: 0.4096663444180024\n",
            "Epochs: 525 w1: 0.9275178452886297 w2: 1.6705356604028625 b: -2.081558992991124 loss: 1.0756636716448875\n",
            "Epochs: 526 w1: 1.135809403583726 w2: 2.2341541441098722 b: -1.8474048488812513 loss: 0.6316914467440738\n",
            "Epochs: 527 w1: 0.9424027167413693 w2: 2.0 b: -1.9581688551478487 loss: 0.25042227105707604\n",
            "Epochs: 528 w1: 1.093620726370707 w2: 2.187241452741414 b: -1.7709274024064348 loss: 0.4691766200846275\n",
            "Epochs: 529 w1: 0.9348368402544653 w2: 2.0 b: -1.8894058746710432 loss: 0.2704408201013022\n",
            "Epochs: 530 w1: 1.2371779099557867 w2: 2.0 b: -1.4941093580780653 loss: 1.5634757107359938\n",
            "Epochs: 531 w1: 1.0606321430844514 w2: 2.1237390675192884 b: -1.370370290558777 loss: 0.28432522635409596\n",
            "Epochs: 532 w1: 1.060316764021117 w2: 2.0988799410182244 b: -1.2714903495405523 loss: 0.2203473169695003\n",
            "Epochs: 533 w1: 1.055441647904631 w2: 2.0955890481114325 b: -1.1759013014291195 loss: 0.21217652982119842\n",
            "Epochs: 534 w1: 1.0515399776947976 w2: 2.0888620305082717 b: -1.0870392709208478 loss: 0.1956792480639888\n",
            "Epochs: 535 w1: 0.9600749699626978 w2: 2.0 b: -1.2405970787566254 loss: 0.3668921272913913\n",
            "Epochs: 536 w1: 1.0588377377870628 w2: 2.108958773679746 b: -1.1316383050768797 loss: 0.24579510583582\n",
            "Epochs: 537 w1: 1.0448350725974311 w2: 2.0915001481580227 b: -1.040138156918857 loss: 0.20211654681013788\n",
            "Epochs: 538 w1: 1.085681165856216 w2: 2.0 b: -0.6974134934939935 loss: 1.1566100929261915\n",
            "Epochs: 539 w1: 1.0337352070559835 w2: 2.068847361338742 b: -0.6285661321552516 loss: 0.14814592098864132\n",
            "Epochs: 540 w1: 1.03222738556437 w2: 2.0596803436377225 b: -0.5688857885175294 loss: 0.12710714354481206\n",
            "Epochs: 541 w1: 1.032903830926712 w2: 2.0530706950430835 b: -0.5158150934744457 loss: 0.11220767077515835\n",
            "Epochs: 542 w1: 1.0313305610467767 w2: 2.051361575486519 b: -0.4644535179879266 loss: 0.10839082571646107\n",
            "Epochs: 543 w1: 1.0288367329039672 w2: 2.0514941658999413 b: -0.41295935208798523 loss: 0.10868640898105802\n",
            "Epochs: 544 w1: 0.9225088706440682 w2: 1.569493725800379 b: -0.8434656262876064 loss: 1.973371626180132\n",
            "Epochs: 545 w1: 1.0561035836435546 w2: 2.11936932690118 b: -0.7240962993864262 loss: 0.27277855537598145\n",
            "Epochs: 546 w1: 0.8723309007749207 w2: 2.0 b: -0.9562219343411157 loss: 0.6240900149707448\n",
            "Epochs: 547 w1: 0.9147705638190803 w2: 1.6125934719049104 b: -1.3436284624362052 loss: 1.4908243603749782\n",
            "Epochs: 548 w1: 1.0869075421380057 w2: 2.158013712978192 b: -1.1856147494580132 loss: 0.37983745859093165\n",
            "Epochs: 549 w1: 1.0477804307112542 w2: 2.0853221976986682 b: -1.100292551759345 loss: 0.1871062597273166\n",
            "Epochs: 550 w1: 1.0872646318146029 w2: 2.0 b: -0.7512340245009331 loss: 1.1977159344805128\n",
            "Epochs: 551 w1: 1.0353081382608835 w2: 2.0720574250222112 b: -0.6791765994787218 loss: 0.15561908245472011\n",
            "Epochs: 552 w1: 0.9124874965855655 w2: 1.5832737932645977 b: -1.095902806214124 loss: 1.7924742054159488\n",
            "Epochs: 553 w1: 1.0801745939841012 w2: 2.1293138612646794 b: -0.9665889449494447 loss: 0.2992523811002419\n",
            "Epochs: 554 w1: 1.0408347015895592 w2: 2.0729191099813558 b: -0.8936698349680889 loss: 0.15763466515190253\n",
            "Epochs: 555 w1: 1.0417429758937315 w2: 2.0719706480926403 b: -0.8216991868754485 loss: 0.1554163259690396\n",
            "Epochs: 556 w1: 0.9146443403185601 w2: 1.593544477707429 b: -1.2281547091680194 loss: 1.6761710778300345\n",
            "Epochs: 557 w1: 1.0752471516287896 w2: 2.1535656155689584 b: -1.074589093599061 loss: 0.3669146644457557\n",
            "Epochs: 558 w1: 1.0446957873581044 w2: 2.077061702341559 b: -0.9975273912575016 loss: 0.16738179843550846\n",
            "Epochs: 559 w1: 1.0845247426029063 w2: 2.0 b: -0.6594284208458767 loss: 1.1276228783494644\n",
            "Epochs: 560 w1: 1.0289996590783708 w2: 2.072499147695927 b: -0.5869292731499498 loss: 0.15665181635362616\n",
            "Epochs: 561 w1: 1.029468641722527 w2: 2.060140085148014 b: -0.5267891880019357 loss: 0.12815179753846762\n",
            "Epochs: 562 w1: 1.0250168879073565 w2: 2.062542219768391 b: -0.46424696823354467 loss: 0.13362789960892288\n",
            "Epochs: 563 w1: 0.8784493808937447 w2: 1.5658906460490882 b: -0.8983563221844564 loss: 2.026611608580376\n",
            "Epochs: 564 w1: 1.0668540133607125 w2: 2.1193821667155577 b: -0.7789741554688985 loss: 0.27281228894464205\n",
            "Epochs: 565 w1: 1.0781670342992995 w2: 2.0 b: -0.4663060182717008 loss: 0.9817263870345253\n",
            "Epochs: 566 w1: 1.029041362577237 w2: 2.0537803010689575 b: -0.41252571720274334 loss: 0.11379666918884465\n",
            "Epochs: 567 w1: 1.0250744392565843 w2: 2.05334987075869 b: -0.35917584644405326 loss: 0.11283251891737237\n",
            "Epochs: 568 w1: 0.8484815875807414 w2: 2.0 b: -0.6346638690245232 loss: 0.8006790411283705\n",
            "Epochs: 569 w1: 0.883460522262488 w2: 1.5837875795088856 b: -1.0508762895156376 loss: 1.7863233178036342\n",
            "Epochs: 570 w1: 1.0583749795160016 w2: 2.145937448790004 b: -0.9049388407256337 loss: 0.3451345025644068\n",
            "Epochs: 571 w1: 0.9548165950014946 w2: 2.0 b: -1.078721167642962 loss: 0.42704323103130243\n",
            "Epochs: 572 w1: 1.0518478287784945 w2: 2.0960144977379525 b: -0.9827066699050093 loss: 0.21322910659492314\n",
            "Epochs: 573 w1: 1.0406424066634596 w2: 2.0812848133269193 b: -0.9014218565780902 loss: 0.1774171550420201\n",
            "Epochs: 574 w1: 1.0406361665301156 w2: 2.0738839391456647 b: -0.8275379174324253 loss: 0.15989634593872779\n",
            "Epochs: 575 w1: 1.0406313678790586 w2: 2.0655344643210625 b: -0.762003453111363 loss: 0.1404914763588185\n",
            "Epochs: 576 w1: 1.0374991220649283 w2: 2.064653658732635 b: -0.6973497943787279 loss: 0.138466197300569\n",
            "Epochs: 577 w1: 0.8802390149257656 w2: 2.0 b: -0.9276593810599479 loss: 0.6173334146302591\n",
            "Epochs: 578 w1: 1.050839751128067 w2: 2.0833438543083065 b: -0.8443155267516416 loss: 0.182346807452685\n",
            "Epochs: 579 w1: 0.8848523386461828 w2: 1.588758352307796 b: -1.2555571744438456 loss: 1.7286905639844055\n",
            "Epochs: 580 w1: 0.9308115530605943 w2: 1.6855070593663375 b: -1.5700501150775081 loss: 0.9915151612155877\n",
            "Epochs: 581 w1: 0.9811046865293119 w2: 2.0 b: -1.6694991333442875 loss: 0.22176704480109166\n",
            "Epochs: 582 w1: 1.0732779150286818 w2: 2.155910457507834 b: -1.5135886758364538 loss: 0.37370617697808095\n",
            "Epochs: 583 w1: 1.0620736554338412 w2: 2.112861191697893 b: -1.4007274841385606 loss: 0.25582479191868723\n",
            "Epochs: 584 w1: 1.0553051884162503 w2: 2.1128677314617357 b: -1.287859752676825 loss: 0.2558416846169634\n",
            "Epochs: 585 w1: 1.197419067261475 w2: 2.0 b: -0.9588279739076999 loss: 1.0731303999451822\n",
            "Epochs: 586 w1: 1.0445974194430414 w2: 2.071931321682325 b: -0.8868966522253752 loss: 0.15532445235420847\n",
            "Epochs: 587 w1: 0.9281912996495887 w2: 1.6010627758310485 b: -1.2858338763943267 loss: 1.5988662317770415\n",
            "Epochs: 588 w1: 1.0786163698537468 w2: 2.1572327397074935 b: -1.1286011366868332 loss: 0.37755642299093645\n",
            "Epochs: 589 w1: 1.0426435884079241 w2: 2.087027731444743 b: -1.04157340524209 loss: 0.1912276540708868\n",
            "Epochs: 590 w1: 0.8891114394929797 w2: 1.6039694267606417 b: -1.437603978481448 loss: 1.5705112159548529\n",
            "Epochs: 591 w1: 0.9288036498372672 w2: 2.0 b: -1.5745200364867036 loss: 0.3199740457257975\n",
            "Epochs: 592 w1: 1.0717984147371524 w2: 2.1465273770145967 b: -1.4279926594721066 loss: 0.34680206167047545\n",
            "Epochs: 593 w1: 1.0579470720088917 w2: 2.107309392609059 b: -1.3206832668630477 loss: 0.2415860551509016\n",
            "Epochs: 594 w1: 1.0573558390395283 w2: 2.098889377654359 b: -1.2217938892086886 loss: 0.2203708429611001\n",
            "Epochs: 595 w1: 1.047461976057603 w2: 2.100982927782134 b: -1.1208109614265547 loss: 0.22560389493423885\n",
            "Epochs: 596 w1: 1.047899956151716 w2: 2.0870908293667565 b: -1.0337201320597984 loss: 0.19138045547588728\n",
            "Epochs: 597 w1: 1.0854872852818833 w2: 2.0 b: -0.6917709909322652 loss: 1.151691225593319\n",
            "Epochs: 598 w1: 1.0356168360449354 w2: 2.0647578837180642 b: -0.6270131072142009 loss: 0.13870563301792416\n",
            "Epochs: 599 w1: 0.9248169277686518 w2: 1.5823162653813982 b: -1.0446968418328026 loss: 1.8040393750125125\n",
            "Epochs: 600 w1: 1.0575004448089602 w2: 2.1437511120224007 b: -0.9009457298104019 loss: 0.33897848831059135\n",
            "Epochs: 601 w1: 0.9062196019306165 w2: 1.592259138828767 b: -1.3086865909816348 loss: 1.6900067545137623\n",
            "Epochs: 602 w1: 0.9451132787625226 w2: 1.6950737709029036 b: -1.6136128200787312 loss: 0.9412302990779263\n",
            "Epochs: 603 w1: 1.087309247535322 w2: 2.185764356458132 b: -1.4278484636205993 loss: 0.46446493682638756\n",
            "Epochs: 604 w1: 0.9228246643087932 w2: 2.0 b: -1.5762625707190738 loss: 0.3521540559942439\n",
            "Epochs: 605 w1: 1.0730279398926177 w2: 2.1460558797852354 b: -1.4302066909338387 loss: 0.34546905024909896\n",
            "Epochs: 606 w1: 1.0586174922668312 w2: 2.1065772586669658 b: -1.323629432266873 loss: 0.23972338698743173\n",
            "Epochs: 607 w1: 0.919242157185741 w2: 1.6329188962988226 b: -1.6907105359680503 loss: 1.3248689584699516\n",
            "Epochs: 608 w1: 1.1111704292248135 w2: 2.191673153835885 b: -1.4990373821321652 loss: 0.48344768926694465\n",
            "Epochs: 609 w1: 0.9171132854191691 w2: 1.639622980083344 b: -1.8594144020488212 loss: 1.275662307863745\n",
            "Epochs: 610 w1: 1.126847993855926 w2: 2.207947530911354 b: -1.6514668711374674 loss: 0.5376746236362365\n",
            "Epochs: 611 w1: 0.9239996616671919 w2: 1.6545439166690543 b: -1.9969229544684133 loss: 1.1741297921907095\n",
            "Epochs: 612 w1: 1.1277769458982774 w2: 2.2281731176754955 b: -1.7687498367929178 loss: 0.6094426967964038\n",
            "Epochs: 613 w1: 1.2246321661025832 w2: 2.0 b: -1.3943628932886125 loss: 1.3814018967996307\n",
            "Epochs: 614 w1: 1.0551859772227812 w2: 2.1174169728144276 b: -1.2769459204741846 loss: 0.2676624041732557\n",
            "Epochs: 615 w1: 1.0534964491413028 w2: 2.0972662711660055 b: -1.1796796493081794 loss: 0.21633247734510305\n",
            "Epochs: 616 w1: 0.9740661433665943 w2: 2.0 b: -1.3161736315892625 loss: 0.3188122466505267\n",
            "Epochs: 617 w1: 0.9367763712659588 w2: 1.6487576181442158 b: -1.6674160134450466 loss: 1.2122898408929699\n",
            "Epochs: 618 w1: 0.9516321786377921 w2: 1.7312898813210675 b: -1.936126132123979 loss: 0.7709362771323544\n",
            "Epochs: 619 w1: 1.1033265360612414 w2: 2.219843693747322 b: -1.716282438376657 loss: 0.5792604143923319\n",
            "Epochs: 620 w1: 1.0559826535205628 w2: 2.1399566338014067 b: -1.5763258045752504 loss: 0.3283836125642001\n",
            "Epochs: 621 w1: 0.9257994640278786 w2: 2.0 b: -1.7112358699791073 loss: 0.31446437903643065\n",
            "Epochs: 622 w1: 1.08831925564055 w2: 2.1522745786906032 b: -1.5589612912885038 loss: 0.36319494931309076\n",
            "Epochs: 623 w1: 1.0680721576081964 w2: 2.1097938025938654 b: -1.4491674886946386 loss: 0.2479327877192915\n",
            "Epochs: 624 w1: 1.06308422548298 w2: 2.1087659060051376 b: -1.3404015826895008 loss: 0.24530201172046895\n",
            "Epochs: 625 w1: 0.9195350746143486 w2: 1.6342503391561296 b: -1.706151243533371 loss: 1.3149018387337665\n",
            "Epochs: 626 w1: 1.0995796148563752 w2: 2.2032237037885207 b: -1.5029275397448503 loss: 0.5216294548348863\n",
            "Epochs: 627 w1: 1.0550256264293136 w2: 2.1122971967945174 b: -1.3906303429503326 loss: 0.25436902342457485\n",
            "Epochs: 628 w1: 1.0620343166668793 w2: 2.101695601093245 b: -1.288934741857088 loss: 0.22739156409082154\n",
            "Epochs: 629 w1: 0.9760452116228929 w2: 2.0 b: -1.4150125754208094 loss: 0.2905604337987314\n",
            "Epochs: 630 w1: 0.9785055139754513 w2: 2.0 b: -1.528141449234224 loss: 0.2565164681214486\n",
            "Epochs: 631 w1: 0.9715794775313111 w2: 2.0 b: -1.6374511510368732 loss: 0.24669292851654973\n",
            "Epochs: 632 w1: 1.0641128199448195 w2: 2.160282049862049 b: -1.477169101174824 loss: 0.38649238350377046\n",
            "Epochs: 633 w1: 0.969919778076881 w2: 2.0 b: -1.5928622624175894 loss: 0.2631668056487231\n",
            "Epochs: 634 w1: 1.0992740156834895 w2: 2.0 b: -1.1957661996836313 loss: 1.5808121932817212\n",
            "Epochs: 635 w1: 1.057212178969488 w2: 2.092277708015303 b: -1.1034884916683283 loss: 0.2040218126703591\n",
            "Epochs: 636 w1: 1.046896846844093 w2: 2.086846012674246 b: -1.016642478994082 loss: 0.19078772428501176\n",
            "Epochs: 637 w1: 1.1787767815746109 w2: 2.0 b: -0.7186811763697305 loss: 0.9061488482018228\n",
            "Epochs: 638 w1: 1.0351373178126706 w2: 2.062745210379769 b: -0.6559359659899615 loss: 0.13409203062068203\n",
            "Epochs: 639 w1: 1.0314896461228356 w2: 2.0642645839241545 b: -0.5916713820658072 loss: 0.13757288314015956\n",
            "Epochs: 640 w1: 1.0316458013899488 w2: 2.057537820708998 b: -0.5341335613568092 loss: 0.12225310815583008\n",
            "Epochs: 641 w1: 1.031743919100078 w2: 2.052039211639472 b: -0.4820943497173374 loss: 0.1099023958187927\n",
            "Epochs: 642 w1: 0.9100663153004027 w2: 1.5717443585733462 b: -0.9103499911439912 loss: 1.9414988730291136\n",
            "Epochs: 643 w1: 0.9189372666253924 w2: 1.6475533331538803 b: -1.262796657990111 loss: 1.220418407292594\n",
            "Epochs: 644 w1: 1.069838626720691 w2: 2.155196948268202 b: -1.107599709721909 loss: 0.37163470894154876\n",
            "Epochs: 645 w1: 1.0372206257270054 w2: 2.093051564317513 b: -1.0145481454043959 loss: 0.2059216146607391\n",
            "Epochs: 646 w1: 1.0443430793916837 w2: 2.080623780712152 b: -0.9339243646922437 loss: 0.17583968330769006\n",
            "Epochs: 647 w1: 1.04133163149497 w2: 2.0765400583240186 b: -0.8573843063682252 loss: 0.16614917752647212\n",
            "Epochs: 648 w1: 0.9277094439429828 w2: 1.598385799683238 b: -1.2589985066849871 loss: 1.6257116169402006\n",
            "Epochs: 649 w1: 0.9759660416115025 w2: 2.0 b: -1.385493024519185 loss: 0.2916754161369518\n",
            "Epochs: 650 w1: 1.062318408722398 w2: 2.124636817444796 b: -1.2608562070743887 loss: 0.2867140543186756\n",
            "Epochs: 651 w1: 1.0528274499849626 w2: 2.0943347321160046 b: -1.166521474958384 loss: 0.20907974221719383\n",
            "Epochs: 652 w1: 1.0529217425228954 w2: 2.0853576492304766 b: -1.0811638257279075 loss: 0.18719175513388236\n",
            "Epochs: 653 w1: 1.0429027073995059 w2: 2.0912823561691614 b: -0.9898814695587461 loss: 0.20158353816759012\n",
            "Epochs: 654 w1: 1.0445574154170978 w2: 2.0768231300294793 b: -0.9130583395292671 loss: 0.16681787445085478\n",
            "Epochs: 655 w1: 1.0390742168792406 w2: 2.0781484337584812 b: -0.8349099057707856 loss: 0.16995458502494268\n",
            "Epochs: 656 w1: 1.0381574123835062 w2: 2.0706618747842707 b: -0.7642480309865148 loss: 0.1523633192715278\n",
            "Epochs: 657 w1: 0.8845254961705925 w2: 2.0 b: -0.9863143845046062 loss: 0.5872256949403226\n",
            "Epochs: 658 w1: 1.053258464083663 w2: 2.087308957514202 b: -0.8990054269904042 loss: 0.19190886656167655\n",
            "Epochs: 659 w1: 0.9071964419381681 w2: 1.596506269296383 b: -1.3024991576940212 loss: 1.6450001253856064\n",
            "Epochs: 660 w1: 0.935024503584971 w2: 1.6905928742141478 b: -1.6119062834798736 loss: 0.9644684939757425\n",
            "Epochs: 661 w1: 0.936311253347472 w2: 2.0 b: -1.7343846424270428 loss: 0.28098020408399155\n",
            "Epochs: 662 w1: 0.9289327394221507 w2: 1.69101191053109 b: -2.043372731895953 loss: 0.9622723135182736\n",
            "Epochs: 663 w1: 1.0990394158265062 w2: 2.2475985395662654 b: -1.7957741923296875 loss: 0.6835871815843354\n",
            "Epochs: 664 w1: 0.9764784181957723 w2: 2.0 b: -1.88624181465364 loss: 0.19959213189067349\n",
            "Epochs: 665 w1: 1.1005674112488038 w2: 2.164864608604596 b: -1.7213772060490438 loss: 0.4000734948260045\n",
            "Epochs: 666 w1: 1.070625494366666 w2: 2.1307879525308633 b: -1.5905892535181807 loss: 0.30323696504436415\n",
            "Epochs: 667 w1: 1.0715377075702077 w2: 2.1153833993067863 b: -1.4752058542113942 loss: 0.2623611026701344\n",
            "Epochs: 668 w1: 1.0962280829207807 w2: 2.0 b: -1.0902935225282717 loss: 1.4689139272970562\n",
            "Epochs: 669 w1: 0.9323582917257542 w2: 1.624212731809746 b: -1.4660807907185258 loss: 1.392612423631202\n",
            "Epochs: 670 w1: 0.9155394070988333 w2: 1.698355025352976 b: -1.7677257653655498 loss: 0.924549615997691\n",
            "Epochs: 671 w1: 1.0852657848251255 w2: 2.2131644620628137 b: -1.5545613033027361 loss: 0.5556990854582983\n",
            "Epochs: 672 w1: 1.0609811478556526 w2: 2.1108748142830045 b: -1.4436864890197316 loss: 0.250706992392315\n",
            "Epochs: 673 w1: 0.9787132882931948 w2: 2.0 b: -1.5557218137923903 loss: 0.25369380617210613\n",
            "Epochs: 674 w1: 1.0705469671090002 w2: 2.1410939342180004 b: -1.41462787957439 loss: 0.33154739937495137\n",
            "Epochs: 675 w1: 0.9162547611443299 w2: 2.0 b: -1.566891950221063 loss: 0.3631647303974851\n",
            "Epochs: 676 w1: 0.9067752389301703 w2: 1.6670544247506083 b: -1.899837525470455 loss: 1.0962884423880062\n",
            "Epochs: 677 w1: 1.1112678635434772 w2: 2.2225357270869543 b: -1.6773017983835008 loss: 0.588915919783508\n",
            "Epochs: 678 w1: 1.1002627658162192 w2: 2.0 b: -1.2762507351186239 loss: 1.6200041719076193\n",
            "Epochs: 679 w1: 1.0581075862635987 w2: 2.1037635468992835 b: -1.1724871882193404 loss: 0.23259696157356033\n",
            "Epochs: 680 w1: 0.9739137382623438 w2: 2.0 b: -1.3097833026280568 loss: 0.32102133922881154\n",
            "Epochs: 681 w1: 1.062398935673645 w2: 2.113452610315718 b: -1.1963306923123387 loss: 0.2573536255325202\n",
            "Epochs: 682 w1: 1.0458764195006305 w2: 2.0976094031928305 b: -1.0987212891195082 loss: 0.21718484768511703\n",
            "Epochs: 683 w1: 0.9051685613628642 w2: 2.0 b: -1.2810894403447692 loss: 0.4537150945594258\n",
            "Epochs: 684 w1: 1.0628397879080653 w2: 2.1142541598328464 b: -1.166835280511923 loss: 0.25942939099039425\n",
            "Epochs: 685 w1: 1.0484008650469112 w2: 2.089631231568354 b: -1.077204048943569 loss: 0.19755190777416137\n",
            "Epochs: 686 w1: 1.0437468626363813 w2: 2.089279311502819 b: -0.9879247374407499 loss: 0.19669470498312694\n",
            "Epochs: 687 w1: 1.0459541880901584 w2: 2.074119658209933 b: -0.9138050792308172 loss: 0.16044967942593644\n",
            "Epochs: 688 w1: 0.9119273996075132 w2: 1.5996699982159692 b: -1.314135081014848 loss: 1.6127433873422032\n",
            "Epochs: 689 w1: 0.9115177815621783 w2: 1.6839920770077799 b: -1.6301430040070681 loss: 0.9997154014806305\n",
            "Epochs: 690 w1: 0.9349679574212331 w2: 1.71725198878797 b: -1.912891015219098 loss: 0.8335501799435853\n",
            "Epochs: 691 w1: 0.9419421638934375 w2: 1.7475746256236417 b: -2.1653163895954566 loss: 0.702896044189485\n",
            "Epochs: 692 w1: 1.1288679995596076 w2: 2.238644443628903 b: -1.9266719459665538 loss: 0.6487263332210452\n",
            "Epochs: 693 w1: 1.0707350009903374 w2: 2.150500002107101 b: -1.776171943859453 loss: 0.3581045427772272\n",
            "Epochs: 694 w1: 0.976241624268649 w2: 2.0 b: -1.8675503120569568 loss: 0.20181847617105175\n",
            "Epochs: 695 w1: 1.234827078430143 w2: 2.0 b: -1.4761718480067183 loss: 1.5267384053358202\n",
            "Epochs: 696 w1: 1.095335813891341 w2: 2.0 b: -1.094828592441354 loss: 1.4383732740490094\n",
            "Epochs: 697 w1: 1.0473912443318996 w2: 2.094782488663799 b: -1.000046103777555 loss: 0.21018411045580207\n",
            "Epochs: 698 w1: 1.0388751503616334 w2: 2.0863892230258516 b: -0.9136568807517034 loss: 0.18968271905353914\n",
            "Epochs: 699 w1: 0.9159227971031954 w2: 1.599632367158073 b: -1.3140245135936304 loss: 1.613121015156833\n",
            "Epochs: 700 w1: 0.9450323275985311 w2: 1.6946240422140617 b: -1.6194004713795687 loss: 0.9435383894667195\n",
            "Epochs: 701 w1: 1.0903034716142272 w2: 2.1842927992127086 b: -1.4351076721668603 loss: 0.4597928941627388\n",
            "Epochs: 702 w1: 1.0468198824789396 w2: 2.1170497061973492 b: -1.3180579659695113 loss: 0.2667028988579765\n",
            "Epochs: 703 w1: 0.9228519378367606 w2: 1.6326282754131456 b: -1.6854296905563657 loss: 1.3270578049926613\n",
            "Epochs: 704 w1: 1.115630096763861 w2: 2.1865001560707436 b: -1.4989295344856222 loss: 0.46680923618265285\n",
            "Epochs: 705 w1: 1.0552333009274957 w2: 2.1127210223010118 b: -1.3862085121846106 loss: 0.2554627924890614\n",
            "Epochs: 706 w1: 1.2039540846750827 w2: 2.0 b: -1.0462850377261395 loss: 1.1389561128954482\n",
            "Epochs: 707 w1: 0.9578175462017012 w2: 2.0 b: -1.2085252446426733 loss: 0.39227312693645555\n",
            "Epochs: 708 w1: 0.9076340239005356 w2: 2.0 b: -1.3764633830053359 loss: 0.40928681663008093\n",
            "Epochs: 709 w1: 0.9011123979309008 w2: 1.64682999261036 b: -1.7296333903949759 loss: 1.2253326937752094\n",
            "Epochs: 710 w1: 1.113615813562409 w2: 2.1958893337282914 b: -1.5337440566666842 loss: 0.4972164294716789\n",
            "Epochs: 711 w1: 0.9367117503925129 w2: 1.6483986132917379 b: -1.8853454433749464 loss: 1.2147061121278686\n",
            "Epochs: 712 w1: 0.9431181910954407 w2: 1.7526877873714812 b: -2.1326576560034654 loss: 0.682453413761473\n",
            "Epochs: 713 w1: 1.1174706484121981 w2: 2.2397360171677514 b: -1.892921638835714 loss: 0.6529116639083848\n",
            "Epochs: 714 w1: 1.0760631657593316 w2: 2.138296665016967 b: -1.7546249738187474 loss: 0.32378373920519926\n",
            "Epochs: 715 w1: 1.0745008336099684 w2: 2.137964506685127 b: -1.6166604671336207 loss: 0.3228658435716536\n",
            "Epochs: 716 w1: 1.055732555578177 w2: 2.1393313889454424 b: -1.4773290781881783 loss: 0.326648536604439\n",
            "Epochs: 717 w1: 1.0505388051468922 w2: 2.1263470128672304 b: -1.350982065320948 loss: 0.29128057361037996\n",
            "Epochs: 718 w1: 0.9348387158471335 w2: 1.6379928658174085 b: -1.7129891995035393 loss: 1.2874061115766213\n",
            "Epochs: 719 w1: 1.1018079664845875 w2: 2.0 b: -1.305757333565189 loss: 1.6845049005558244\n",
            "Epochs: 720 w1: 0.9762108182564797 w2: 2.0 b: -1.4309635532679272 loss: 0.288232142920107\n",
            "Epochs: 721 w1: 0.9208114280050363 w2: 1.6557018608914624 b: -1.7752616923764648 loss: 1.1666650678780517\n",
            "Epochs: 722 w1: 0.9427182965535778 w2: 1.7396286206980809 b: -2.035633071678384 loss: 0.73551778731939\n",
            "Epochs: 723 w1: 0.957838318145942 w2: 1.765768434144122 b: -2.269864637534262 loss: 0.6319827171181186\n",
            "Epochs: 724 w1: 1.1104940794242992 w2: 2.0 b: -1.827888319837065 loss: 2.1537568556483175\n",
            "Epochs: 725 w1: 1.085345517779379 w2: 2.158047255146998 b: -1.6698410646900668 loss: 0.37993554385078643\n",
            "Epochs: 726 w1: 1.0657284342475193 w2: 2.1314568684950386 b: -1.5383841961950282 loss: 0.30505034749573084\n",
            "Epochs: 727 w1: 0.9292648847055596 w2: 2.0 b: -1.6744132640689522 loss: 0.3175340907706693\n",
            "Epochs: 728 w1: 1.0831143400656145 w2: 2.151116981937481 b: -1.5232962821314713 loss: 0.3598714242070315\n",
            "Epochs: 729 w1: 0.9280156685069437 w2: 2.0 b: -1.6617276888488872 loss: 0.32415632853638254\n",
            "Epochs: 730 w1: 0.9388471298815174 w2: 2.0 b: -1.7793293621536614 loss: 0.26814529305152307\n",
            "Epochs: 731 w1: 0.9769601139558528 w2: 2.0 b: -1.8679443084773046 loss: 0.19507845225620984\n",
            "Epochs: 732 w1: 1.0811906826137656 w2: 2.1804237391417014 b: -1.6875205693356035 loss: 0.447612164953692\n",
            "Epochs: 733 w1: 0.9362923949410054 w2: 2.0 b: -1.8100351944490547 loss: 0.28107627250599126\n",
            "Epochs: 734 w1: 1.079146794725899 w2: 2.1758817660575533 b: -1.6341534283915014 loss: 0.4334997296213643\n",
            "Epochs: 735 w1: 1.054841181042486 w2: 2.137102952606215 b: -1.4970504757852863 loss: 0.32048892037904614\n",
            "Epochs: 736 w1: 1.0632933886555787 w2: 2.1130239083135334 b: -1.384026567471753 loss: 0.2562451858887272\n",
            "Epochs: 737 w1: 0.9677178618369012 w2: 2.0 b: -1.508188637329825 loss: 0.285450084811961\n",
            "Epochs: 738 w1: 0.9405453660363703 w2: 1.669696477979835 b: -1.83849215934999 loss: 1.0805966807884593\n",
            "Epochs: 739 w1: 1.0896659014626908 w2: 2.224164753656727 b: -1.6143274056932633 loss: 0.5948043444796655\n",
            "Epochs: 740 w1: 1.0577263726661807 w2: 2.122822069502512 b: -1.491505336190751 loss: 0.28189105812992765\n",
            "Epochs: 741 w1: 0.8996810712943537 w2: 1.641718111765549 b: -1.849787224425202 loss: 1.2607681422114725\n",
            "Epochs: 742 w1: 0.9560376627201957 w2: 1.7557647928899767 b: -2.0940224315352256 loss: 0.6703498540511645\n",
            "Epochs: 743 w1: 1.1162791163931518 w2: 2.2325582327863036 b: -1.8614641987489218 loss: 0.6257062484436964\n",
            "Epochs: 744 w1: 1.0707700569730583 w2: 2.1415401139461165 b: -1.7199240848028055 loss: 0.33279133849558723\n",
            "Epochs: 745 w1: 0.9751297676676669 w2: 2.0 b: -1.8155788245425482 loss: 0.21233898082303967\n",
            "Epochs: 746 w1: 1.0930384021495414 w2: 2.1604110381888644 b: -1.6551677863536836 loss: 0.3868721480140287\n",
            "Epochs: 747 w1: 0.973679951208999 w2: 2.0 b: -1.756398743242149 loss: 0.22622568844394506\n",
            "Epochs: 748 w1: 0.9763474756093073 w2: 2.0 b: -1.8473699908986594 loss: 0.20082264572192104\n",
            "Epochs: 749 w1: 1.0979700287097764 w2: 2.1606066044422563 b: -1.686763386456403 loss: 0.38744820498127547\n",
            "Epochs: 750 w1: 1.0691259941398534 w2: 2.1280111002589877 b: -1.5587522861974152 loss: 0.2957440840001299\n",
            "Epochs: 751 w1: 0.9239977985394616 w2: 1.6545354479066434 b: -1.9042168382907718 loss: 1.1741845921119167\n",
            "Epochs: 752 w1: 1.1243883308594314 w2: 2.2144626394128126 b: -1.689754198877959 loss: 0.5602352176872705\n",
            "Epochs: 753 w1: 1.070560558414516 w2: 2.1138073522814773 b: -1.5759468465964817 loss: 0.2582717661063452\n",
            "Epochs: 754 w1: 1.0984037085923677 w2: 2.0 b: -1.1823320122270107 loss: 1.54754195200033\n",
            "Epochs: 755 w1: 1.0539467098213715 w2: 2.096333410395306 b: -1.0859986018317045 loss: 0.21401883444219758\n",
            "Epochs: 756 w1: 1.0442317323440142 w2: 2.0884634646880285 b: -0.9975351371436763 loss: 0.19471029655497904\n",
            "Epochs: 757 w1: 1.0441464666513145 w2: 2.0788329761630617 b: -0.9187021609806145 loss: 0.17157861221269705\n",
            "Epochs: 758 w1: 1.082341973820538 w2: 2.0 b: -0.5893342656984625 loss: 1.0750982939778597\n",
            "Epochs: 759 w1: 1.034147217287911 w2: 2.05597904473428 b: -0.5333552209641823 loss: 0.11873634055927482\n",
            "Epochs: 760 w1: 0.9237990950710115 w2: 1.5766616392833974 b: -0.9566935816807849 loss: 1.8752066548815927\n",
            "Epochs: 761 w1: 1.0714999519293538 w2: 2.1172130359497605 b: -0.8394805457310246 loss: 0.2671294936284757\n",
            "Epochs: 762 w1: 1.0377576422890595 w2: 2.0650993832569995 b: -0.7743811624740253 loss: 0.13949056069359703\n",
            "Epochs: 763 w1: 0.9054793296202387 w2: 1.5890405635662552 b: -1.18534059890777 loss: 1.7255160621144747\n",
            "Epochs: 764 w1: 1.1965652190275966 w2: 2.0 b: -0.8577319005284425 loss: 1.0648411961019484\n",
            "Epochs: 765 w1: 1.0386821886977355 w2: 2.0716336827735846 b: -0.786098217754858 loss: 0.15462938752787211\n",
            "Epochs: 766 w1: 0.9098374018784027 w2: 1.5901700085381942 b: -1.1959282092166639 loss: 1.712911226220416\n",
            "Epochs: 767 w1: 1.069579294915851 w2: 2.1546206553685576 b: -1.0413075538481062 loss: 0.3699647357964441\n",
            "Epochs: 768 w1: 1.0855458359273273 w2: 2.0 b: -0.6991242101387971 loss: 1.1531741424078163\n",
            "Epochs: 769 w1: 0.8787384275178598 w2: 2.0 b: -0.9323195418352206 loss: 0.6280912871440838\n",
            "Epochs: 770 w1: 0.8896609339709389 w2: 1.6059319070390676 b: -1.326387634796153 loss: 1.5518115971525792\n",
            "Epochs: 771 w1: 0.9169083744851505 w2: 2.0 b: -1.4774633175504248 loss: 0.35975305576586514\n",
            "Epochs: 772 w1: 1.072516926681846 w2: 2.1318489576033564 b: -1.3456143599470687 loss: 0.30611480316602063\n",
            "Epochs: 773 w1: 1.2005962408151056 w2: 2.0 b: -1.0112872919218925 loss: 1.1045925429472725\n",
            "Epochs: 774 w1: 0.91444290614142 w2: 1.6111041188246364 b: -1.400183173097256 loss: 1.5041403293347575\n",
            "Epochs: 775 w1: 1.0975811597636396 w2: 2.157388967360709 b: -1.242794205736547 loss: 0.3780123103673893\n",
            "Epochs: 776 w1: 0.9322721680948073 w2: 1.6237342671933739 b: -1.619059938543173 loss: 1.3964718388464947\n",
            "Epochs: 777 w1: 0.9737992179059362 w2: 2.0 b: -1.7198321773664953 loss: 0.22507601437707184\n",
            "Epochs: 778 w1: 0.9756310856320102 w2: 2.0 b: -1.813558771089533 loss: 0.20758175098696674\n",
            "Epochs: 779 w1: 1.0719387472087538 w2: 2.1798468680218845 b: -1.6337119030676484 loss: 0.4458086796593307\n",
            "Epochs: 780 w1: 1.070598986059177 w2: 2.115736042719962 b: -1.5179758603476863 loss: 0.26327839322780416\n",
            "Epochs: 781 w1: 1.0643140941989562 w2: 2.1169347167253747 b: -1.4010411436223114 loss: 0.26640267135274326\n",
            "Epochs: 782 w1: 0.916825203999879 w2: 1.6383704521733868 b: -1.7626706914489245 loss: 1.2846735738891393\n",
            "Epochs: 783 w1: 1.102770469727939 w2: 2.2097356525059983 b: -1.5529350389429264 loss: 0.5438160475620052\n",
            "Epochs: 784 w1: 0.8986068351161056 w2: 1.6378815539860916 b: -1.9150534849568348 loss: 1.2882130862677645\n",
            "Epochs: 785 w1: 0.9505106171407354 w2: 2.0 b: -2.0102253750708052 loss: 0.21114554144182224\n",
            "Epochs: 786 w1: 1.1042637483316513 w2: 2.1861852648779485 b: -1.8240401101928565 loss: 0.4658053021764679\n",
            "Epochs: 787 w1: 1.0715313556962163 w2: 2.1430627113924325 b: -1.6809773988004237 loss: 0.3370479942366346\n",
            "Epochs: 788 w1: 0.9045462429994677 w2: 1.6590937249980993 b: -2.0218836738023245 loss: 1.1451146044715936\n",
            "Epochs: 789 w1: 1.1265287559977888 w2: 2.2343125111070163 b: -1.7875711626953081 loss: 0.6322873341079973\n",
            "Epochs: 790 w1: 1.2257311967876618 w2: 2.0 b: -1.4113525013825383 loss: 1.3960914871167023\n",
            "Epochs: 791 w1: 1.0611499872236148 w2: 2.109196405756455 b: -1.3021560956260836 loss: 0.24640298115270204\n",
            "Epochs: 792 w1: 1.048774461235291 w2: 2.10838769163398 b: -1.1937684039921037 loss: 0.2443357572944565\n",
            "Epochs: 793 w1: 1.0479248105116843 w2: 2.0958496210233686 b: -1.0979187829687351 loss: 0.2128210645299697\n",
            "Epochs: 794 w1: 0.9189703951150292 w2: 1.6141447386429963 b: -1.4837740443257388 loss: 1.4771408181162045\n",
            "Epochs: 795 w1: 1.094035205337699 w2: 2.174139269143887 b: -1.309634775181852 loss: 0.42813801429679205\n",
            "Epochs: 796 w1: 1.051081235474343 w2: 2.0945948805080428 b: -1.2150398946738092 loss: 0.2097212362354902\n",
            "Epochs: 797 w1: 0.9212171403911497 w2: 1.6248435256721412 b: -1.590196369001668 loss: 1.3875469398921148\n",
            "Epochs: 798 w1: 1.087649247250441 w2: 2.1947761050009804 b: -1.3954202640006879 loss: 0.49356250915715844\n",
            "Epochs: 799 w1: 1.0517468797126512 w2: 2.1034937594253025 b: -1.2919265045753856 loss: 0.23191631831680337\n",
            "Epochs: 800 w1: 0.9147343433130573 w2: 1.6292797535350316 b: -1.662646751040354 loss: 1.352629410094357\n",
            "Epochs: 801 w1: 1.098889985235607 w2: 2.197779970471214 b: -1.4648667805691398 loss: 0.5034527717303231\n",
            "Epochs: 802 w1: 1.0571873449159601 w2: 2.103976990756291 b: -1.3608897898128485 loss: 0.23313578470491228\n",
            "Epochs: 803 w1: 1.0583282052704661 w2: 2.1041575094115466 b: -1.2567322804013017 loss: 0.23359171733089684\n",
            "Epochs: 804 w1: 0.9071995955852068 w2: 2.0 b: -1.4254602884281984 loss: 0.41166833246333684\n",
            "Epochs: 805 w1: 1.0723856992749645 w2: 2.1248029297844218 b: -1.3006573586437766 loss: 0.28715668991448384\n",
            "Epochs: 806 w1: 0.9655929370842246 w2: 2.0 b: -1.4329922160121435 loss: 0.3074355129996069\n",
            "Epochs: 807 w1: 0.9264861889649195 w2: 2.0 b: -1.5743649295411444 loss: 0.33232444848117815\n",
            "Epochs: 808 w1: 0.9317223439958283 w2: 1.6748683047420396 b: -1.8994966247991047 loss: 1.0505749521335066\n",
            "Epochs: 809 w1: 1.1050170144774971 w2: 2.2234404563351005 b: -1.6760561684640043 loss: 0.5921819528503216\n",
            "Epochs: 810 w1: 0.9206151065743818 w2: 1.6548482894538343 b: -2.02120787901017 loss: 1.172162238535841\n",
            "Epochs: 811 w1: 1.1392122526114405 w2: 2.224535891308775 b: -1.7966719877013948 loss: 0.5961507552988558\n",
            "Epochs: 812 w1: 1.0673597835907682 w2: 2.1347195671815364 b: -1.6619524205198584 loss: 0.3139427307463595\n",
            "Epochs: 813 w1: 1.1001758958094912 w2: 2.0 b: -1.2612488372818937 loss: 1.616498612996611\n",
            "Epochs: 814 w1: 1.0568914456234282 w2: 2.1034389920425967 b: -1.157809845239297 loss: 0.23177820296052284\n",
            "Epochs: 815 w1: 0.931877156171781 w2: 1.6215397565098946 b: -1.5362700887294025 loss: 1.4143666750912314\n",
            "Epochs: 816 w1: 0.9493375038457575 w2: 1.7185416880319861 b: -1.8177284006974164 loss: 0.827631310176605\n",
            "Epochs: 817 w1: 0.9448726249625143 w2: 1.7374886902976872 b: -2.080239710399729 loss: 0.7444880958805664\n",
            "Epochs: 818 w1: 0.9820997254145726 w2: 2.0 b: -2.1490869203436804 loss: 0.14814556984904417\n",
            "Epochs: 819 w1: 1.099288592013799 w2: 2.211252323433615 b: -1.9378345969100654 loss: 0.5490548831419036\n",
            "Epochs: 820 w1: 1.0861443744702877 w2: 2.138942539468206 b: -1.7988920574418594 loss: 0.3255709823073996\n",
            "Epochs: 821 w1: 1.0818714007715156 w2: 2.134215411100845 b: -1.6646766463410143 loss: 0.3125634932076025\n",
            "Epochs: 822 w1: 1.074498390764786 w2: 2.122128509450469 b: -1.5425481368905452 loss: 0.280053932697405\n",
            "Epochs: 823 w1: 1.057761234893745 w2: 2.128358299763878 b: -1.414189837126667 loss: 0.29667787970496023\n",
            "Epochs: 824 w1: 0.9782323980236983 w2: 2.0 b: -1.5287561633177282 loss: 0.26023897259780926\n",
            "Epochs: 825 w1: 1.0742592801443636 w2: 2.132605857400649 b: -1.396150305917079 loss: 0.3081728686116116\n",
            "Epochs: 826 w1: 0.9679423426877267 w2: 2.0 b: -1.519448987887361 loss: 0.2831554848460117\n",
            "Epochs: 827 w1: 0.9714472115317873 w2: 2.0 b: -1.6292674050727944 loss: 0.24799587069470513\n",
            "Epochs: 828 w1: 0.9818721237778002 w2: 2.0 b: -1.7246772799264776 loss: 0.2117335804463079\n",
            "Epochs: 829 w1: 0.9112129974694602 w2: 1.6829035623909294 b: -2.0417737175355484 loss: 1.0056490659546393\n",
            "Epochs: 830 w1: 1.1327309861725694 w2: 2.22884652788374 b: -1.812927189651808 loss: 0.611923120067708\n",
            "Epochs: 831 w1: 1.07390689064417 w2: 2.127425673524431 b: -1.6855015161273772 loss: 0.2941715463442691\n",
            "Epochs: 832 w1: 0.936377417689348 w2: 2.0 b: -1.807852635955554 loss: 0.28064322292114124\n",
            "Epochs: 833 w1: 0.9341932488956994 w2: 1.7008784040713611 b: -2.106974231884193 loss: 0.9119083282909952\n",
            "Epochs: 834 w1: 1.1016207844667787 w2: 2.254051961166947 b: -1.852922270717246 loss: 0.7094878090566952\n",
            "Epochs: 835 w1: 1.0687748716783494 w2: 2.1403568809762232 b: -1.7125653897410227 loss: 0.3294958947156637\n",
            "Epochs: 836 w1: 0.927409189274967 w2: 1.6700417694316683 b: -2.0425236203093546 loss: 1.0785639890126306\n",
            "Epochs: 837 w1: 0.9815814614227697 w2: 2.0 b: -2.113364153298702 loss: 0.1527795305906354\n",
            "Epochs: 838 w1: 0.924360496060764 w2: 1.7298589145027283 b: -2.3835052387959736 loss: 0.7771423929206059\n",
            "Epochs: 839 w1: 0.954978377036773 w2: 1.8042538132033612 b: -2.5792514255926124 loss: 0.49674583350783175\n",
            "Epochs: 840 w1: 0.9473942370337037 w2: 1.8121222751203705 b: -2.767129150472242 loss: 0.4712130799512858\n",
            "Epochs: 841 w1: 1.1545142767597003 w2: 2.3090285535194006 b: -2.4581005969528413 loss: 0.9624841764170046\n",
            "Epochs: 842 w1: 1.1121842994821485 w2: 2.0 b: -2.0093633990242474 loss: 2.2776427150823864\n",
            "Epochs: 843 w1: 1.0916559240792751 w2: 2.1833118481585503 b: -1.8260515508656971 loss: 0.4566905568769136\n",
            "Epochs: 844 w1: 1.077045390810112 w2: 2.137581055018057 b: -1.68847049584764 loss: 0.32180724917949355\n",
            "Epochs: 845 w1: 0.9048941413547884 w2: 1.6603362191242443 b: -2.028134276723396 loss: 1.1373351184506046\n",
            "Epochs: 846 w1: 1.1002920192227907 w2: 2.250730048056977 b: -1.777404228666419 loss: 0.6960716448680673\n",
            "Epochs: 847 w1: 1.2260423097729374 w2: 2.0 b: -1.4006670457115231 loss: 1.400289298653845\n",
            "Epochs: 848 w1: 1.055424549051432 w2: 2.1179245724498554 b: -1.2827424732616677 loss: 0.26899005498740486\n",
            "Epochs: 849 w1: 1.053719044498876 w2: 2.0976709899979564 b: -1.1850714832637115 loss: 0.21733791169579803\n",
            "Epochs: 850 w1: 0.9324383505237407 w2: 1.6246575029096706 b: -1.5604139803540409 loss: 1.3890380984496338\n",
            "Epochs: 851 w1: 1.0976735260334813 w2: 2.1808769000620027 b: -1.3795370802920384 loss: 0.44903117685242494\n",
            "Epochs: 852 w1: 0.9186665168865695 w2: 1.6303023494844069 b: -1.7492347308076315 loss: 1.3447505831077784\n",
            "Epochs: 853 w1: 1.0960548602605744 w2: 2.2134552450234986 b: -1.5357794857841327 loss: 0.5567133616348863\n",
            "Epochs: 854 w1: 0.9710670983209456 w2: 2.0 b: -1.6470598768574187 loss: 0.251749814378986\n",
            "Epochs: 855 w1: 1.100358031920529 w2: 2.0 b: -1.245627749175302 loss: 1.6238627284715403\n",
            "Epochs: 856 w1: 0.895957213652395 w2: 1.628418620187125 b: -1.6172091289881771 loss: 1.3593127006466015\n",
            "Epochs: 857 w1: 1.1110412755738874 w2: 2.182034877989979 b: -1.4351742509981977 loss: 0.45266640087099147\n",
            "Epochs: 858 w1: 1.204962110458164 w2: 2.0 b: -1.0935707335679241 loss: 1.1495068252876248\n",
            "Epochs: 859 w1: 0.8913280789727465 w2: 1.6118859963312373 b: -1.4816847372366868 loss: 1.4971276354285012\n",
            "Epochs: 860 w1: 1.102974578782218 w2: 2.168810784888882 b: -1.3128739523478048 loss: 0.4119182395115717\n",
            "Epochs: 861 w1: 1.0474512900973707 w2: 2.1009601916965335 b: -1.2119137606512713 loss: 0.2255469163249156\n",
            "Epochs: 862 w1: 1.1925577756384884 w2: 2.0 b: -0.8909841345871239 loss: 1.026829219365213\n",
            "Epochs: 863 w1: 1.0401980933783634 w2: 2.073087442506115 b: -0.8178966920810087 loss: 0.1580288895512345\n",
            "Epochs: 864 w1: 1.0362214309280833 w2: 2.0724428618561666 b: -0.7454538302248424 loss: 0.15652016249980402\n",
            "Epochs: 865 w1: 0.8745369374907186 w2: 2.0 b: -0.9735684893326266 loss: 0.6092276618369521\n",
            "Epochs: 866 w1: 1.0850316120921528 w2: 2.0 b: -0.6334420409640156 loss: 1.1402248979456824\n",
            "Epochs: 867 w1: 1.0304442349350607 w2: 2.067653855411246 b: -0.5657881855527699 loss: 0.1453815703938855\n",
            "Epochs: 868 w1: 1.0323829314832473 w2: 2.0530867729233564 b: -0.5127014126294136 loss: 0.11224364552394948\n",
            "Epochs: 869 w1: 1.027387047989322 w2: 2.0582703148708976 b: -0.454431097758516 loss: 0.12390997553709912\n",
            "Epochs: 870 w1: 0.8549018134027583 w2: 2.0 b: -0.7182459824807736 loss: 0.749992214097016\n",
            "Epochs: 871 w1: 1.0431442686450598 w2: 2.0707283092541964 b: -0.647517673226577 loss: 0.1525180681896589\n",
            "Epochs: 872 w1: 1.0309360852454519 w2: 2.063134867847861 b: -0.5843828053787161 loss: 0.13498357303768083\n",
            "Epochs: 873 w1: 1.1474368360851186 w2: 2.0 b: -0.33865474523685174 loss: 0.6762037747557922\n",
            "Epochs: 874 w1: 1.025423905767514 w2: 2.045399831727704 b: -0.29325491350914784 loss: 0.09518981684918455\n",
            "Epochs: 875 w1: 0.9358659014577495 w2: 2.0 b: -0.5399245232870346 loss: 0.6799135714216987\n",
            "Epochs: 876 w1: 1.0305772881613378 w2: 2.06505805991774 b: -0.4748664633692945 loss: 0.13939554731682877\n",
            "Epochs: 877 w1: 1.0262245582835603 w2: 2.0557969325182133 b: -0.41906953085108134 loss: 0.11832628135359038\n",
            "Epochs: 878 w1: 1.027644471601616 w2: 2.0493651278600287 b: -0.36970440299105267 loss: 0.10395068296143001\n",
            "Epochs: 879 w1: 1.0242413534935024 w2: 2.051577347858516 b: -0.3181270551325367 loss: 0.10887189078944977\n",
            "Epochs: 880 w1: 0.8457260702972107 w2: 2.0 b: -0.598625109137608 loss: 0.8232470003657241\n",
            "Epochs: 881 w1: 1.0394395972952113 w2: 2.0636122537019537 b: -0.5350128554356544 loss: 0.13607692391788886\n",
            "Epochs: 882 w1: 0.910586298371567 w2: 1.5742204684360332 b: -0.9607923869996211 loss: 1.9075681313567698\n",
            "Epochs: 883 w1: 1.0613066240136857 w2: 2.1304396255610336 b: -0.8303527614385876 loss: 0.3022939764180649\n",
            "Epochs: 884 w1: 1.0341575622631396 w2: 2.0697093107411013 b: -0.7606434506974864 loss: 0.15014709660188735\n",
            "Epochs: 885 w1: 0.9137471871117866 w2: 1.589272319579936 b: -1.1713711311175503 loss: 1.7229166297000496\n",
            "Epochs: 886 w1: 1.0627175115231537 w2: 2.1567937788078844 b: -1.0145773523096662 loss: 0.3762766039560223\n",
            "Epochs: 887 w1: 0.8995048120631695 w2: 2.0 b: -1.2078373291112634 loss: 0.4886075395706805\n",
            "Epochs: 888 w1: 1.0595043960263442 w2: 2.1081898109569894 b: -1.0996475181542742 loss: 0.24383058752500733\n",
            "Epochs: 889 w1: 0.9105661844180349 w2: 1.6111573235566736 b: -1.4884901945976006 loss: 1.5036615712336376\n",
            "Epochs: 890 w1: 1.0898510960009433 w2: 2.1797021920018866 b: -1.308788002595714 loss: 0.44535688542052704\n",
            "Epochs: 891 w1: 0.9161363095139498 w2: 2.0 b: -1.470064330453503 loss: 0.3894234498620837\n",
            "Epochs: 892 w1: 1.0768137329039051 w2: 2.125924152301484 b: -1.3441401781520192 loss: 0.2901495202361392\n",
            "Epochs: 893 w1: 1.052696636081779 w2: 2.105393272163558 b: -1.238746905988461 loss: 0.23671845521611892\n",
            "Epochs: 894 w1: 1.1941856779176134 w2: 2.0 b: -0.9151041094591053 loss: 1.0420965949948742\n",
            "Epochs: 895 w1: 0.8889816446505278 w2: 2.0 b: -1.1286009466696287 loss: 0.5568585229235267\n",
            "Epochs: 896 w1: 1.0579668753577627 w2: 2.099942888547867 b: -1.0286580581217621 loss: 0.2230007828757749\n",
            "Epochs: 897 w1: 1.0445927283530312 w2: 2.0796298720589843 b: -0.9490281860627777 loss: 0.1734725182213304\n",
            "Epochs: 898 w1: 0.9695334755411235 w2: 2.0 b: -1.109378314793707 loss: 0.38669280179549115\n",
            "Epochs: 899 w1: 1.1886810297269153 w2: 2.0 b: -0.7949099319155151 loss: 0.9913827881932451\n",
            "Epochs: 900 w1: 1.033595509397547 w2: 2.074656687550105 b: -0.7202532443654103 loss: 0.16171146158799732\n",
            "Epochs: 901 w1: 1.037108355202819 w2: 2.0598521858109984 b: -0.6604010585544118 loss: 0.12749748658690208\n",
            "Epochs: 902 w1: 0.8778621995994982 w2: 2.0 b: -0.8952814439399921 loss: 0.634426998371958\n",
            "Epochs: 903 w1: 1.0466757207056094 w2: 2.0848649467374716 b: -0.8104164972025205 loss: 0.18600420158394243\n",
            "Epochs: 904 w1: 0.9665879172728147 w2: 2.0 b: -0.9862695641877063 loss: 0.43341118846922716\n",
            "Epochs: 905 w1: 0.9108893803310368 w2: 1.612562523178421 b: -1.373707041009285 loss: 1.4910992695700254\n",
            "Epochs: 906 w1: 1.0948470926532206 w2: 2.0 b: -0.9943186703964031 loss: 1.4220323893658688\n",
            "Epochs: 907 w1: 1.0481756753695184 w2: 2.0789765169992105 b: -0.9153421533971928 loss: 0.17191948719614356\n",
            "Epochs: 908 w1: 0.9552006806903174 w2: 2.0 b: -1.087647227665203 loss: 0.422525027329253\n",
            "Epochs: 909 w1: 1.0492314240882543 w2: 2.100472294057662 b: -0.9871749336075408 loss: 0.22432498407529317\n",
            "Epochs: 910 w1: 1.045026498782145 w2: 2.0738139324297458 b: -0.913361001177795 loss: 0.15973206917878155\n",
            "Epochs: 911 w1: 1.0423311879387545 w2: 2.0729848067909558 b: -0.8403761943868391 loss: 0.1577885045407485\n",
            "Epochs: 912 w1: 1.0364775131151236 w2: 2.074443904316579 b: -0.7659322900702601 loss: 0.16121132435455376\n",
            "Epochs: 913 w1: 1.0367823368787836 w2: 2.0656827444263994 b: -0.7002495456438607 loss: 0.14083282774899317\n",
            "Epochs: 914 w1: 1.031050437213933 w2: 2.069000971586518 b: -0.6312485740573426 loss: 0.1485022625820475\n",
            "Epochs: 915 w1: 1.0326415981533321 w2: 2.059348360278786 b: -0.5719002137785567 loss: 0.12635346774146425\n",
            "Epochs: 916 w1: 0.9067820661956016 w2: 1.5762821190709164 b: -0.9956180947076403 loss: 1.8801695379117498\n",
            "Epochs: 917 w1: 1.072066664843084 w2: 2.1242528704191104 b: -0.8713652242885298 loss: 0.28569170899090257\n",
            "Epochs: 918 w1: 0.9271575629685008 w2: 1.5953197942694488 b: -1.2760454300190809 loss: 1.6573706045086158\n",
            "Epochs: 919 w1: 1.0845192494407574 w2: 2.15092723114421 b: -1.1251181988748713 loss: 0.35932769120416\n",
            "Epochs: 920 w1: 0.9142238508244912 w2: 1.610108412838596 b: -1.5150097860362752 loss: 1.5131426467262883\n",
            "Epochs: 921 w1: 0.9320816043385695 w2: 2.0 b: -1.6456220853851802 loss: 0.3027613266875495\n",
            "Epochs: 922 w1: 1.0753758643206475 w2: 2.153828294531934 b: -1.4917937908532464 loss: 0.36767318788180625\n",
            "Epochs: 923 w1: 0.9256128482916928 w2: 1.6457754680556798 b: -1.8460183227975666 loss: 1.2325405505101414\n",
            "Epochs: 924 w1: 1.1149277093363195 w2: 2.2128290913635547 b: -1.6331892314340122 loss: 0.5545305594271982\n",
            "Epochs: 925 w1: 0.9007028250750466 w2: 1.6453672324108808 b: -1.9878219990231314 loss: 1.23534492040636\n",
            "Epochs: 926 w1: 0.9808134601463201 w2: 2.0 b: -2.0616163830757466 loss: 0.15968620205569192\n",
            "Epochs: 927 w1: 0.9524169167901969 w2: 1.735649537723316 b: -2.3259668453524305 loss: 0.7522624067631986\n",
            "Epochs: 928 w1: 0.9642894178789941 w2: 1.801607877105523 b: -2.5243589682469074 loss: 0.5054803449055697\n",
            "Epochs: 929 w1: 0.9608566610896359 w2: 1.8136031480458847 b: -2.7107558202010225 loss: 0.4664797715847009\n",
            "Epochs: 930 w1: 1.160234368411724 w2: 2.2967303118735627 b: -2.4140255083274598 loss: 0.9000744881347971\n",
            "Epochs: 931 w1: 1.096579145951803 w2: 2.193158291903606 b: -2.2208672164238537 loss: 0.48827609261345895\n",
            "Epochs: 932 w1: 1.0894032779735152 w2: 2.1902197403691814 b: -2.030647476054672 loss: 0.47874489218936983\n",
            "Epochs: 933 w1: 0.9807112366551671 w2: 2.0 b: -2.1048350273809526 loss: 0.16060911042559126\n",
            "Epochs: 934 w1: 1.1011990226768114 w2: 2.2023980453536227 b: -1.9024369820273297 loss: 0.5188512274526432\n",
            "Epochs: 935 w1: 1.0645815576716695 w2: 2.1614538941791737 b: -1.7409830878481558 loss: 0.3899478090797277\n",
            "Epochs: 936 w1: 1.0779057389964612 w2: 2.1277143262237073 b: -1.6132687616244485 loss: 0.2949465986054412\n",
            "Epochs: 937 w1: 1.0702925594084705 w2: 2.121194067945639 b: -1.4920746936788096 loss: 0.27758407711049765\n",
            "Epochs: 938 w1: 0.8996435157809672 w2: 1.6415839849320257 b: -1.850490708746784 loss: 1.261715024321476\n",
            "Epochs: 939 w1: 1.1179773631835086 w2: 2.2145042966972883 b: -1.6359864120494958 loss: 0.5603811191671797\n",
            "Epochs: 940 w1: 1.0657478175736288 w2: 2.113358306161429 b: -1.5226281058880669 loss: 0.25710968997583256\n",
            "Epochs: 941 w1: 0.9382390637288095 w2: 1.656883687382275 b: -1.8657444185057919 loss: 1.1591034123338162\n",
            "Epochs: 942 w1: 0.9785556593945965 w2: 2.0 b: -1.9482226516034975 loss: 0.18027141919741022\n",
            "Epochs: 943 w1: 1.0919855387761501 w2: 2.1839710775523002 b: -1.764251574051197 loss: 0.45877436229036894\n",
            "Epochs: 944 w1: 0.9415565816631912 w2: 1.6753143425732844 b: -2.0889372314779124 loss: 1.048027492538465\n",
            "Epochs: 945 w1: 1.1018498017823064 w2: 2.254624504455766 b: -1.8343127270221466 loss: 0.7118184262892086\n",
            "Epochs: 946 w1: 0.9238309595495113 w2: 1.668830258910919 b: -2.165482468111228 loss: 1.0857142733743592\n",
            "Epochs: 947 w1: 0.9382901950433602 w2: 1.779607839440572 b: -2.385874628670656 loss: 0.5812200503991856\n",
            "Epochs: 948 w1: 1.1228229169147719 w2: 2.27293981536616 b: -2.112934813304496 loss: 0.7893929855361301\n",
            "Epochs: 949 w1: 1.089211491744504 w2: 2.153812916800869 b: -1.959121896503627 loss: 0.36762876660394\n",
            "Epochs: 950 w1: 1.085624677990809 w2: 2.155681232710562 b: -1.8034406637930653 loss: 0.37304022102581674\n",
            "Epochs: 951 w1: 1.0725170465725808 w2: 2.1450340931451617 b: -1.6584065706479034 loss: 0.3425863505872518\n",
            "Epochs: 952 w1: 0.9223140006654647 w2: 1.6622347855020203 b: -1.9961717851458831 loss: 1.1255635191792612\n",
            "Epochs: 953 w1: 1.1256129182259227 w2: 2.2283871240471322 b: -1.7677846610987509 loss: 0.6102302960820274\n",
            "Epochs: 954 w1: 1.070403267000063 w2: 2.1257201196429696 b: -1.6420645414557815 loss: 0.28960423767619936\n",
            "Epochs: 955 w1: 1.219307108367326 w2: 2.0 b: -1.276552694176905 loss: 1.3131319871177265\n",
            "Epochs: 956 w1: 1.0541912499205033 w2: 2.1003541665194505 b: -1.1761985276574545 loss: 0.22402935982537817\n",
            "Epochs: 957 w1: 0.9023284497858495 w2: 2.0 b: -1.3537831644104554 loss: 0.4387674361738369\n",
            "Epochs: 958 w1: 0.9230593689593595 w2: 1.6502698589061793 b: -1.7035133055042762 loss: 1.2021753613203845\n",
            "Epochs: 959 w1: 0.9830646200683727 w2: 2.0 b: -1.792646884091788 loss: 0.1963399454814799\n",
            "Epochs: 960 w1: 1.0949939356077358 w2: 2.1532160251737675 b: -1.6394308589180204 loss: 0.36590606327367703\n",
            "Epochs: 961 w1: 1.0685211896712932 w2: 2.1223592672701663 b: -1.5170715916478539 loss: 0.2806647972731533\n",
            "Epochs: 962 w1: 1.0658452196646708 w2: 2.113526240801157 b: -1.403545350846697 loss: 0.2575441261048983\n",
            "Epochs: 963 w1: 0.9681732247606952 w2: 2.0 b: -1.5259560248440232 loss: 0.2808009325517867\n",
            "Epochs: 964 w1: 1.078921053931899 w2: 2.1272920224708045 b: -1.3986640023732186 loss: 0.2938128874727496\n",
            "Epochs: 965 w1: 1.0573152004167095 w2: 2.106139260030943 b: -1.2925247423422752 loss: 0.23861070345827387\n",
            "Epochs: 966 w1: 1.0450077437443996 w2: 2.112519359360999 b: -1.1800053829812762 loss: 0.25494221051810223\n",
            "Epochs: 967 w1: 0.9162051482715136 w2: 1.6191143103250618 b: -1.5608910726562146 loss: 1.4345244754160158\n",
            "Epochs: 968 w1: 1.0790782727887838 w2: 2.1976956819719597 b: -1.3631953906842549 loss: 0.503173912822021\n",
            "Epochs: 969 w1: 1.0531881728019659 w2: 2.096705768730847 b: -1.2664896219534079 loss: 0.21494170046576766\n",
            "Epochs: 970 w1: 0.9143178182640586 w2: 1.6274687750611245 b: -1.6390208468922833 loss: 1.3667366652983528\n",
            "Epochs: 971 w1: 0.9821724926777236 w2: 2.0 b: -1.7328498327990014 loss: 0.20783381052890024\n",
            "Epochs: 972 w1: 1.0797573205802766 w2: 2.1595146411605532 b: -1.5733351916384481 loss: 0.3842359727602017\n",
            "Epochs: 973 w1: 1.2148472616668813 w2: 2.0 b: -1.215256422193646 loss: 1.2593359091318992\n",
            "Epochs: 974 w1: 1.0521274005834143 w2: 2.0947770919698443 b: -1.1204793302238019 loss: 0.21017079252686832\n",
            "Epochs: 975 w1: 0.9314199214611212 w2: 1.6189995636728955 b: -1.501479766550906 loss: 1.4354882719317066\n",
            "Epochs: 976 w1: 1.0759745785034576 w2: 2.189936446258644 b: -1.311543320292262 loss: 0.4778308098862122\n",
            "Epochs: 977 w1: 0.8929157155894207 w2: 1.617556127105074 b: -1.693987193187188 loss: 1.4476922013995612\n",
            "Epochs: 978 w1: 1.1079819658696533 w2: 2.199966603462321 b: -1.494020589724867 loss: 0.5107143081695382\n",
            "Epochs: 979 w1: 0.9257980535238242 w2: 2.0 b: -1.6367166406405897 loss: 0.3360212808810624\n",
            "Epochs: 980 w1: 0.9433480520968199 w2: 1.6852669560934441 b: -1.9514496845471456 loss: 0.9928103075658954\n",
            "Epochs: 981 w1: 0.9492864005650591 w2: 1.7585066693574243 b: -2.1929430151897216 loss: 0.6596866045843841\n",
            "Epochs: 982 w1: 0.9486888228100899 w2: 1.7769079252612605 b: -2.416035089928461 loss: 0.5909230472707475\n",
            "Epochs: 983 w1: 1.1352756809929194 w2: 2.270551361985839 b: -2.145483727942622 loss: 0.7789288934710029\n",
            "Epochs: 984 w1: 0.9879563955670895 w2: 2.0 b: -2.208871119694783 loss: 0.13556177646440892\n",
            "Epochs: 985 w1: 0.9838364272809978 w2: 2.0 b: -2.27103870707556 loss: 0.1327718808541142\n",
            "Epochs: 986 w1: 0.9847104459157481 w2: 2.0 b: -2.329844684322683 loss: 0.1251233588388826\n",
            "Epochs: 987 w1: 1.0967991191392406 w2: 2.2419977978481014 b: -2.0878468864745816 loss: 0.6616399780645262\n",
            "Epochs: 988 w1: 1.082811749589224 w2: 2.165623499178448 b: -1.9222233872961334 loss: 0.40234049234370783\n",
            "Epochs: 989 w1: 1.0773267143222565 w2: 2.1578096210658293 b: -1.764413766230304 loss: 0.3792408526890595\n",
            "Epochs: 990 w1: 1.0706267829611082 w2: 2.1412535659222165 b: -1.6231602003080876 loss: 0.3319922712506298\n",
            "Epochs: 991 w1: 0.9288483103414352 w2: 1.6611824301973108 b: -1.961977770110777 loss: 1.1320712681031302\n",
            "Epochs: 992 w1: 1.1095361307929488 w2: 2.2330555974318056 b: -1.7289221726789714 loss: 0.6275676917865051\n",
            "Epochs: 993 w1: 0.9253327477516646 w2: 1.660603398871203 b: -2.0683187738077686 loss: 1.135670133551888\n",
            "Epochs: 994 w1: 1.1215664265278693 w2: 2.2431328530557386 b: -1.82518592075203 loss: 0.6660490851455355\n",
            "Epochs: 995 w1: 0.9237751689438396 w2: 1.6685876910601725 b: -2.1565982296918578 loss: 1.0871520622801032\n",
            "Epochs: 996 w1: 1.1246656175843102 w2: 2.254419627723082 b: -1.9021786019687759 loss: 0.7109838227820321\n",
            "Epochs: 997 w1: 1.0688561776287222 w2: 2.146502505593026 b: -1.7556760963757498 loss: 0.3467317010683248\n",
            "Epochs: 998 w1: 1.0751163442976255 w2: 2.136575171450228 b: -1.6191009249255217 loss: 0.31903562187225365\n",
            "Epochs: 999 w1: 1.0621543163496092 w2: 2.1322432262757642 b: -1.4868576986497573 loss: 0.3071863197377829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MINI BATCH GRADIENT DESCENT**"
      ],
      "metadata": {
        "id": "jR0PpAHifDMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "def log_loss_mini_batch(y_true, y_pred):\n",
        "    return np.mean(log_loss(y_true, y_pred))"
      ],
      "metadata": {
        "id": "G2uSXDSCyJIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_numpy(x):\n",
        "  return 1/(1+np.exp(-x))\n"
      ],
      "metadata": {
        "id": "zEmfiWGuyPjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN:\n",
        "  def __init__(self):\n",
        "    self.w1=1\n",
        "    self.w2=1\n",
        "    self.b=0\n",
        "\n",
        "  def fit(self,X,y,epochs,batch_size):\n",
        "      self.mini_batch_gradient_descent(X[\"age\"],X[\"affordibility\"],y,epochs,batch_size)\n",
        "\n",
        "  def mini_batch_gradient_descent(self, age, aff, y_t, epochs, batch_size):\n",
        "    w1 = 1\n",
        "    w2 = 1\n",
        "    b = 0\n",
        "    n = len(age)\n",
        "    lear_rate = 0.5\n",
        "\n",
        "    age = np.array(age)\n",
        "    aff = np.array(aff)\n",
        "    y_t = np.array(y_t)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        indices = np.random.choice(n, size=batch_size, replace=False)\n",
        "        batch_age = age[indices]\n",
        "        batch_aff = aff[indices]\n",
        "        batch_y_t = y_t[indices]\n",
        "\n",
        "        weighted_sum = w1 * batch_age + w2 * batch_aff + b\n",
        "        y_p = sigmoid_numpy(weighted_sum)\n",
        "        loss = log_loss_mini_batch(batch_y_t, y_p)\n",
        "\n",
        "        w1_d = np.mean(batch_age * (y_p - batch_y_t))\n",
        "        w2_d = np.mean(batch_aff * (y_p - batch_y_t))\n",
        "        b_d = np.mean(y_p - batch_y_t)\n",
        "\n",
        "        w1 = w1 - lear_rate * w1_d\n",
        "        w2 = w2 - lear_rate * w2_d\n",
        "        b = b - lear_rate * b_d\n",
        "\n",
        "        print('Epoch:', i, 'w1:', w1, 'w2:', w2, 'b:', b, 'loss:', loss)\n",
        "\n",
        "    return w1, w2, b"
      ],
      "metadata": {
        "id": "_6aVxmMiybDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_model2=ANN()\n",
        "mini_model2.fit(X_train_scaled,y_train,1000,7)"
      ],
      "metadata": {
        "id": "INXAecNPe52-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee7aaf2-227b-476c-e91c-c4dd0cf43217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 w1: 0.9695545538511102 w2: 0.8606073605256206 b: -0.1593777749912791 loss: 0.8917571931390118\n",
            "Epoch: 1 w1: 0.9572253187119656 w2: 0.8581982054498064 b: -0.21762949416084534 loss: 0.6136408618470656\n",
            "Epoch: 2 w1: 0.947026354688556 w2: 0.8269884700378047 b: -0.2895233384333783 loss: 0.6296494752240298\n",
            "Epoch: 3 w1: 0.9213133700230167 w2: 0.8164458784408682 b: -0.3822083492313848 loss: 0.6607127379725395\n",
            "Epoch: 4 w1: 0.9351485501967578 w2: 0.8040795847268294 b: -0.4277456183080564 loss: 0.583307824378316\n",
            "Epoch: 5 w1: 0.9721619024431585 w2: 0.8185821052045184 b: -0.4132430978303675 loss: 0.540101839974822\n",
            "Epoch: 6 w1: 1.0035629843006184 w2: 0.8073922710385584 b: -0.38568662973444917 loss: 0.6054493713042665\n",
            "Epoch: 7 w1: 1.051880049259704 w2: 0.8592000112601048 b: -0.2957611725275202 loss: 0.5004682595262427\n",
            "Epoch: 8 w1: 1.059103961242577 w2: 0.763967593209843 b: -0.3546938008942807 loss: 0.7160979320224791\n",
            "Epoch: 9 w1: 1.0701511041211875 w2: 0.7760856717006793 b: -0.3845865828780853 loss: 0.5750882569101072\n",
            "Epoch: 10 w1: 1.106750217969902 w2: 0.8099040558675378 b: -0.3534439734159708 loss: 0.5219374580077373\n",
            "Epoch: 11 w1: 1.1031750789815054 w2: 0.8224703576170566 b: -0.378583161023865 loss: 0.6105032679849794\n",
            "Epoch: 12 w1: 1.1531676321631221 w2: 0.9166420595849887 b: -0.2809401680001511 loss: 0.41798558550104475\n",
            "Epoch: 13 w1: 1.163549641819647 w2: 0.9801530850702931 b: -0.25985605132763107 loss: 0.4690183240111229\n",
            "Epoch: 14 w1: 1.1092575584318165 w2: 0.8552068168718157 b: -0.46309629958742005 loss: 0.862262325366532\n",
            "Epoch: 15 w1: 1.1573101998570752 w2: 0.9046414223485216 b: -0.37463938350484766 loss: 0.49778461004137686\n",
            "Epoch: 16 w1: 1.1504972517809264 w2: 0.9226828847129538 b: -0.43074943459128373 loss: 0.5385630392179894\n",
            "Epoch: 17 w1: 1.1678315515434772 w2: 0.9956848811970762 b: -0.39154755934115654 loss: 0.47967213073280934\n",
            "Epoch: 18 w1: 1.187655628712554 w2: 0.962064482623097 b: -0.38767675360628595 loss: 0.6069304614714561\n",
            "Epoch: 19 w1: 1.187182473204903 w2: 0.9129316229871127 b: -0.44664862847882464 loss: 0.6543622053800169\n",
            "Epoch: 20 w1: 1.1809529721087069 w2: 0.9351644875323157 b: -0.49705523638192645 loss: 0.5358414978659461\n",
            "Epoch: 21 w1: 1.1733484235210536 w2: 0.7815588055433764 b: -0.6187096945871919 loss: 0.8102764992345676\n",
            "Epoch: 22 w1: 1.1901529215938471 w2: 0.763714043162972 b: -0.6252397206761366 loss: 0.6350986078214416\n",
            "Epoch: 23 w1: 1.2423714015343188 w2: 0.812338215901747 b: -0.5711672934128037 loss: 0.5185606447038985\n",
            "Epoch: 24 w1: 1.2614601150070024 w2: 0.8454322165299342 b: -0.5991643562057 loss: 0.4917546480535519\n",
            "Epoch: 25 w1: 1.2606480303953527 w2: 0.8168320915086545 b: -0.6880287697943056 loss: 0.5830933689902719\n",
            "Epoch: 26 w1: 1.2612944876674514 w2: 0.7730710496012643 b: -0.7466798955986932 loss: 0.6441349430893307\n",
            "Epoch: 27 w1: 1.2436137758858024 w2: 0.8055416992725561 b: -0.8114158537194762 loss: 0.5645854964199184\n",
            "Epoch: 28 w1: 1.2495427081179729 w2: 0.7561146559240481 b: -0.8880105294542741 loss: 0.6021175661881936\n",
            "Epoch: 29 w1: 1.2694908596249612 w2: 0.8277043217754191 b: -0.8744780831078083 loss: 0.536876369944198\n",
            "Epoch: 30 w1: 1.3232386261323728 w2: 0.9109268092273147 b: -0.8160247637742588 loss: 0.4777247671282849\n",
            "Epoch: 31 w1: 1.346974395876841 w2: 0.8509145840193716 b: -0.8399284052161942 loss: 0.6634784481806918\n",
            "Epoch: 32 w1: 1.4116690080066878 w2: 0.9420769776142047 b: -0.7019163240390378 loss: 0.5525386032669599\n",
            "Epoch: 33 w1: 1.432550320202915 w2: 0.9745563164944919 b: -0.6645971252934257 loss: 0.5560121881206442\n",
            "Epoch: 34 w1: 1.4171807232940463 w2: 1.0006793924790478 b: -0.7135353962903634 loss: 0.5430370736755817\n",
            "Epoch: 35 w1: 1.3699144654303579 w2: 0.9441101768649197 b: -0.8710364439228375 loss: 0.6632033082166359\n",
            "Epoch: 36 w1: 1.4009592123931751 w2: 1.0587404502565039 b: -0.8167413976190859 loss: 0.4343773836401173\n",
            "Epoch: 37 w1: 1.4517541168921098 w2: 1.1167220271559404 b: -0.7334673906663498 loss: 0.504255475389528\n",
            "Epoch: 38 w1: 1.4971926946013379 w2: 1.1872242650548794 b: -0.6243222223816719 loss: 0.48339579980341024\n",
            "Epoch: 39 w1: 1.503166752840449 w2: 1.1448606807552797 b: -0.6963889889276461 loss: 0.551652298685264\n",
            "Epoch: 40 w1: 1.519293035696806 w2: 1.2280549226380946 b: -0.6789108101887937 loss: 0.3675048896176514\n",
            "Epoch: 41 w1: 1.5281860353260577 w2: 1.119820307249158 b: -0.7555672307656448 loss: 0.7072828312068504\n",
            "Epoch: 42 w1: 1.541750767692439 w2: 1.0765933651160025 b: -0.7840399383611988 loss: 0.622443131062537\n",
            "Epoch: 43 w1: 1.5402156364273307 w2: 1.05550593683111 b: -0.8419827456853132 loss: 0.5641648611151487\n",
            "Epoch: 44 w1: 1.5438935474771107 w2: 0.9533515616148792 b: -0.9378444330706066 loss: 0.6752442668442429\n",
            "Epoch: 45 w1: 1.5225566603146088 w2: 0.825953379031469 b: -1.0898303989499412 loss: 0.6747267605208432\n",
            "Epoch: 46 w1: 1.587910759715456 w2: 0.9572715874932334 b: -0.9410692878690313 loss: 0.5655431458045169\n",
            "Epoch: 47 w1: 1.6314411014681154 w2: 1.0655289151957072 b: -0.8839779392840654 loss: 0.3852356261734106\n",
            "Epoch: 48 w1: 1.6305436069050212 w2: 1.0314904520864385 b: -0.9090351953189177 loss: 0.6607933638405854\n",
            "Epoch: 49 w1: 1.7004007519244693 w2: 1.17257427354148 b: -0.7679513738638764 loss: 0.3318355155897139\n",
            "Epoch: 50 w1: 1.7063920126433696 w2: 1.169659325514139 b: -0.8062263066447346 loss: 0.5309981393400047\n",
            "Epoch: 51 w1: 1.7024411276457054 w2: 1.1729266991861895 b: -0.8270174167239713 loss: 0.5909179086149773\n",
            "Epoch: 52 w1: 1.7092077644266468 w2: 1.1268819396068341 b: -0.8775634692309049 loss: 0.6106405578209911\n",
            "Epoch: 53 w1: 1.722330181964375 w2: 1.1313329342157916 b: -0.9040481048884991 loss: 0.5179432338867035\n",
            "Epoch: 54 w1: 1.721879394188212 w2: 1.1362301037803215 b: -0.9377930845532452 loss: 0.5539388858036259\n",
            "Epoch: 55 w1: 1.7364054657766883 w2: 1.179540649420333 b: -0.9294395131716211 loss: 0.46140713345489115\n",
            "Epoch: 56 w1: 1.7153613313161398 w2: 1.132299306160477 b: -1.038170033293269 loss: 0.5835964308437818\n",
            "Epoch: 57 w1: 1.7290259289295526 w2: 1.1003782884742905 b: -1.068240984581166 loss: 0.5976263391204741\n",
            "Epoch: 58 w1: 1.7495542055852367 w2: 1.0745680427471054 b: -1.0704240061323236 loss: 0.6092335970697942\n",
            "Epoch: 59 w1: 1.741347042056029 w2: 1.028053915310378 b: -1.129124070864179 loss: 0.6444348021780656\n",
            "Epoch: 60 w1: 1.7453847787532732 w2: 1.0197137567722145 b: -1.1837118870992331 loss: 0.5295063877107389\n",
            "Epoch: 61 w1: 1.7660485551686311 w2: 1.0101897175881076 b: -1.1679937581975042 loss: 0.632347729138058\n",
            "Epoch: 62 w1: 1.7499783269675926 w2: 1.0005312371809747 b: -1.2411451752771476 loss: 0.5680461910191875\n",
            "Epoch: 63 w1: 1.8101028427893027 w2: 1.139696221988146 b: -1.1327504074489165 loss: 0.4173898421766899\n",
            "Epoch: 64 w1: 1.8264266732314516 w2: 1.0894969775422005 b: -1.131293411321865 loss: 0.701943222994162\n",
            "Epoch: 65 w1: 1.8543607009273868 w2: 1.06488354835813 b: -1.1439557894407144 loss: 0.5601528893716856\n",
            "Epoch: 66 w1: 1.8925978316772079 w2: 1.0863636161261156 b: -1.072287926641779 loss: 0.6214045447775429\n",
            "Epoch: 67 w1: 1.8871103353806138 w2: 0.9998816210714145 b: -1.1593394417701135 loss: 0.6811922452348335\n",
            "Epoch: 68 w1: 1.924539465644638 w2: 1.0415774808975622 b: -1.1149944505331844 loss: 0.5182260009436771\n",
            "Epoch: 69 w1: 1.9912083515696277 w2: 1.1433128140573816 b: -1.0033261430721507 loss: 0.3978394413658762\n",
            "Epoch: 70 w1: 1.9760967914164198 w2: 1.142325554938455 b: -1.0333999540338923 loss: 0.6095724140477213\n",
            "Epoch: 71 w1: 2.0299438197194086 w2: 1.1842243512199522 b: -0.958500526627662 loss: 0.4344359495268752\n",
            "Epoch: 72 w1: 2.0286816277948687 w2: 1.1798117542267 b: -0.984864814645106 loss: 0.560450629115686\n",
            "Epoch: 73 w1: 2.0778720788785696 w2: 1.195151732159972 b: -0.8938550395372233 loss: 0.5294548507750555\n",
            "Epoch: 74 w1: 2.066628045602173 w2: 1.2016215728033972 b: -0.9569874697638355 loss: 0.48257192796766596\n",
            "Epoch: 75 w1: 2.040265348978695 w2: 1.1521539056423171 b: -1.0736973641408796 loss: 0.6031591080278609\n",
            "Epoch: 76 w1: 2.0355579186306696 w2: 1.1273260796106142 b: -1.1340116328588232 loss: 0.5426300612315451\n",
            "Epoch: 77 w1: 2.057916096018081 w2: 1.0293308559914456 b: -1.151323593176694 loss: 0.7218374221018612\n",
            "Epoch: 78 w1: 2.0395474397284503 w2: 0.9664949769394501 b: -1.2484244253511976 loss: 0.6301015457701157\n",
            "Epoch: 79 w1: 2.071192515188873 w2: 1.0372703113002764 b: -1.2111043727744877 loss: 0.46361323065056076\n",
            "Epoch: 80 w1: 2.0646438495373607 w2: 1.000915236984396 b: -1.2572982488989586 loss: 0.641947269478698\n",
            "Epoch: 81 w1: 2.121693920234253 w2: 1.0863483718154445 b: -1.1718651140679102 loss: 0.42506284396282695\n",
            "Epoch: 82 w1: 2.1575405554575537 w2: 1.1348076899211685 b: -1.1460308691797825 loss: 0.3932956026740733\n",
            "Epoch: 83 w1: 2.1670627685561046 w2: 1.1107510790166353 b: -1.1932201912636347 loss: 0.49194893665846795\n",
            "Epoch: 84 w1: 2.16926649278843 w2: 1.0793717391462436 b: -1.2133372402109295 loss: 0.6364561475378212\n",
            "Epoch: 85 w1: 2.1968488205694747 w2: 1.0495421232779445 b: -1.233537025178067 loss: 0.5196440846663123\n",
            "Epoch: 86 w1: 2.242537152191725 w2: 1.0788869711697087 b: -1.1918861074213474 loss: 0.4464012099503966\n",
            "Epoch: 87 w1: 2.2491188445647725 w2: 1.090525831071628 b: -1.1952422143090382 loss: 0.5570595591291049\n",
            "Epoch: 88 w1: 2.278198218288626 w2: 1.1166000695752625 b: -1.1726624611446268 loss: 0.4743345274703247\n",
            "Epoch: 89 w1: 2.2809765783652334 w2: 1.0850478291161942 b: -1.1939741266206614 loss: 0.6336314040214741\n",
            "Epoch: 90 w1: 2.293257792592493 w2: 1.057968036847956 b: -1.197300497086462 loss: 0.6222506565049756\n",
            "Epoch: 91 w1: 2.2785340498006112 w2: 1.0092369048422922 b: -1.2616723797407805 loss: 0.6536477149273472\n",
            "Epoch: 92 w1: 2.2709568677462104 w2: 0.9912520448824457 b: -1.3369279252719957 loss: 0.5186630246109746\n",
            "Epoch: 93 w1: 2.27818034551979 w2: 0.9990828926161194 b: -1.3620307459293461 loss: 0.5287953673929967\n",
            "Epoch: 94 w1: 2.2994470766252024 w2: 1.0923375595566769 b: -1.2859315033322705 loss: 0.5707513310040154\n",
            "Epoch: 95 w1: 2.314172686235925 w2: 1.086407308590984 b: -1.3157518526674408 loss: 0.48587696444556994\n",
            "Epoch: 96 w1: 2.305067256543419 w2: 1.0637345675682899 b: -1.3943715608045417 loss: 0.5148608696636172\n",
            "Epoch: 97 w1: 2.3319978801408356 w2: 0.9842016962146135 b: -1.3884282426007246 loss: 0.7118802889024886\n",
            "Epoch: 98 w1: 2.3734174139235114 w2: 1.0143478607344005 b: -1.3059766161413582 loss: 0.6270494194207731\n",
            "Epoch: 99 w1: 2.382182912623691 w2: 1.0378809806586544 b: -1.2940971308335638 loss: 0.5796003259998234\n",
            "Epoch: 100 w1: 2.3586235754238087 w2: 0.9934510609405206 b: -1.4188716448651237 loss: 0.5133010662626393\n",
            "Epoch: 101 w1: 2.4165910999634734 w2: 1.0647989703959477 b: -1.3036982738882672 loss: 0.542218521054944\n",
            "Epoch: 102 w1: 2.449216379896392 w2: 1.0952464538312554 b: -1.2496225109913808 loss: 0.5214074126663613\n",
            "Epoch: 103 w1: 2.4430080461032753 w2: 1.0254198033203525 b: -1.3418348781287095 loss: 0.5794035163164244\n",
            "Epoch: 104 w1: 2.457470617084185 w2: 0.9700416738402926 b: -1.348995660808114 loss: 0.6688083297637508\n",
            "Epoch: 105 w1: 2.522489691493248 w2: 1.0377986518795042 b: -1.2477622952563143 loss: 0.4516589992718738\n",
            "Epoch: 106 w1: 2.4898230351357262 w2: 0.9441700510777555 b: -1.4036889842733358 loss: 0.5999155316599086\n",
            "Epoch: 107 w1: 2.5195900699655267 w2: 1.0120962125475048 b: -1.3695329429593057 loss: 0.44974933087401603\n",
            "Epoch: 108 w1: 2.5485398161875215 w2: 0.9352097886137218 b: -1.3648893194744314 loss: 0.6723968000847375\n",
            "Epoch: 109 w1: 2.5965374399780266 w2: 0.946295085019757 b: -1.3210159231591798 loss: 0.49755507285832085\n",
            "Epoch: 110 w1: 2.593429706485986 w2: 0.888378949983465 b: -1.4034970870551977 loss: 0.5487394384360719\n",
            "Epoch: 111 w1: 2.6211111645387972 w2: 0.9379861866209473 b: -1.340031098009369 loss: 0.5868483751464922\n",
            "Epoch: 112 w1: 2.609171962308536 w2: 0.954630386831867 b: -1.4067833180784597 loss: 0.47791259696497274\n",
            "Epoch: 113 w1: 2.5857515402111355 w2: 0.9708751109480215 b: -1.484832180860041 loss: 0.5053738170580988\n",
            "Epoch: 114 w1: 2.575094516447258 w2: 0.9196473390234815 b: -1.570655518294914 loss: 0.5482618164720534\n",
            "Epoch: 115 w1: 2.5799825857138656 w2: 0.8975951477020503 b: -1.6101296267051695 loss: 0.555913784847444\n",
            "Epoch: 116 w1: 2.616033309618145 w2: 0.9028002243278666 b: -1.570772777823863 loss: 0.5611772038434658\n",
            "Epoch: 117 w1: 2.6194971463673182 w2: 0.8830317068285969 b: -1.6089524485672708 loss: 0.5650543852839405\n",
            "Epoch: 118 w1: 2.6203347814796953 w2: 0.9016791956283042 b: -1.6382114891327466 loss: 0.533507762404073\n",
            "Epoch: 119 w1: 2.678518862887418 w2: 0.9284924307226431 b: -1.5745056350898805 loss: 0.5111182577004774\n",
            "Epoch: 120 w1: 2.6691228405841336 w2: 1.0047658381694897 b: -1.6038903657032721 loss: 0.45950714182360425\n",
            "Epoch: 121 w1: 2.7075394809719984 w2: 1.0376204423511162 b: -1.5710357615216457 loss: 0.4660002419556419\n",
            "Epoch: 122 w1: 2.7029175619476122 w2: 1.0595892293760207 b: -1.6214336654355046 loss: 0.44238381937252125\n",
            "Epoch: 123 w1: 2.7173558313072337 w2: 1.113618032140149 b: -1.6184484467888562 loss: 0.449800474336583\n",
            "Epoch: 124 w1: 2.7285065952395673 w2: 1.100052274327352 b: -1.6127216503493826 loss: 0.6256920234261926\n",
            "Epoch: 125 w1: 2.723792896439374 w2: 1.1021867362197182 b: -1.6592013988501924 loss: 0.5137211460546895\n",
            "Epoch: 126 w1: 2.746701441984226 w2: 1.1275087005223725 b: -1.6504692687838083 loss: 0.48698112815713074\n",
            "Epoch: 127 w1: 2.786389422185951 w2: 1.1709495108723182 b: -1.6030333980456521 loss: 0.47464962859989485\n",
            "Epoch: 128 w1: 2.857513954299167 w2: 1.2808240419323274 b: -1.4422824160185823 loss: 0.43276152063497353\n",
            "Epoch: 129 w1: 2.845994182786798 w2: 1.276439907871304 b: -1.4902977161516762 loss: 0.5380902509186503\n",
            "Epoch: 130 w1: 2.8515816279188253 w2: 1.2414014580158024 b: -1.5290159359262576 loss: 0.5659763862484206\n",
            "Epoch: 131 w1: 2.8422868139447566 w2: 1.16737330403014 b: -1.622434263751493 loss: 0.5647681732688751\n",
            "Epoch: 132 w1: 2.8271746351047526 w2: 1.0867863073420876 b: -1.7419868067925592 loss: 0.5085148206096262\n",
            "Epoch: 133 w1: 2.877059539076266 w2: 1.0838548885915886 b: -1.655679655740806 loss: 0.674210372267194\n",
            "Epoch: 134 w1: 2.9034679216658317 w2: 1.1239848424888585 b: -1.5986432077565018 loss: 0.5627143169269667\n",
            "Epoch: 135 w1: 2.9463867973873925 w2: 1.0965276981193843 b: -1.5425628511279454 loss: 0.607494519545719\n",
            "Epoch: 136 w1: 2.925657632705366 w2: 0.9938651356287888 b: -1.6684980234488722 loss: 0.6088107296077743\n",
            "Epoch: 137 w1: 2.9737346790914385 w2: 0.976876258863567 b: -1.6000012069550784 loss: 0.6082791540571059\n",
            "Epoch: 138 w1: 2.986866811087894 w2: 0.9611174876181594 b: -1.6180827265055433 loss: 0.5398796372143123\n",
            "Epoch: 139 w1: 3.01005791563617 w2: 0.9557504029959673 b: -1.5946062152522007 loss: 0.5853801132796207\n",
            "Epoch: 140 w1: 3.0547540028540436 w2: 1.0663902728217434 b: -1.4708464256374822 loss: 0.5406270539677639\n",
            "Epoch: 141 w1: 3.0875457586946866 w2: 1.0857059833901876 b: -1.424476823706878 loss: 0.4612946617710127\n",
            "Epoch: 142 w1: 3.009439386652741 w2: 0.9631963160483891 b: -1.6730231878565753 loss: 0.708809298151688\n",
            "Epoch: 143 w1: 3.055317700785859 w2: 0.9765457895904797 b: -1.6263245414275347 loss: 0.5001187593839581\n",
            "Epoch: 144 w1: 3.1051591491937254 w2: 1.009254832680075 b: -1.5330144840364965 loss: 0.5736575819070212\n",
            "Epoch: 145 w1: 3.109018475198061 w2: 0.9870728966813364 b: -1.5454073184552088 loss: 0.6050938750095478\n",
            "Epoch: 146 w1: 3.126875376291727 w2: 0.9604710927787938 b: -1.5463323848140078 loss: 0.5449599939653862\n",
            "Epoch: 147 w1: 3.117023649840672 w2: 0.8306896656576959 b: -1.6661242643705243 loss: 0.602680621437698\n",
            "Epoch: 148 w1: 3.1622761846614047 w2: 0.885036263953876 b: -1.6117776660743441 loss: 0.4545197102131216\n",
            "Epoch: 149 w1: 3.18419593736406 w2: 0.9288269649244738 b: -1.6093478591570816 loss: 0.4034624568089029\n",
            "Epoch: 150 w1: 3.1739852126574966 w2: 0.9723270166092448 b: -1.640636158678544 loss: 0.5230618259518701\n",
            "Epoch: 151 w1: 3.2162778255881053 w2: 1.0761024261328374 b: -1.5244516763105467 loss: 0.524982295157396\n",
            "Epoch: 152 w1: 3.2036122632136603 w2: 0.9586645720143263 b: -1.6418895304290577 loss: 0.5861359804682821\n",
            "Epoch: 153 w1: 3.234769043949184 w2: 0.9492134355893144 b: -1.6393462314352218 loss: 0.4554809404422589\n",
            "Epoch: 154 w1: 3.2574837680467845 w2: 0.9324617556888444 b: -1.6478979695849887 loss: 0.49057202604164124\n",
            "Epoch: 155 w1: 3.233406082144885 w2: 0.866667368179619 b: -1.769033716849034 loss: 0.5257875967796289\n",
            "Epoch: 156 w1: 3.2765087104059774 w2: 0.914720789721106 b: -1.7209802953075468 loss: 0.4451875678421374\n",
            "Epoch: 157 w1: 3.2514276817611893 w2: 0.9021765150841031 b: -1.8060934937356055 loss: 0.5421797329119998\n",
            "Epoch: 158 w1: 3.2381311647902895 w2: 0.8866057419817498 b: -1.8385939437800964 loss: 0.653900748728031\n",
            "Epoch: 159 w1: 3.299503650150282 w2: 0.9955774803999057 b: -1.7296222053619406 loss: 0.44959664417624373\n",
            "Epoch: 160 w1: 3.3231692516984044 w2: 1.033511483372524 b: -1.6780695936999876 loss: 0.5558855038385174\n",
            "Epoch: 161 w1: 3.3319460742072975 w2: 0.9884230035717599 b: -1.723158073500752 loss: 0.49729579358363896\n",
            "Epoch: 162 w1: 3.329598790875896 w2: 0.9226901180200641 b: -1.7939574662314168 loss: 0.5630295996211105\n",
            "Epoch: 163 w1: 3.329898374726734 w2: 0.8979195955324074 b: -1.8400515060688198 loss: 0.5253713006629058\n",
            "Epoch: 164 w1: 3.3792281966475666 w2: 0.9263718999926793 b: -1.7786984934508827 loss: 0.5028492788325386\n",
            "Epoch: 165 w1: 3.4350937450591106 w2: 1.009424574501136 b: -1.695645818942426 loss: 0.3612365858853566\n",
            "Epoch: 166 w1: 3.4642113480035546 w2: 1.0023995157476235 b: -1.6528275851923007 loss: 0.5585930069876531\n",
            "Epoch: 167 w1: 3.4754646282497137 w2: 0.9879782089354392 b: -1.6865345379539096 loss: 0.42291407629018724\n",
            "Epoch: 168 w1: 3.519571768274974 w2: 0.977254134149079 b: -1.6190189509275363 loss: 0.5783465959073874\n",
            "Epoch: 169 w1: 3.557092500217955 w2: 1.052752534586271 b: -1.5559021410375997 loss: 0.35298088317798754\n",
            "Epoch: 170 w1: 3.519400016493417 w2: 0.9977036557911255 b: -1.6976195822580749 loss: 0.5582421979687794\n",
            "Epoch: 171 w1: 3.501178312870462 w2: 1.0208977591090374 b: -1.7524470443185989 loss: 0.49211108330333514\n",
            "Epoch: 172 w1: 3.4942453537198177 w2: 0.9762479286453611 b: -1.8259764821591307 loss: 0.5071344572636726\n",
            "Epoch: 173 w1: 3.5170619557230074 w2: 0.9896932985388156 b: -1.829551925363896 loss: 0.4093960001212225\n",
            "Epoch: 174 w1: 3.523972344182303 w2: 0.9587513005208352 b: -1.8464375412739413 loss: 0.5685866783444463\n",
            "Epoch: 175 w1: 3.5016279723207875 w2: 0.9636644472586502 b: -1.9143406668545537 loss: 0.5672444473697171\n",
            "Epoch: 176 w1: 3.5291905081184924 w2: 1.022875120956402 b: -1.8382903104438169 loss: 0.6260920430225564\n",
            "Epoch: 177 w1: 3.5340024672411836 w2: 1.0670221862543021 b: -1.848638353724043 loss: 0.4543732412192269\n",
            "Epoch: 178 w1: 3.55977878269746 w2: 1.027972255778507 b: -1.825284153430915 loss: 0.6133496952283961\n",
            "Epoch: 179 w1: 3.5822562987567825 w2: 1.0743141233224893 b: -1.8167843474317447 loss: 0.3796767736824462\n",
            "Epoch: 180 w1: 3.615677821686047 w2: 1.061410873123839 b: -1.7998579138827526 loss: 0.44785639360855234\n",
            "Epoch: 181 w1: 3.6177071277939987 w2: 0.9503919823385066 b: -1.8816875148869823 loss: 0.5805802190242222\n",
            "Epoch: 182 w1: 3.6542674694866357 w2: 1.0407247274768336 b: -1.8150125589590802 loss: 0.44282299680772347\n",
            "Epoch: 183 w1: 3.661065970969641 w2: 1.0093431601603873 b: -1.834319170774917 loss: 0.5672919365546198\n",
            "Epoch: 184 w1: 3.6653921478437255 w2: 1.0506945665735261 b: -1.8527798450229598 loss: 0.4228188692267073\n",
            "Epoch: 185 w1: 3.710751753079026 w2: 1.1185986014169444 b: -1.7425962102308776 loss: 0.5244282316339622\n",
            "Epoch: 186 w1: 3.7168291827652635 w2: 1.0429655914643812 b: -1.768718188761293 loss: 0.6352073880197524\n",
            "Epoch: 187 w1: 3.708738182857082 w2: 0.9462190978775801 b: -1.8654646823480943 loss: 0.554485630699224\n",
            "Epoch: 188 w1: 3.7208514741241743 w2: 0.9318856359940271 b: -1.8872803809734355 loss: 0.48683799432418834\n",
            "Epoch: 189 w1: 3.769077013546063 w2: 0.9272839667798625 b: -1.8106624947845191 loss: 0.564949381308055\n",
            "Epoch: 190 w1: 3.7528073685651546 w2: 0.9061058082256659 b: -1.8918936408576301 loss: 0.4853717470496366\n",
            "Epoch: 191 w1: 3.778320488478983 w2: 1.0006491806108495 b: -1.8545379364972683 loss: 0.37231652038625623\n",
            "Epoch: 192 w1: 3.8352572847981405 w2: 1.0309497101504097 b: -1.7448577434615544 loss: 0.5028380402768781\n",
            "Epoch: 193 w1: 3.823013092077573 w2: 1.0349609894296539 b: -1.7971164811834297 loss: 0.4943963012246206\n",
            "Epoch: 194 w1: 3.8336034944113666 w2: 0.9876767538932588 b: -1.8444007167198249 loss: 0.43745157643066507\n",
            "Epoch: 195 w1: 3.827969653483945 w2: 0.9337453464703465 b: -1.8798368922514004 loss: 0.6704995989057742\n",
            "Epoch: 196 w1: 3.8051906809086407 w2: 0.8476561611189135 b: -1.9944210310194894 loss: 0.5524033638597896\n",
            "Epoch: 197 w1: 3.8235557076929956 w2: 0.8864748215355721 b: -1.9558986660385131 loss: 0.5631501738712843\n",
            "Epoch: 198 w1: 3.8162855024679576 w2: 0.8598522994456882 b: -1.9883898133429543 loss: 0.6007267946347403\n",
            "Epoch: 199 w1: 3.8440521143497075 w2: 0.8930229151785049 b: -1.9744833369508297 loss: 0.42174149677497846\n",
            "Epoch: 200 w1: 3.8657577983752436 w2: 0.8727941870720983 b: -1.9947120650572363 loss: 0.4012399031202621\n",
            "Epoch: 201 w1: 3.889183528271943 w2: 0.9053822191051933 b: -1.981480327428558 loss: 0.4602524579341526\n",
            "Epoch: 202 w1: 3.9450738528882354 w2: 1.0028538635349338 b: -1.8840086829988174 loss: 0.39012705424858757\n",
            "Epoch: 203 w1: 3.9408768339500297 w2: 0.9465080195608164 b: -1.95773608335269 loss: 0.483351769682763\n",
            "Epoch: 204 w1: 3.9607824782521455 w2: 1.0009654418625404 b: -1.940626090403754 loss: 0.4012656774867906\n",
            "Epoch: 205 w1: 4.002479249604286 w2: 1.0388170966377532 b: -1.8952101269721735 loss: 0.3636394373156769\n",
            "Epoch: 206 w1: 3.9989910588692577 w2: 1.0346981940322986 b: -1.9404680358512942 loss: 0.466665504565392\n",
            "Epoch: 207 w1: 3.994713285402363 w2: 0.9727958314459485 b: -2.0191513695035566 loss: 0.4573368133232046\n",
            "Epoch: 208 w1: 4.045608513511767 w2: 1.055132358279023 b: -1.936814842670482 loss: 0.3537922335085234\n",
            "Epoch: 209 w1: 4.041771815610472 w2: 1.0794590407553215 b: -1.9741827463328347 loss: 0.41086756207705843\n",
            "Epoch: 210 w1: 4.055094643028529 w2: 1.132730615993445 b: -1.9195325397828655 loss: 0.6046985381835069\n",
            "Epoch: 211 w1: 4.091756300868259 w2: 1.191213504442324 b: -1.8246620685286834 loss: 0.49926318025793287\n",
            "Epoch: 212 w1: 4.0678724766933305 w2: 1.179881545334142 b: -1.8954681526568549 loss: 0.52873573126456\n",
            "Epoch: 213 w1: 4.08745433622648 w2: 1.1830720635617835 b: -1.90517494713621 loss: 0.3684454281386578\n",
            "Epoch: 214 w1: 4.132633475595835 w2: 1.2531697078941892 b: -1.8020001066133475 loss: 0.3728146834461813\n",
            "Epoch: 215 w1: 4.142200542580873 w2: 1.3026642940333084 b: -1.7688164030795284 loss: 0.45536051913015596\n",
            "Epoch: 216 w1: 4.1326287613253765 w2: 1.2896454638780745 b: -1.7955582883631402 loss: 0.56809175187878\n",
            "Epoch: 217 w1: 4.139994529522774 w2: 1.2934228629752567 b: -1.809786533948671 loss: 0.4125105175211092\n",
            "Epoch: 218 w1: 4.120575943292204 w2: 1.2544880772815208 b: -1.8926301265631382 loss: 0.5030254154565724\n",
            "Epoch: 219 w1: 4.13377367927625 w2: 1.2420728543442494 b: -1.9050453495004096 loss: 0.42397288851846904\n",
            "Epoch: 220 w1: 4.122630422029642 w2: 1.1901760405492428 b: -1.9962042660177737 loss: 0.41409074880968244\n",
            "Epoch: 221 w1: 4.119010141090522 w2: 1.1586240827756646 b: -2.016553862339039 loss: 0.6192155146904075\n",
            "Epoch: 222 w1: 4.152279601675051 w2: 1.1800113180239686 b: -1.959240668363122 loss: 0.4505057476444504\n",
            "Epoch: 223 w1: 4.162205838286559 w2: 1.1752694028341908 b: -1.9448341280972246 loss: 0.5890309281935796\n",
            "Epoch: 224 w1: 4.190783114554653 w2: 1.182512288744829 b: -1.9326981507410907 loss: 0.31952207027001295\n",
            "Epoch: 225 w1: 4.192345252496118 w2: 1.2052612134735592 b: -1.950043303017749 loss: 0.39690909000519525\n",
            "Epoch: 226 w1: 4.20701126153542 w2: 1.1083266347435694 b: -1.9702879690390707 loss: 0.6210089375599422\n",
            "Epoch: 227 w1: 4.217805225092602 w2: 1.0188070258948898 b: -1.9995920792337822 loss: 0.6283504592914085\n",
            "Epoch: 228 w1: 4.177283748907442 w2: 0.9053228843226266 b: -2.1544600198448935 loss: 0.5917131411134763\n",
            "Epoch: 229 w1: 4.240392448509368 w2: 1.00914225244881 b: -2.0114948769755583 loss: 0.4790271704161782\n",
            "Epoch: 230 w1: 4.229188994737686 w2: 0.9757261893713625 b: -2.0530564319918674 loss: 0.6163282563782875\n",
            "Epoch: 231 w1: 4.264609297242354 w2: 1.0374082452245348 b: -2.011244951578823 loss: 0.3379048974654351\n",
            "Epoch: 232 w1: 4.316937413031188 w2: 1.113786267526531 b: -1.925214287500132 loss: 0.2766591981887935\n",
            "Epoch: 233 w1: 4.315291595956554 w2: 1.1391003514405749 b: -1.9590452059154266 loss: 0.3972491239732137\n",
            "Epoch: 234 w1: 4.3094676347650545 w2: 1.0806048338709622 b: -2.0003176957465816 loss: 0.654246826967297\n",
            "Epoch: 235 w1: 4.326681871389627 w2: 1.0522178947899736 b: -2.024098068221571 loss: 0.40904410309907047\n",
            "Epoch: 236 w1: 4.344332004775816 w2: 1.0899627532900422 b: -2.0235201768275184 loss: 0.353929898490646\n",
            "Epoch: 237 w1: 4.347751344185293 w2: 1.0638139569827831 b: -2.0704037105609805 loss: 0.38742596149219594\n",
            "Epoch: 238 w1: 4.360089696384099 w2: 1.009723475669356 b: -2.0725088075866847 loss: 0.6200023952430207\n",
            "Epoch: 239 w1: 4.358768860898597 w2: 0.9841143306507179 b: -2.0853272308213087 loss: 0.6134277444624658\n",
            "Epoch: 240 w1: 4.382484615005231 w2: 0.9178343220263705 b: -2.072983541791178 loss: 0.6036074526818427\n",
            "Epoch: 241 w1: 4.411680645318648 w2: 0.9573591614354938 b: -2.049485972053709 loss: 0.3132826960819438\n",
            "Epoch: 242 w1: 4.398029673573299 w2: 1.0036098342567141 b: -2.085662330339863 loss: 0.5050149912341837\n",
            "Epoch: 243 w1: 4.4054616376779805 w2: 1.0323038275307033 b: -2.0624624029182685 loss: 0.5860239231393579\n",
            "Epoch: 244 w1: 4.433014258252007 w2: 1.0454010427132554 b: -2.0493651877357166 loss: 0.3530452565977881\n",
            "Epoch: 245 w1: 4.4755478332289345 w2: 1.113317598032816 b: -1.981448632416156 loss: 0.31509009768496465\n",
            "Epoch: 246 w1: 4.4640951730221445 w2: 1.1212512637475405 b: -2.0395150854054442 loss: 0.3764651672277446\n",
            "Epoch: 247 w1: 4.4655082487463815 w2: 1.1357550318600493 b: -2.0643251102560476 loss: 0.45855352263045396\n",
            "Epoch: 248 w1: 4.43945522472019 w2: 1.094571432096484 b: -2.164462674411069 loss: 0.48008579752423636\n",
            "Epoch: 249 w1: 4.436163604386877 w2: 1.1300703765119802 b: -2.1886643547883287 loss: 0.44979949330031943\n",
            "Epoch: 250 w1: 4.44039196507751 w2: 1.1157829150804195 b: -2.187457398825646 loss: 0.6119458546870333\n",
            "Epoch: 251 w1: 4.4241886758937286 w2: 1.088248090907966 b: -2.2700090765136482 loss: 0.4119669132909142\n",
            "Epoch: 252 w1: 4.4478433097832 w2: 1.1200650238752303 b: -2.247884442405563 loss: 0.4156065492403643\n",
            "Epoch: 253 w1: 4.440705082878751 w2: 1.1442017382979024 b: -2.2926735942352288 loss: 0.4045960463367829\n",
            "Epoch: 254 w1: 4.459134996618318 w2: 1.1722069419594607 b: -2.2483799808082563 loss: 0.5463085363761734\n",
            "Epoch: 255 w1: 4.464819796624452 w2: 1.155527691789413 b: -2.247993755121069 loss: 0.593906602139394\n",
            "Epoch: 256 w1: 4.482259775931232 w2: 1.0941093050940411 b: -2.28127557835008 loss: 0.43395210060506306\n",
            "Epoch: 257 w1: 4.469045842429029 w2: 1.0869795633967447 b: -2.341192203122311 loss: 0.48040561601257054\n",
            "Epoch: 258 w1: 4.477828162812185 w2: 1.076156015796224 b: -2.3322245699469963 loss: 0.5892333219664364\n",
            "Epoch: 259 w1: 4.502222515469142 w2: 1.0694816937309288 b: -2.3007867751836297 loss: 0.5341378856101614\n",
            "Epoch: 260 w1: 4.519413827625802 w2: 1.083443698854475 b: -2.3042620948676347 loss: 0.41256481556057284\n",
            "Epoch: 261 w1: 4.530466500887304 w2: 1.1029146311288376 b: -2.2803768085945375 loss: 0.5374563684869336\n",
            "Epoch: 262 w1: 4.551853646117645 w2: 1.144753720192053 b: -2.2499954565085263 loss: 0.4786420258926376\n",
            "Epoch: 263 w1: 4.573978637893259 w2: 1.1771768496734292 b: -2.2280880666950518 loss: 0.42489911687400594\n",
            "Epoch: 264 w1: 4.610323232623533 w2: 1.202701674423221 b: -2.190468929211416 loss: 0.3367983768905635\n",
            "Epoch: 265 w1: 4.6208951358585555 w2: 1.1917015314157824 b: -2.220794763140091 loss: 0.35962114586349686\n",
            "Epoch: 266 w1: 4.644937720103651 w2: 1.2388693695640076 b: -2.1547292059505017 loss: 0.5351664424854848\n",
            "Epoch: 267 w1: 4.643572414496452 w2: 1.2319907029753752 b: -2.1654577282670795 loss: 0.5142718855152663\n",
            "Epoch: 268 w1: 4.644409840138099 w2: 1.148431751916762 b: -2.239544112714687 loss: 0.4832470925360629\n",
            "Epoch: 269 w1: 4.662658353766238 w2: 1.1797072916316902 b: -2.223378516214529 loss: 0.4133930280819115\n",
            "Epoch: 270 w1: 4.63092035367378 w2: 1.1023509470174113 b: -2.3548818469723742 loss: 0.5052517911100735\n",
            "Epoch: 271 w1: 4.647564302478359 w2: 1.0770934795225366 b: -2.342447708101996 loss: 0.5242465859251754\n",
            "Epoch: 272 w1: 4.652465660359915 w2: 1.1065903420175098 b: -2.363459445775966 loss: 0.3496541597082718\n",
            "Epoch: 273 w1: 4.710471312074462 w2: 1.193386630357679 b: -2.261727805251994 loss: 0.3023642464116896\n",
            "Epoch: 274 w1: 4.7159403474533175 w2: 1.203183627256214 b: -2.2521214060234103 loss: 0.5347196018555931\n",
            "Epoch: 275 w1: 4.744066961671331 w2: 1.1862739773692412 b: -2.24335096899569 loss: 0.3807561545001068\n",
            "Epoch: 276 w1: 4.754621546375554 w2: 1.175338708807166 b: -2.2305023962889234 loss: 0.5572819078397033\n",
            "Epoch: 277 w1: 4.778079636438833 w2: 1.210599848205766 b: -2.214531501726868 loss: 0.29672226248228567\n",
            "Epoch: 278 w1: 4.81473983723067 w2: 1.242189444052589 b: -2.130443701768498 loss: 0.48028120093850674\n",
            "Epoch: 279 w1: 4.803240593938425 w2: 1.1935042893297203 b: -2.19864623922544 loss: 0.5047348472514598\n",
            "Epoch: 280 w1: 4.808748036748857 w2: 1.167822322012112 b: -2.2397943096291053 loss: 0.35810386406452543\n",
            "Epoch: 281 w1: 4.802214468307146 w2: 1.1306145114562902 b: -2.2671095777894275 loss: 0.5865563121276786\n",
            "Epoch: 282 w1: 4.822168984760738 w2: 1.1122560842036373 b: -2.279340557081198 loss: 0.39179783601576806\n",
            "Epoch: 283 w1: 4.806870976837477 w2: 1.043464952649933 b: -2.3653453905192086 loss: 0.5410360962688292\n",
            "Epoch: 284 w1: 4.848161413793437 w2: 1.1039226049606508 b: -2.3094152806803505 loss: 0.27464546577497756\n",
            "Epoch: 285 w1: 4.829413807218508 w2: 1.0800818236381013 b: -2.3938110261273993 loss: 0.4181427648955315\n",
            "Epoch: 286 w1: 4.785046855411021 w2: 1.0261334421467267 b: -2.5259419261504816 loss: 0.5680665918654246\n",
            "Epoch: 287 w1: 4.791137645236337 w2: 0.9435619301076065 b: -2.5520286001016275 loss: 0.5826764334520814\n",
            "Epoch: 288 w1: 4.772335817136333 w2: 0.905401552942424 b: -2.6400423009332186 loss: 0.4296646147518269\n",
            "Epoch: 289 w1: 4.806985624887305 w2: 0.9030280100946314 b: -2.5845922809854396 loss: 0.5688505159617874\n",
            "Epoch: 290 w1: 4.857071389340167 w2: 0.9363642478746151 b: -2.520852079567678 loss: 0.41267892392382716\n",
            "Epoch: 291 w1: 4.903247508732952 w2: 1.029814938104893 b: -2.437020108860912 loss: 0.40157621404037736\n",
            "Epoch: 292 w1: 4.9092183796220805 w2: 1.046261590801141 b: -2.4188368252641794 loss: 0.5726798319591676\n",
            "Epoch: 293 w1: 4.899640092800977 w2: 1.0450957913947683 b: -2.4753820419093286 loss: 0.43549502654963446\n",
            "Epoch: 294 w1: 4.943806349898702 w2: 1.0853550152083038 b: -2.4201190452628736 loss: 0.328680792657644\n",
            "Epoch: 295 w1: 4.931464120196455 w2: 1.0487897530566461 b: -2.456241645928403 loss: 0.6198654715397404\n",
            "Epoch: 296 w1: 4.9169749591407355 w2: 1.0070408067313368 b: -2.5356337082203217 loss: 0.4582835086055134\n",
            "Epoch: 297 w1: 4.932181171567351 w2: 0.9797231066603066 b: -2.514420577075657 loss: 0.6301470802205291\n",
            "Epoch: 298 w1: 4.94373226823675 w2: 0.983702737214143 b: -2.491147515518094 loss: 0.609277045569183\n",
            "Epoch: 299 w1: 4.986614223708527 w2: 1.0336266473704947 b: -2.3981250128679377 loss: 0.5066790368290216\n",
            "Epoch: 300 w1: 4.986557221353337 w2: 1.0675092530028152 b: -2.379115758652056 loss: 0.613665188015809\n",
            "Epoch: 301 w1: 4.958346375076791 w2: 1.0359397324392001 b: -2.438318143546673 loss: 0.6919467182303289\n",
            "Epoch: 302 w1: 4.989644746983464 w2: 1.0909492591084355 b: -2.4004975256643615 loss: 0.3211857614559287\n",
            "Epoch: 303 w1: 5.005538022184552 w2: 1.1143393678565985 b: -2.39348131153111 loss: 0.3766098504147927\n",
            "Epoch: 304 w1: 4.98519526384155 w2: 1.044429033278105 b: -2.4939637282533273 loss: 0.5209130936021716\n",
            "Epoch: 305 w1: 5.000697287804758 w2: 1.042460313476978 b: -2.5124941985748332 loss: 0.3028208873681857\n",
            "Epoch: 306 w1: 5.0013457145272335 w2: 1.0025087222054272 b: -2.568823794500296 loss: 0.3981987341470003\n",
            "Epoch: 307 w1: 4.977652996428577 w2: 0.9556489408845206 b: -2.670317338993234 loss: 0.41519779515464555\n",
            "Epoch: 308 w1: 5.032291542981004 w2: 1.0272723466370837 b: -2.545242556561744 loss: 0.571994463506554\n",
            "Epoch: 309 w1: 5.04027143320187 w2: 0.970757558838397 b: -2.5578889021131292 loss: 0.5554914323025549\n",
            "Epoch: 310 w1: 5.019212923285885 w2: 0.9008789737478998 b: -2.6244415699862294 loss: 0.6243036428746221\n",
            "Epoch: 311 w1: 5.0294040405789415 w2: 0.897925376549765 b: -2.653768679734852 loss: 0.3000357192298811\n",
            "Epoch: 312 w1: 5.049781154397098 w2: 0.888262149438405 b: -2.663431906846212 loss: 0.3591864220415232\n",
            "Epoch: 313 w1: 5.080033689951309 w2: 0.9709431670143528 b: -2.615794794688803 loss: 0.41557148818456896\n",
            "Epoch: 314 w1: 5.127074509937822 w2: 0.9696106133622818 b: -2.5323391379686115 loss: 0.5539025916776155\n",
            "Epoch: 315 w1: 5.168861253109931 w2: 0.9894856797750872 b: -2.4862298203959567 loss: 0.3665912953114378\n",
            "Epoch: 316 w1: 5.157894287838946 w2: 0.9599607706907501 b: -2.5550564834372653 loss: 0.45754306668270317\n",
            "Epoch: 317 w1: 5.191433233545168 w2: 1.0131000652542976 b: -2.5182738575664447 loss: 0.2957265407937557\n",
            "Epoch: 318 w1: 5.205233371220835 w2: 0.9937070589894242 b: -2.5376668638313182 loss: 0.40383330563149294\n",
            "Epoch: 319 w1: 5.2293276362461585 w2: 0.9832317202342867 b: -2.50530995641354 loss: 0.48864738595253276\n",
            "Epoch: 320 w1: 5.239547630261751 w2: 0.9364682693908171 b: -2.5101103011118657 loss: 0.5665688173404397\n",
            "Epoch: 321 w1: 5.24038052572717 w2: 0.9012990094017087 b: -2.5624857072753304 loss: 0.40909802129550615\n",
            "Epoch: 322 w1: 5.227990627522207 w2: 0.8784639990338422 b: -2.6266962094615325 loss: 0.46343317345777\n",
            "Epoch: 323 w1: 5.290080748504029 w2: 0.9681390131448937 b: -2.4806546561251044 loss: 0.5710606798928134\n",
            "Epoch: 324 w1: 5.2616653921327705 w2: 0.9869495608886399 b: -2.5589047898645676 loss: 0.4478817945859196\n",
            "Epoch: 325 w1: 5.28353999998029 w2: 1.0202450152545848 b: -2.539137553267318 loss: 0.387349787445871\n",
            "Epoch: 326 w1: 5.299856361637274 w2: 1.0439906098042662 b: -2.5300063465008753 loss: 0.40381742712213164\n",
            "Epoch: 327 w1: 5.323747601542101 w2: 1.0442901253254222 b: -2.4918993619940593 loss: 0.5320949962786617\n",
            "Epoch: 328 w1: 5.367285101877908 w2: 1.088170674995836 b: -2.400937744316403 loss: 0.4310706928228002\n",
            "Epoch: 329 w1: 5.4020402028564245 w2: 1.1476735819134123 b: -2.321875881512346 loss: 0.40420545581628314\n",
            "Epoch: 330 w1: 5.40300433747433 w2: 1.196153005815922 b: -2.3329941997220676 loss: 0.277172597771388\n",
            "Epoch: 331 w1: 5.416158662526216 w2: 1.1793130833352308 b: -2.3498341222027586 loss: 0.32282903509841304\n",
            "Epoch: 332 w1: 5.410491818478548 w2: 1.1230779287359776 b: -2.4261100359802756 loss: 0.4435179469050325\n",
            "Epoch: 333 w1: 5.4140943261213215 w2: 1.1562834420440236 b: -2.4354504919553945 loss: 0.37113159342497254\n",
            "Epoch: 334 w1: 5.437691943292632 w2: 1.2190075038572667 b: -2.3617968124392332 loss: 0.463746227784331\n",
            "Epoch: 335 w1: 5.45780850239317 w2: 1.25255566207236 b: -2.3481977855449028 loss: 0.28285118323589575\n",
            "Epoch: 336 w1: 5.474984841275268 w2: 1.2573288579087087 b: -2.326819344129785 loss: 0.4436069381746163\n",
            "Epoch: 337 w1: 5.455127945367798 w2: 1.221869123589999 b: -2.4070782331348837 loss: 0.45486757126245125\n",
            "Epoch: 338 w1: 5.44059587981993 w2: 1.1927120809848846 b: -2.4795049438557597 loss: 0.39615676393865795\n",
            "Epoch: 339 w1: 5.503593027908459 w2: 1.2701611446084118 b: -2.3258312928525404 loss: 0.4297457316576562\n",
            "Epoch: 340 w1: 5.47978964760886 w2: 1.2302371150923952 b: -2.413501147814579 loss: 0.4649581101402723\n",
            "Epoch: 341 w1: 5.511821431896 w2: 1.2346348438196164 b: -2.349700668098669 loss: 0.5054085106925091\n",
            "Epoch: 342 w1: 5.50622729205853 w2: 1.1815500588739125 b: -2.3785906463453763 loss: 0.6218488902894413\n",
            "Epoch: 343 w1: 5.504803999653451 w2: 1.1243115672416877 b: -2.4358291379776014 loss: 0.4530351844919909\n",
            "Epoch: 344 w1: 5.5169844977664875 w2: 1.0922744196750174 b: -2.429066402070174 loss: 0.5333487815273602\n",
            "Epoch: 345 w1: 5.511155860524459 w2: 1.1229803082079044 b: -2.461088918591185 loss: 0.42231596121549053\n",
            "Epoch: 346 w1: 5.503332167021677 w2: 1.1458437025125194 b: -2.49782429018312 loss: 0.394104271973084\n",
            "Epoch: 347 w1: 5.491190475766521 w2: 1.10494758719649 b: -2.572328808625279 loss: 0.42830694309129175\n",
            "Epoch: 348 w1: 5.46764176492346 w2: 1.0542401761693143 b: -2.6666163775558984 loss: 0.4901107547096443\n",
            "Epoch: 349 w1: 5.5094324111179995 w2: 1.1174915702621635 b: -2.6033649834630492 loss: 0.2761956900631256\n",
            "Epoch: 350 w1: 5.495618870717945 w2: 1.1377344632878303 b: -2.6114799908160395 loss: 0.6627954088979392\n",
            "Epoch: 351 w1: 5.508829541970781 w2: 1.2198822232383397 b: -2.5846146570338955 loss: 0.3475080587616263\n",
            "Epoch: 352 w1: 5.502553880862779 w2: 1.2141154505644547 b: -2.631062894907717 loss: 0.4114402430619018\n",
            "Epoch: 353 w1: 5.469270418035791 w2: 1.1458161126212727 b: -2.7556991992807998 loss: 0.492458363569571\n",
            "Epoch: 354 w1: 5.513944122000685 w2: 1.2166962492341122 b: -2.638408347141664 loss: 0.5686456554111233\n",
            "Epoch: 355 w1: 5.512757001974721 w2: 1.1874049925837151 b: -2.6833036081367285 loss: 0.4267966333202429\n",
            "Epoch: 356 w1: 5.510498542735393 w2: 1.237596501873746 b: -2.6577774912962266 loss: 0.5713872158558407\n",
            "Epoch: 357 w1: 5.509343334711244 w2: 1.2197894702606913 b: -2.661992172544211 loss: 0.626678742787346\n",
            "Epoch: 358 w1: 5.5321692605930775 w2: 1.239892473639734 b: -2.6035562862250163 loss: 0.6084944428350764\n",
            "Epoch: 359 w1: 5.533788672892629 w2: 1.1668332324706647 b: -2.6339426384284677 loss: 0.5852482032737161\n",
            "Epoch: 360 w1: 5.566538010919015 w2: 1.2215642463743734 b: -2.5426949355536217 loss: 0.5269643841851887\n",
            "Epoch: 361 w1: 5.5595897116600455 w2: 1.1565336672970705 b: -2.620915903881378 loss: 0.4027725388402282\n",
            "Epoch: 362 w1: 5.576235761109504 w2: 1.110863858269926 b: -2.6113002285034788 loss: 0.550552887775785\n",
            "Epoch: 363 w1: 5.562243642734966 w2: 1.1562924451112597 b: -2.61232793254414 loss: 0.6107544536979833\n",
            "Epoch: 364 w1: 5.568580240912055 w2: 1.1459355107344633 b: -2.6396529080241162 loss: 0.36346244176164744\n",
            "Epoch: 365 w1: 5.579393969126714 w2: 1.1733381224551203 b: -2.6317314348094114 loss: 0.4415629771952322\n",
            "Epoch: 366 w1: 5.578114063372634 w2: 1.125230428018922 b: -2.696614589754661 loss: 0.365357432358882\n",
            "Epoch: 367 w1: 5.591890415591792 w2: 1.1777304271383857 b: -2.6834592358899414 loss: 0.3728252163467802\n",
            "Epoch: 368 w1: 5.601931179420798 w2: 1.1729665882434663 b: -2.6596094885939134 loss: 0.5975009861190385\n",
            "Epoch: 369 w1: 5.6393407139842715 w2: 1.2279055485116963 b: -2.6046705283256832 loss: 0.25292183046086497\n",
            "Epoch: 370 w1: 5.664997586521588 w2: 1.2953058648024693 b: -2.5239570683685306 loss: 0.48294250860257165\n",
            "Epoch: 371 w1: 5.6322337365928306 w2: 1.2184616729005804 b: -2.64678526864369 loss: 0.5163146153052277\n",
            "Epoch: 372 w1: 5.5694428719772056 w2: 1.0830560236980276 b: -2.8548160984096462 loss: 0.5684449585555672\n",
            "Epoch: 373 w1: 5.601075403538035 w2: 1.119979541671022 b: -2.8178925804366517 loss: 0.36984758768186243\n",
            "Epoch: 374 w1: 5.6564700194422635 w2: 1.2238003016506915 b: -2.714071820456982 loss: 0.23492227374968028\n",
            "Epoch: 375 w1: 5.6800176798721544 w2: 1.2392023680424207 b: -2.702248140085514 loss: 0.31473698900290886\n",
            "Epoch: 376 w1: 5.673925709288898 w2: 1.17822787336419 b: -2.774993019451605 loss: 0.3942277747787129\n",
            "Epoch: 377 w1: 5.680122517347857 w2: 1.1996968295932309 b: -2.7538510211852016 loss: 0.5575812959123433\n",
            "Epoch: 378 w1: 5.695898366674626 w2: 1.155968425663026 b: -2.7410457200979814 loss: 0.6000798789962768\n",
            "Epoch: 379 w1: 5.703938166157945 w2: 1.1013841693573334 b: -2.7873378462008214 loss: 0.3839474050666919\n",
            "Epoch: 380 w1: 5.664988864622914 w2: 1.0860594379419435 b: -2.89445771338606 loss: 0.48196831189376627\n",
            "Epoch: 381 w1: 5.672285953244953 w2: 1.1120165684284495 b: -2.9051313904832123 loss: 0.39176407604739777\n",
            "Epoch: 382 w1: 5.648881241270527 w2: 1.1393213758115919 b: -2.967655877059077 loss: 0.43819253856574986\n",
            "Epoch: 383 w1: 5.6618806924781095 w2: 1.1940585713034482 b: -2.9574321353139226 loss: 0.35240224765782074\n",
            "Epoch: 384 w1: 5.650696657128428 w2: 1.1898459033403455 b: -3.013337122488882 loss: 0.3916540195899527\n",
            "Epoch: 385 w1: 5.660417994709616 w2: 1.1889897766394828 b: -3.0357369794343003 loss: 0.2958817393982575\n",
            "Epoch: 386 w1: 5.663890191717861 w2: 1.2021811850098887 b: -3.0596429667995855 loss: 0.3501065544402665\n",
            "Epoch: 387 w1: 5.689745731288865 w2: 1.228718775779618 b: -3.041744363377104 loss: 0.3170554029177678\n",
            "Epoch: 388 w1: 5.739486442825172 w2: 1.2942423391970674 b: -2.959454234926339 loss: 0.38271600971417585\n",
            "Epoch: 389 w1: 5.734390480608836 w2: 1.2822728760572424 b: -3.0075857945126647 loss: 0.340377206526976\n",
            "Epoch: 390 w1: 5.730795679812135 w2: 1.21163085348236 b: -3.078227817087547 loss: 0.4030015328946158\n",
            "Epoch: 391 w1: 5.7315153332272955 w2: 1.1949592556504636 b: -3.081100464585559 loss: 0.5860393267119096\n",
            "Epoch: 392 w1: 5.73817067203638 w2: 1.198534578381179 b: -3.0972084992337456 loss: 0.4362465826099799\n",
            "Epoch: 393 w1: 5.7321423778427745 w2: 1.197634756796377 b: -3.1437465174404595 loss: 0.363625642832828\n",
            "Epoch: 394 w1: 5.810099970429552 w2: 1.3193776061391091 b: -2.9915287827852692 loss: 0.37033240251289695\n",
            "Epoch: 395 w1: 5.833422342847702 w2: 1.3802626687792658 b: -2.95232378245582 loss: 0.3411116483177496\n",
            "Epoch: 396 w1: 5.8579392047584085 w2: 1.361833825050082 b: -2.912418831163505 loss: 0.5102967090359611\n",
            "Epoch: 397 w1: 5.878055928303931 w2: 1.3653457989347035 b: -2.9089068572788834 loss: 0.30307078323961484\n",
            "Epoch: 398 w1: 5.894445514549729 w2: 1.3435528360751705 b: -2.8831610874971427 loss: 0.5616366047639719\n",
            "Epoch: 399 w1: 5.859216330658026 w2: 1.2675108368152266 b: -3.0117126575172386 loss: 0.43677067002008035\n",
            "Epoch: 400 w1: 5.891446395771655 w2: 1.3270703100587917 b: -2.9653085099389225 loss: 0.30784363222179356\n",
            "Epoch: 401 w1: 5.893205963455703 w2: 1.363535746306082 b: -2.9791764902035425 loss: 0.3452984974369286\n",
            "Epoch: 402 w1: 5.888093783388099 w2: 1.3648777528992844 b: -3.0182022837220477 loss: 0.40803160125931964\n",
            "Epoch: 403 w1: 5.9062186033729045 w2: 1.3261419713458582 b: -3.030216411146648 loss: 0.44770332102358523\n",
            "Epoch: 404 w1: 5.892353021986467 w2: 1.3888616410287213 b: -3.0566267968080596 loss: 0.3914453724065445\n",
            "Epoch: 405 w1: 5.868133173877123 w2: 1.3316531346481657 b: -3.1528290278600823 loss: 0.4352764854629175\n",
            "Epoch: 406 w1: 5.877275998004213 w2: 1.3265406545296106 b: -3.1315844577132195 loss: 0.6294502358004516\n",
            "Epoch: 407 w1: 5.880435927462958 w2: 1.367173700585783 b: -3.1404301240264925 loss: 0.3626776021891863\n",
            "Epoch: 408 w1: 5.891628218311213 w2: 1.4116076646891353 b: -3.1333843902962775 loss: 0.3419344211327974\n",
            "Epoch: 409 w1: 5.903552308441586 w2: 1.419589502022511 b: -3.1457959082130422 loss: 0.3126935813088423\n",
            "Epoch: 410 w1: 5.891097226190523 w2: 1.3815760561491375 b: -3.2181680644158464 loss: 0.39251128976367383\n",
            "Epoch: 411 w1: 5.908663820510569 w2: 1.338918742693905 b: -3.2000131723109027 loss: 0.5847179881276524\n",
            "Epoch: 412 w1: 5.904221550513208 w2: 1.3016156260468617 b: -3.256643002852213 loss: 0.36368058953230753\n",
            "Epoch: 413 w1: 5.932512356506495 w2: 1.3434460577568474 b: -3.2197168105749676 loss: 0.3855375798981374\n",
            "Epoch: 414 w1: 5.931613739709848 w2: 1.3473592854387844 b: -3.252288552261089 loss: 0.3491372277629326\n",
            "Epoch: 415 w1: 5.965383372490375 w2: 1.3725068952045993 b: -3.171727953013571 loss: 0.6328353907549368\n",
            "Epoch: 416 w1: 5.935035790777524 w2: 1.3562101117494976 b: -3.260157308934058 loss: 0.43776995408614455\n",
            "Epoch: 417 w1: 5.987201593665436 w2: 1.404206185775873 b: -3.1817793603117157 loss: 0.3028024434012229\n",
            "Epoch: 418 w1: 5.9602609344311 w2: 1.394898804701384 b: -3.26327708589361 loss: 0.42321413789811174\n",
            "Epoch: 419 w1: 5.984839841309191 w2: 1.3834756274549231 b: -3.2212202500995573 loss: 0.5174633919270464\n",
            "Epoch: 420 w1: 5.997826676143436 w2: 1.3642566468437198 b: -3.2404392307107606 loss: 0.35294219083946493\n",
            "Epoch: 421 w1: 6.0110387645599275 w2: 1.3988685124705944 b: -3.2321975190257852 loss: 0.2956233919847597\n",
            "Epoch: 422 w1: 6.0468109700180115 w2: 1.4303833157973043 b: -3.1513379564824633 loss: 0.4968720444651585\n",
            "Epoch: 423 w1: 6.071709219305167 w2: 1.4215537684833293 b: -3.14501702446631 loss: 0.3312727986652911\n",
            "Epoch: 424 w1: 6.106987137466467 w2: 1.473451300310626 b: -3.0931194926390133 loss: 0.2546538771997664\n",
            "Epoch: 425 w1: 6.1401844616297705 w2: 1.4979711884380065 b: -3.0557886498654527 loss: 0.2729018582525488\n",
            "Epoch: 426 w1: 6.165445674836143 w2: 1.4898623639753326 b: -3.039048109302836 loss: 0.40587644771125336\n",
            "Epoch: 427 w1: 6.1824387556707165 w2: 1.4616397504749163 b: -3.052494134122921 loss: 0.3255987371947608\n",
            "Epoch: 428 w1: 6.212881771622707 w2: 1.4843212860920785 b: -2.9849671677691068 loss: 0.4555550490669927\n",
            "Epoch: 429 w1: 6.213624050171342 w2: 1.4823950641098511 b: -2.9794115338621436 loss: 0.5323747598386582\n",
            "Epoch: 430 w1: 6.155825552284555 w2: 1.3980269626820092 b: -3.147378926390205 loss: 0.5557290092361657\n",
            "Epoch: 431 w1: 6.124822949911031 w2: 1.3535467127046914 b: -3.208967603122332 loss: 0.688623357801713\n",
            "Epoch: 432 w1: 6.142405348350751 w2: 1.43313737978031 b: -3.1764963372322725 loss: 0.30710250298759867\n",
            "Epoch: 433 w1: 6.143603537783825 w2: 1.4670262097416604 b: -3.1908402872858237 loss: 0.35151796774150906\n",
            "Epoch: 434 w1: 6.16459713164226 w2: 1.4884834321273237 b: -3.1777224815371263 loss: 0.19604713535061605\n",
            "Epoch: 435 w1: 6.1690555363964314 w2: 1.4563279965683886 b: -3.2183441654306733 loss: 0.35918979716978444\n",
            "Epoch: 436 w1: 6.151858543517296 w2: 1.4116638310302252 b: -3.2946111960805755 loss: 0.4377620265248376\n",
            "Epoch: 437 w1: 6.1883115606054835 w2: 1.4375370380959167 b: -3.2154400745443583 loss: 0.4667367279640416\n",
            "Epoch: 438 w1: 6.187757944006078 w2: 1.45038769423226 b: -3.238348024402594 loss: 0.44540669281557355\n",
            "Epoch: 439 w1: 6.174382022510104 w2: 1.428588041670037 b: -3.3035476558997425 loss: 0.33436992467291615\n",
            "Epoch: 440 w1: 6.233984061985247 w2: 1.482992393946962 b: -3.1671375475444314 loss: 0.48571404059676937\n",
            "Epoch: 441 w1: 6.285460553225546 w2: 1.5529949496946498 b: -3.0376190849694344 loss: 0.4101308524941775\n",
            "Epoch: 442 w1: 6.302370010413776 w2: 1.5783150143814326 b: -2.9839495716660114 loss: 0.5021595436360907\n",
            "Epoch: 443 w1: 6.304588295727215 w2: 1.5812232584114831 b: -2.967812533834277 loss: 0.5431439834461677\n",
            "Epoch: 444 w1: 6.345339627961075 w2: 1.591187121754263 b: -2.8787274770102003 loss: 0.49007447713531843\n",
            "Epoch: 445 w1: 6.328297898113356 w2: 1.5867691483234736 b: -2.929446637196047 loss: 0.3723845512640572\n",
            "Epoch: 446 w1: 6.3613821718202885 w2: 1.6085763765290921 b: -2.850946574927389 loss: 0.45666440916296597\n",
            "Epoch: 447 w1: 6.3507040025267845 w2: 1.5389429435699633 b: -2.888970305381326 loss: 0.6801582198607792\n",
            "Epoch: 448 w1: 6.367245877727465 w2: 1.5336910036442932 b: -2.885088260131779 loss: 0.2879785179569117\n",
            "Epoch: 449 w1: 6.360206956919401 w2: 1.4817380391972947 b: -2.9483067457495253 loss: 0.326602674127727\n",
            "Epoch: 450 w1: 6.410638021221511 w2: 1.528323440921208 b: -2.8237795871120452 loss: 0.37872496222250845\n",
            "Epoch: 451 w1: 6.393412781815784 w2: 1.475185295804907 b: -2.8783224549453297 loss: 0.6198414475564661\n",
            "Epoch: 452 w1: 6.405298859953286 w2: 1.4669335189178254 b: -2.8944730804002496 loss: 0.25964762039925454\n",
            "Epoch: 453 w1: 6.4333121418519905 w2: 1.4803421184857442 b: -2.861125546341507 loss: 0.25831101443578736\n",
            "Epoch: 454 w1: 6.421499261368529 w2: 1.4266768762613211 b: -2.9430881182823567 loss: 0.3135136933969749\n",
            "Epoch: 455 w1: 6.393789971707062 w2: 1.3824984225587127 b: -3.040783212596466 loss: 0.43204905327001997\n",
            "Epoch: 456 w1: 6.393462776324703 w2: 1.4148805017537356 b: -3.052455127494222 loss: 0.36157093913919175\n",
            "Epoch: 457 w1: 6.374984875414606 w2: 1.3946105725799904 b: -3.127510956254385 loss: 0.4146492315212656\n",
            "Epoch: 458 w1: 6.368560363077048 w2: 1.4000886281866742 b: -3.1644305387085927 loss: 0.40867124425683976\n",
            "Epoch: 459 w1: 6.359743428020958 w2: 1.3191017672121037 b: -3.2454173996831632 loss: 0.4013213341733464\n",
            "Epoch: 460 w1: 6.353147239934458 w2: 1.3380602120798195 b: -3.2835941127073047 loss: 0.3161319947929993\n",
            "Epoch: 461 w1: 6.39080963630581 w2: 1.3725897403688476 b: -3.1966704059361906 loss: 0.49423173695057\n",
            "Epoch: 462 w1: 6.414122524653615 w2: 1.3930040221458404 b: -3.1334910620627525 loss: 0.6237053586944797\n",
            "Epoch: 463 w1: 6.429726919400526 w2: 1.3146425422756327 b: -3.1296740161345857 loss: 0.6003630325526749\n",
            "Epoch: 464 w1: 6.453870309892175 w2: 1.276257348335336 b: -3.0953975100274667 loss: 0.5262259721767382\n",
            "Epoch: 465 w1: 6.4991742100134005 w2: 1.2911337176788946 b: -2.9998177852807077 loss: 0.46340725450524684\n",
            "Epoch: 466 w1: 6.479238032584047 w2: 1.3243655353913948 b: -3.0128686556440196 loss: 0.6105156655557332\n",
            "Epoch: 467 w1: 6.453998743556182 w2: 1.2464227852538436 b: -3.115098419218961 loss: 0.5067675717711596\n",
            "Epoch: 468 w1: 6.438382816593402 w2: 1.1806999528287632 b: -3.198015737121802 loss: 0.43256783691820383\n",
            "Epoch: 469 w1: 6.452952307929537 w2: 1.2550229881549457 b: -3.174855822730117 loss: 0.30725027540390076\n",
            "Epoch: 470 w1: 6.500528933279371 w2: 1.310181685688285 b: -3.095947379351003 loss: 0.2918814976153377\n",
            "Epoch: 471 w1: 6.509217113010535 w2: 1.3355721854129445 b: -3.0925926891525255 loss: 0.3966311329400122\n",
            "Epoch: 472 w1: 6.470854724182148 w2: 1.3183013540979314 b: -3.1950097010407217 loss: 0.5105961485743444\n",
            "Epoch: 473 w1: 6.489656407561567 w2: 1.3728140184468152 b: -3.132932132781249 loss: 0.514311780310688\n",
            "Epoch: 474 w1: 6.52726484571866 w2: 1.3633506618023585 b: -3.0611385483674542 loss: 0.5690527321818296\n",
            "Epoch: 475 w1: 6.531829039771833 w2: 1.298997554887931 b: -3.1141330850681817 loss: 0.3554416663014712\n",
            "Epoch: 476 w1: 6.513909837853133 w2: 1.3119212558478135 b: -3.1639620922130502 loss: 0.4727553675979149\n",
            "Epoch: 477 w1: 6.493966333082483 w2: 1.365586438970209 b: -3.202147974081402 loss: 0.38938258678032966\n",
            "Epoch: 478 w1: 6.526065880324253 w2: 1.3922921470725638 b: -3.164534857603411 loss: 0.27672088279059953\n",
            "Epoch: 479 w1: 6.556046258683619 w2: 1.4154181398429597 b: -3.131887652056368 loss: 0.2790603459316073\n",
            "Epoch: 480 w1: 6.570057877831305 w2: 1.4607099367297476 b: -3.108500279241538 loss: 0.28704274536231905\n",
            "Epoch: 481 w1: 6.582329393711758 w2: 1.4538491210944706 b: -3.115361094876815 loss: 0.3423827358002847\n",
            "Epoch: 482 w1: 6.56326349541238 w2: 1.4207549044751784 b: -3.1896169371888954 loss: 0.3756109703086379\n",
            "Epoch: 483 w1: 6.5847808698716195 w2: 1.4347771305816865 b: -3.175594711082387 loss: 0.30452844986482214\n",
            "Epoch: 484 w1: 6.585440942876453 w2: 1.469169730739218 b: -3.184751828911279 loss: 0.3528503312840793\n",
            "Epoch: 485 w1: 6.5741503381408535 w2: 1.4531127380035946 b: -3.2407826904444357 loss: 0.3740074061272584\n",
            "Epoch: 486 w1: 6.605221725136118 w2: 1.4956960016090055 b: -3.154035387773642 loss: 0.5176297951117433\n",
            "Epoch: 487 w1: 6.6185466748432935 w2: 1.4427882959796283 b: -3.1485158586476216 loss: 0.5769449039980963\n",
            "Epoch: 488 w1: 6.620013273222465 w2: 1.4515752191406648 b: -3.168206349515886 loss: 0.36670720916661687\n",
            "Epoch: 489 w1: 6.626337199885491 w2: 1.4301496256863415 b: -3.19884162089986 loss: 0.25227593818710947\n",
            "Epoch: 490 w1: 6.633561881275119 w2: 1.4164172431384563 b: -3.221550125170136 loss: 0.32259696196138893\n",
            "Epoch: 491 w1: 6.640371954483288 w2: 1.357481147771627 b: -3.2665138631622055 loss: 0.3517915569940377\n",
            "Epoch: 492 w1: 6.62114753633108 w2: 1.337365139848356 b: -3.3382740166796667 loss: 0.40436120455358476\n",
            "Epoch: 493 w1: 6.637052452021066 w2: 1.3840536765991178 b: -3.315855726322115 loss: 0.3029541140371518\n",
            "Epoch: 494 w1: 6.631778293216785 w2: 1.3273859362499063 b: -3.3806353723259077 loss: 0.3033885590228088\n",
            "Epoch: 495 w1: 6.654441718400506 w2: 1.3346747613804228 b: -3.367107817976294 loss: 0.27717604049750394\n",
            "Epoch: 496 w1: 6.644768715401383 w2: 1.2865117616383208 b: -3.3957493259147897 loss: 0.6308481927657192\n",
            "Epoch: 497 w1: 6.641456946462502 w2: 1.2485035694853535 b: -3.4526563673423194 loss: 0.28181468034478563\n",
            "Epoch: 498 w1: 6.681828509903247 w2: 1.3137030577840623 b: -3.3874568790436106 loss: 0.26436804956050103\n",
            "Epoch: 499 w1: 6.718142773618826 w2: 1.3871330108888655 b: -3.3255329563226153 loss: 0.18809298360493085\n",
            "Epoch: 500 w1: 6.74572639996958 w2: 1.3788523965545696 b: -3.2739314753022044 loss: 0.47967573386800255\n",
            "Epoch: 501 w1: 6.750375493324548 w2: 1.4458465639192202 b: -3.263138218167605 loss: 0.31404888871970954\n",
            "Epoch: 502 w1: 6.787857540855466 w2: 1.4580580423833491 b: -3.1823454771534476 loss: 0.5072128938829744\n",
            "Epoch: 503 w1: 6.759260426419164 w2: 1.3968029623649634 b: -3.288912131480146 loss: 0.4339247922596469\n",
            "Epoch: 504 w1: 6.777382101670531 w2: 1.3933245808861692 b: -3.2541474288194636 loss: 0.42092983060106437\n",
            "Epoch: 505 w1: 6.800792739703459 w2: 1.421444316571678 b: -3.226027693133955 loss: 0.24262838209711482\n",
            "Epoch: 506 w1: 6.837357077144321 w2: 1.4554924605590909 b: -3.1706580754645026 loss: 0.2735596904609762\n",
            "Epoch: 507 w1: 6.828249923197295 w2: 1.451464709947514 b: -3.176867483444352 loss: 0.6103935265222585\n",
            "Epoch: 508 w1: 6.829952567452648 w2: 1.3778820812641812 b: -3.2018371528254677 loss: 0.5710749320634202\n",
            "Epoch: 509 w1: 6.8649716048320215 w2: 1.4066157286081897 b: -3.114765638465916 loss: 0.49659534185223647\n",
            "Epoch: 510 w1: 6.891930326147986 w2: 1.4175408889668963 b: -3.0566003269000186 loss: 0.40542611755966496\n",
            "Epoch: 511 w1: 6.8855239675257796 w2: 1.4057317188004526 b: -3.0673953045668374 loss: 0.4970546301401904\n",
            "Epoch: 512 w1: 6.826384706932988 w2: 1.3569059669659245 b: -3.2245132082886565 loss: 0.5428537582161926\n",
            "Epoch: 513 w1: 6.848868561459622 w2: 1.3964784959883296 b: -3.1985160326232664 loss: 0.25413874039698403\n",
            "Epoch: 514 w1: 6.863807681953817 w2: 1.3741482610859137 b: -3.2096739157166048 loss: 0.3146839383550016\n",
            "Epoch: 515 w1: 6.905954983090604 w2: 1.462211946131683 b: -3.1216102306708358 loss: 0.19667550595878464\n",
            "Epoch: 516 w1: 6.874235495141262 w2: 1.4259772797298778 b: -3.220188144903393 loss: 0.48936806626162266\n",
            "Epoch: 517 w1: 6.918409330249186 w2: 1.4440791055773556 b: -3.1230881693499666 loss: 0.45343942551935024\n",
            "Epoch: 518 w1: 6.886675022186498 w2: 1.3720945110755862 b: -3.2391045259808386 loss: 0.4714932032379551\n",
            "Epoch: 519 w1: 6.892746199775195 w2: 1.330265145382486 b: -3.2737703389146127 loss: 0.2854301660328392\n",
            "Epoch: 520 w1: 6.882358608799917 w2: 1.3426183940559022 b: -3.3158581148225745 loss: 0.3553728461372138\n",
            "Epoch: 521 w1: 6.840021543247233 w2: 1.332099651000122 b: -3.419159747418941 loss: 0.4210620012237749\n",
            "Epoch: 522 w1: 6.8392773293518605 w2: 1.3335156147932734 b: -3.4432376960777953 loss: 0.36208731453144377\n",
            "Epoch: 523 w1: 6.856680933017905 w2: 1.3257010446291533 b: -3.445576345309461 loss: 0.3267984172464504\n",
            "Epoch: 524 w1: 6.895916993999807 w2: 1.3654744233935503 b: -3.352618188778657 loss: 0.47559426077554606\n",
            "Epoch: 525 w1: 6.936411294333155 w2: 1.3763012114589883 b: -3.267904414013717 loss: 0.4586707022472007\n",
            "Epoch: 526 w1: 6.978743418978973 w2: 1.4373915463494538 b: -3.156956436550539 loss: 0.40301175976917714\n",
            "Epoch: 527 w1: 6.960687098422524 w2: 1.4097614346740717 b: -3.2285761687870353 loss: 0.36985719556782287\n",
            "Epoch: 528 w1: 6.975400043060755 w2: 1.3795326292210497 b: -3.238853530678894 loss: 0.31825552806967916\n",
            "Epoch: 529 w1: 7.024091894065458 w2: 1.449946818278148 b: -3.1100944783267312 loss: 0.398943923123421\n",
            "Epoch: 530 w1: 7.035092547332604 w2: 1.4548259084744042 b: -3.115562357748832 loss: 0.18822696714423034\n",
            "Epoch: 531 w1: 7.029388466084749 w2: 1.4561301422496848 b: -3.1450638887963627 loss: 0.3627298716030375\n",
            "Epoch: 532 w1: 6.982917907100885 w2: 1.4016766206497282 b: -3.2740025496216676 loss: 0.5452212733229855\n",
            "Epoch: 533 w1: 6.979918430984658 w2: 1.3362030855518552 b: -3.341457095603628 loss: 0.36490873927361184\n",
            "Epoch: 534 w1: 6.973161285952372 w2: 1.3451992737440943 b: -3.376880277536872 loss: 0.3924489639036813\n",
            "Epoch: 535 w1: 6.940201144510385 w2: 1.2587378444103157 b: -3.5034824655469374 loss: 0.41220159939457984\n",
            "Epoch: 536 w1: 6.962024035677428 w2: 1.247197364974967 b: -3.497917480834968 loss: 0.2830643576484257\n",
            "Epoch: 537 w1: 6.955862695994277 w2: 1.3181530158479569 b: -3.5064329698753003 loss: 0.3929489495151204\n",
            "Epoch: 538 w1: 6.922730908478231 w2: 1.3101269206987558 b: -3.5935145881560833 loss: 0.4820960789779699\n",
            "Epoch: 539 w1: 6.934482151536608 w2: 1.2517548186362215 b: -3.5900562128485545 loss: 0.5596953139422222\n",
            "Epoch: 540 w1: 6.932144480394414 w2: 1.2641206381654988 b: -3.61738643188362 loss: 0.3853897009337583\n",
            "Epoch: 541 w1: 6.960619333436015 w2: 1.2936671864955895 b: -3.5878398835535292 loss: 0.27006607802402244\n",
            "Epoch: 542 w1: 6.989186083615054 w2: 1.3621130840191906 b: -3.536892845636309 loss: 0.33658058805174146\n",
            "Epoch: 543 w1: 7.021677535460378 w2: 1.4361416436887147 b: -3.4391124231200014 loss: 0.5514227941744922\n",
            "Epoch: 544 w1: 7.0367770461844135 w2: 1.433468394829366 b: -3.44178567197935 loss: 0.262492462209935\n",
            "Epoch: 545 w1: 7.038602229625329 w2: 1.4198400134302886 b: -3.434762221433508 loss: 0.5968552731323447\n",
            "Epoch: 546 w1: 7.0196464749581535 w2: 1.3928465171438549 b: -3.509286983808034 loss: 0.3389618223010968\n",
            "Epoch: 547 w1: 7.0270623628815985 w2: 1.3919044054670018 b: -3.5286941112259314 loss: 0.2790983952586996\n",
            "Epoch: 548 w1: 6.986495905352646 w2: 1.3592333693178404 b: -3.6409771731938885 loss: 0.5023687294107555\n",
            "Epoch: 549 w1: 6.978383136032915 w2: 1.349362158850258 b: -3.643943714367386 loss: 0.6662515349416022\n",
            "Epoch: 550 w1: 7.013617444319841 w2: 1.332968938326745 b: -3.5783620295102874 loss: 0.545390500410376\n",
            "Epoch: 551 w1: 7.0659656938061 w2: 1.412207241379446 b: -3.444449055581991 loss: 0.47978920557561666\n",
            "Epoch: 552 w1: 7.02143361912394 w2: 1.385587892897671 b: -3.5621268240671955 loss: 0.46115036813667404\n",
            "Epoch: 553 w1: 7.0694685680500156 w2: 1.4415457120934831 b: -3.4448139438171683 loss: 0.5213104678794577\n",
            "Epoch: 554 w1: 7.0758983092075205 w2: 1.4303452576325864 b: -3.4679458288469913 loss: 0.3028205707608305\n",
            "Epoch: 555 w1: 7.0629462057969015 w2: 1.3910043813608797 b: -3.498098071058588 loss: 0.6283379186109403\n",
            "Epoch: 556 w1: 7.067433781746321 w2: 1.4335403154040345 b: -3.498093940186531 loss: 0.35488026346445006\n",
            "Epoch: 557 w1: 7.063727248429392 w2: 1.4640948016450095 b: -3.51753083759736 loss: 0.343223029633132\n",
            "Epoch: 558 w1: 7.028711584053913 w2: 1.4661755763422915 b: -3.603425938864828 loss: 0.391444043649083\n",
            "Epoch: 559 w1: 7.011633493708383 w2: 1.4766780578698928 b: -3.651545515037883 loss: 0.4220767308562453\n",
            "Epoch: 560 w1: 7.045083520011727 w2: 1.4869606420250308 b: -3.615219754727136 loss: 0.3306642767854626\n",
            "Epoch: 561 w1: 7.059341772622162 w2: 1.527645667587553 b: -3.5963893966123774 loss: 0.2824605674641613\n",
            "Epoch: 562 w1: 7.06193427414937 w2: 1.535559219993746 b: -3.574478697570381 loss: 0.6047381677823305\n",
            "Epoch: 563 w1: 7.045462319456401 w2: 1.5112869252555874 b: -3.643126962759635 loss: 0.3166716711046861\n",
            "Epoch: 564 w1: 7.075012722413231 w2: 1.5088293479432278 b: -3.6200146729134364 loss: 0.2682100428123108\n",
            "Epoch: 565 w1: 7.076406914048116 w2: 1.489738012781448 b: -3.656062459159652 loss: 0.25678963155593076\n",
            "Epoch: 566 w1: 7.115463269079975 w2: 1.5722474401176232 b: -3.5799938389658803 loss: 0.20161231957815673\n",
            "Epoch: 567 w1: 7.0985282701473436 w2: 1.5519589279780206 b: -3.6418975940504104 loss: 0.38837186110614075\n",
            "Epoch: 568 w1: 7.1213835998114865 w2: 1.5339311215755607 b: -3.598058146243805 loss: 0.53120498025684\n",
            "Epoch: 569 w1: 7.134979828665061 w2: 1.6059945916035305 b: -3.5673523969502607 loss: 0.28307894578342646\n",
            "Epoch: 570 w1: 7.127640740085082 w2: 1.545976726931362 b: -3.6382896272319436 loss: 0.27590775995064315\n",
            "Epoch: 571 w1: 7.117194109532365 w2: 1.610676902654212 b: -3.6512344102578456 loss: 0.371520948233992\n",
            "Epoch: 572 w1: 7.169245375270664 w2: 1.6429855278743948 b: -3.5320206158423213 loss: 0.5298892076626373\n",
            "Epoch: 573 w1: 7.171899485067306 w2: 1.5984649212222086 b: -3.5765412224945075 loss: 0.30985123034811146\n",
            "Epoch: 574 w1: 7.1563486201729996 w2: 1.539200856683291 b: -3.6168652716532548 loss: 0.7051981915120091\n",
            "Epoch: 575 w1: 7.182067703446032 w2: 1.5672980153412979 b: -3.588768112995248 loss: 0.2910540905163894\n",
            "Epoch: 576 w1: 7.178106867007247 w2: 1.587245752853383 b: -3.614106993392008 loss: 0.3086659812597211\n",
            "Epoch: 577 w1: 7.208656999725598 w2: 1.6036529493789138 b: -3.543043418825314 loss: 0.43813040489366034\n",
            "Epoch: 578 w1: 7.234477512152815 w2: 1.612038992943226 b: -3.481183530030598 loss: 0.4918716519271577\n",
            "Epoch: 579 w1: 7.252550322833446 w2: 1.6176718285690626 b: -3.474047949773888 loss: 0.26245986489839557\n",
            "Epoch: 580 w1: 7.254821298095344 w2: 1.570927096985222 b: -3.5207926813577286 loss: 0.3111994374488792\n",
            "Epoch: 581 w1: 7.271135391426419 w2: 1.5718678663106043 b: -3.519851912032346 loss: 0.2567540528614415\n",
            "Epoch: 582 w1: 7.284617234126291 w2: 1.568326796577773 b: -3.5233929817651775 loss: 0.276607194653464\n",
            "Epoch: 583 w1: 7.283861460734516 w2: 1.5760826145747804 b: -3.5111069713073415 loss: 0.5616972532820399\n",
            "Epoch: 584 w1: 7.284570553522896 w2: 1.5764645332629923 b: -3.494799679337742 loss: 0.5530499744999812\n",
            "Epoch: 585 w1: 7.297514194283633 w2: 1.5228832938731953 b: -3.4882335765274393 loss: 0.5521117631228479\n",
            "Epoch: 586 w1: 7.2689628567915285 w2: 1.4659455443259268 b: -3.594096715614005 loss: 0.4173223849132192\n",
            "Epoch: 587 w1: 7.270571407882984 w2: 1.4720501621148623 b: -3.60817357077937 loss: 0.36581706816421583\n",
            "Epoch: 588 w1: 7.274339035203978 w2: 1.4367288648227676 b: -3.6020328022050823 loss: 0.6378952287403789\n",
            "Epoch: 589 w1: 7.290012023049387 w2: 1.4705819475200308 b: -3.5843900829993567 loss: 0.36158614569449143\n",
            "Epoch: 590 w1: 7.310756945944457 w2: 1.4981909952427166 b: -3.5639106397960716 loss: 0.19509857118132326\n",
            "Epoch: 591 w1: 7.316344656257567 w2: 1.5156484109113002 b: -3.568387480837556 loss: 0.3500391436321658\n",
            "Epoch: 592 w1: 7.299593286836859 w2: 1.5290220929181129 b: -3.617344365077769 loss: 0.38630625863863255\n",
            "Epoch: 593 w1: 7.31635945769087 w2: 1.5111381534043187 b: -3.5848508117074642 loss: 0.5744583198721106\n",
            "Epoch: 594 w1: 7.340226963875833 w2: 1.5691084619911309 b: -3.505595955874122 loss: 0.5161198122275309\n",
            "Epoch: 595 w1: 7.347065980196974 w2: 1.6080233983613017 b: -3.463579167677452 loss: 0.5160396193432594\n",
            "Epoch: 596 w1: 7.316196518908255 w2: 1.5440786804711824 b: -3.573270138418483 loss: 0.44036049606116084\n",
            "Epoch: 597 w1: 7.303689392569647 w2: 1.5570841492837832 b: -3.618627889038924 loss: 0.3157353961967807\n",
            "Epoch: 598 w1: 7.2859778412451535 w2: 1.5473292830102696 b: -3.681969708034856 loss: 0.37941194676438966\n",
            "Epoch: 599 w1: 7.299936233064446 w2: 1.5437992901198123 b: -3.6854997009253134 loss: 0.25881514912823494\n",
            "Epoch: 600 w1: 7.282623431874846 w2: 1.5483279371391874 b: -3.6983896931191524 loss: 0.6954384164932883\n",
            "Epoch: 601 w1: 7.299091290207617 w2: 1.52204824002943 b: -3.7069323783241375 loss: 0.25205259537480457\n",
            "Epoch: 602 w1: 7.308739882852211 w2: 1.5797754977373484 b: -3.6903687981588527 loss: 0.38465747014103335\n",
            "Epoch: 603 w1: 7.2919751675270605 w2: 1.5192343564656068 b: -3.7686723112783436 loss: 0.4560764107125347\n",
            "Epoch: 604 w1: 7.311692029513873 w2: 1.5276743646292716 b: -3.712543412193205 loss: 0.6527776796503072\n",
            "Epoch: 605 w1: 7.313041045671569 w2: 1.4940505876450638 b: -3.752539316290683 loss: 0.32364538207837784\n",
            "Epoch: 606 w1: 7.3360304384281285 w2: 1.5297064483741605 b: -3.726579033375717 loss: 0.22100389178968657\n",
            "Epoch: 607 w1: 7.372488188260178 w2: 1.584055044991961 b: -3.6233452295229287 loss: 0.5785775782856005\n",
            "Epoch: 608 w1: 7.343202928620409 w2: 1.4967719340650085 b: -3.738915385910495 loss: 0.4490055335493422\n",
            "Epoch: 609 w1: 7.34950847748273 w2: 1.5144709759332997 b: -3.7442738244293627 loss: 0.32702138745441683\n",
            "Epoch: 610 w1: 7.379520847520481 w2: 1.4766506884304575 b: -3.6956519177529636 loss: 0.6010783641115128\n",
            "Epoch: 611 w1: 7.368619284798226 w2: 1.4874054586378942 b: -3.740018690234412 loss: 0.2879119336463334\n",
            "Epoch: 612 w1: 7.334124944458768 w2: 1.4733150054749113 b: -3.8327126657789274 loss: 0.428768624912065\n",
            "Epoch: 613 w1: 7.2954253440442445 w2: 1.4534125693255 b: -3.9363697674557385 loss: 0.37120411875421755\n",
            "Epoch: 614 w1: 7.3002919379009725 w2: 1.4954904904232778 b: -3.939586916973711 loss: 0.3209762953470721\n",
            "Epoch: 615 w1: 7.302635864649777 w2: 1.484918979378285 b: -3.9635523369300762 loss: 0.3982119701578088\n",
            "Epoch: 616 w1: 7.331360059594519 w2: 1.5220136222439422 b: -3.9264576940644194 loss: 0.3243360491765742\n",
            "Epoch: 617 w1: 7.351312266355607 w2: 1.4922638390633953 b: -3.8926159557004296 loss: 0.5834775684197533\n",
            "Epoch: 618 w1: 7.39001577614782 w2: 1.516978452980752 b: -3.8045848764245713 loss: 0.5584127356314048\n",
            "Epoch: 619 w1: 7.404875562141485 w2: 1.5384571932701039 b: -3.7946713966089463 loss: 0.2989687031768131\n",
            "Epoch: 620 w1: 7.403825224604474 w2: 1.554288004100018 b: -3.815552181707909 loss: 0.25740729808794854\n",
            "Epoch: 621 w1: 7.446274179531438 w2: 1.5690368667936312 b: -3.7226534619811824 loss: 0.523417583113341\n",
            "Epoch: 622 w1: 7.467570432168497 w2: 1.594389056116099 b: -3.6973012726587147 loss: 0.2252099654454081\n",
            "Epoch: 623 w1: 7.484985434058606 w2: 1.650798570474986 b: -3.6641507744520063 loss: 0.3088458312169684\n",
            "Epoch: 624 w1: 7.502131990316605 w2: 1.7113754537997483 b: -3.62549829073323 loss: 0.3221207953808\n",
            "Epoch: 625 w1: 7.487778578416726 w2: 1.6396144717608565 b: -3.715652719229094 loss: 0.30189530538187614\n",
            "Epoch: 626 w1: 7.494534279525633 w2: 1.5817498340935412 b: -3.7222531561328256 loss: 0.5475264047549576\n",
            "Epoch: 627 w1: 7.508240677549187 w2: 1.5865057849558901 b: -3.7240161013607085 loss: 0.2907703025403148\n",
            "Epoch: 628 w1: 7.509771687244963 w2: 1.6297388042112633 b: -3.7262316501556314 loss: 0.21978842012696848\n",
            "Epoch: 629 w1: 7.508287654917268 w2: 1.6596516123776022 b: -3.7417308659524986 loss: 0.32085013742290985\n",
            "Epoch: 630 w1: 7.460371761822243 w2: 1.6202247378493682 b: -3.8687427719532557 loss: 0.43323027013429793\n",
            "Epoch: 631 w1: 7.481678825716551 w2: 1.6082299041473527 b: -3.86121698972875 loss: 0.3033093642301446\n",
            "Epoch: 632 w1: 7.500744602312813 w2: 1.6559319687735827 b: -3.792635011008042 loss: 0.5239477949389604\n",
            "Epoch: 633 w1: 7.506737184350803 w2: 1.6942871136659188 b: -3.788194142557171 loss: 0.30103551993535477\n",
            "Epoch: 634 w1: 7.52255636384631 w2: 1.6719475442086589 b: -3.758125419307464 loss: 0.5710813327761172\n",
            "Epoch: 635 w1: 7.501227214015282 w2: 1.5962664849253814 b: -3.814262010162118 loss: 0.6628489439075381\n",
            "Epoch: 636 w1: 7.514055842470921 w2: 1.6079687259719726 b: -3.8121486357180294 loss: 0.20900766684923136\n",
            "Epoch: 637 w1: 7.552662866868396 w2: 1.616068230103955 b: -3.723911731333599 loss: 0.5539927252102125\n",
            "Epoch: 638 w1: 7.557445356198547 w2: 1.605650754994851 b: -3.751386979424749 loss: 0.25219165212361255\n",
            "Epoch: 639 w1: 7.5415808689608435 w2: 1.5416681653514746 b: -3.8318586166017488 loss: 0.42351393060129244\n",
            "Epoch: 640 w1: 7.550694744717029 w2: 1.5316392084805677 b: -3.847834157010312 loss: 0.20274639714016437\n",
            "Epoch: 641 w1: 7.60154949965604 w2: 1.5592835706679347 b: -3.73360154946735 loss: 0.5083112260706418\n",
            "Epoch: 642 w1: 7.614942407163927 w2: 1.5792014121771765 b: -3.730766133074074 loss: 0.20682928915140675\n",
            "Epoch: 643 w1: 7.641075906232743 w2: 1.5803937705405706 b: -3.6680446605353705 loss: 0.4572493785877998\n",
            "Epoch: 644 w1: 7.622196045101258 w2: 1.5661480147610394 b: -3.7343507436452077 loss: 0.3779519269218562\n",
            "Epoch: 645 w1: 7.657373593446643 w2: 1.5960636026462707 b: -3.682881411838967 loss: 0.21863233441437188\n",
            "Epoch: 646 w1: 7.636516668932663 w2: 1.5872761968756317 b: -3.743557362690205 loss: 0.31873129105696923\n",
            "Epoch: 647 w1: 7.635379512843723 w2: 1.543523481122165 b: -3.793862655841039 loss: 0.286747215370851\n",
            "Epoch: 648 w1: 7.65339761783955 w2: 1.5255047676694018 b: -3.795801213655022 loss: 0.23604814797037027\n",
            "Epoch: 649 w1: 7.663683370512678 w2: 1.4936548495594801 b: -3.815529792993199 loss: 0.29378531113476064\n",
            "Epoch: 650 w1: 7.654521476479881 w2: 1.4637990123534914 b: -3.867876465441883 loss: 0.38109252316172126\n",
            "Epoch: 651 w1: 7.645765124596853 w2: 1.4275478038965088 b: -3.8851510947029637 loss: 0.5888445004197219\n",
            "Epoch: 652 w1: 7.680946302557643 w2: 1.487897838509117 b: -3.8248010600903557 loss: 0.22153095739810305\n",
            "Epoch: 653 w1: 7.667537308220978 w2: 1.4824478387760107 b: -3.878874480932135 loss: 0.32272458626807676\n",
            "Epoch: 654 w1: 7.722828587352202 w2: 1.5366186989396722 b: -3.744541395452704 loss: 0.48928834081443207\n",
            "Epoch: 655 w1: 7.686401320673883 w2: 1.5465324304029568 b: -3.830365611121323 loss: 0.4306269007575661\n",
            "Epoch: 656 w1: 7.708936138670225 w2: 1.5834376978423568 b: -3.8033183389556995 loss: 0.22221670948914365\n",
            "Epoch: 657 w1: 7.710373617992437 w2: 1.5624345176864525 b: -3.834462480103239 loss: 0.2731741122865858\n",
            "Epoch: 658 w1: 7.6951639486946855 w2: 1.548574492685293 b: -3.89119298238103 loss: 0.32161972593134613\n",
            "Epoch: 659 w1: 7.698168622828035 w2: 1.5331572497769073 b: -3.9217654160334856 loss: 0.19479741329877162\n",
            "Epoch: 660 w1: 7.732451729246703 w2: 1.5168469588589257 b: -3.8514362210529436 loss: 0.5863474071246958\n",
            "Epoch: 661 w1: 7.741710288015251 w2: 1.4964559753098798 b: -3.8718272046019897 loss: 0.27331470876664304\n",
            "Epoch: 662 w1: 7.736047013063295 w2: 1.4301026709220896 b: -3.9381805089897797 loss: 0.3214259573470478\n",
            "Epoch: 663 w1: 7.767391039468304 w2: 1.4506667343924187 b: -3.899549303880128 loss: 0.21489322569695293\n",
            "Epoch: 664 w1: 7.7762312915205065 w2: 1.4534053373643652 b: -3.8724202065120674 loss: 0.6000483377782401\n",
            "Epoch: 665 w1: 7.777606225722219 w2: 1.483637905962735 b: -3.839183793517798 loss: 0.656550560725554\n",
            "Epoch: 666 w1: 7.773420183128105 w2: 1.4391947307549604 b: -3.8493814780033935 loss: 0.6261468706260774\n",
            "Epoch: 667 w1: 7.763878193685412 w2: 1.4411393741483727 b: -3.892676101073922 loss: 0.33805836160367114\n",
            "Epoch: 668 w1: 7.7697685455119165 w2: 1.490368475539008 b: -3.8858226849204778 loss: 0.3497666967497782\n",
            "Epoch: 669 w1: 7.726871951450317 w2: 1.399318760922084 b: -4.03080281310421 loss: 0.36317335980559545\n",
            "Epoch: 670 w1: 7.720008157742748 w2: 1.3784366144503777 b: -4.07442284447236 loss: 0.3780394148054305\n",
            "Epoch: 671 w1: 7.691586497813122 w2: 1.3305129823883213 b: -4.169915993712749 loss: 0.31654490484039105\n",
            "Epoch: 672 w1: 7.7154383982165555 w2: 1.3483237639023256 b: -4.1521052121987445 loss: 0.2609778436582676\n",
            "Epoch: 673 w1: 7.742431073318089 w2: 1.3764823923433598 b: -4.12394658375771 loss: 0.265759162182551\n",
            "Epoch: 674 w1: 7.750848629857776 w2: 1.420916450048298 b: -4.117623036846464 loss: 0.3719977332893896\n",
            "Epoch: 675 w1: 7.795029075345582 w2: 1.47441990606307 b: -4.042437882464402 loss: 0.3339793995529648\n",
            "Epoch: 676 w1: 7.815641143557182 w2: 1.5133526386564466 b: -3.9758234950623947 loss: 0.6483939323509923\n",
            "Epoch: 677 w1: 7.847580293823759 w2: 1.520703370279867 b: -3.9053957138559388 loss: 0.5137149622465821\n",
            "Epoch: 678 w1: 7.850250199935708 w2: 1.4591113221506988 b: -3.9507544027115316 loss: 0.3198170188477695\n",
            "Epoch: 679 w1: 7.872107506552203 w2: 1.5029091419186884 b: -3.9217982705584564 loss: 0.2471154058970643\n",
            "Epoch: 680 w1: 7.881088532158544 w2: 1.4565400754723894 b: -3.9518453489351217 loss: 0.29612115461666594\n",
            "Epoch: 681 w1: 7.891229362397891 w2: 1.4904400874383235 b: -3.9084151230400916 loss: 0.5169928306428917\n",
            "Epoch: 682 w1: 7.911938069586003 w2: 1.5223633649884019 b: -3.8861410372604093 loss: 0.19557060727771067\n",
            "Epoch: 683 w1: 7.922316216264123 w2: 1.5208782014805313 b: -3.893661064293253 loss: 0.2653172309690504\n",
            "Epoch: 684 w1: 7.899322805789276 w2: 1.5225922994882548 b: -3.9192907221506887 loss: 0.6519668906681131\n",
            "Epoch: 685 w1: 7.863441469143862 w2: 1.4771662226659055 b: -3.984493145094777 loss: 0.7190361077663348\n",
            "Epoch: 686 w1: 7.890549672079914 w2: 1.518102158352095 b: -3.9435572094085876 loss: 0.2399440402803395\n",
            "Epoch: 687 w1: 7.928426246347312 w2: 1.5124593289202386 b: -3.864220561973487 loss: 0.5490723371647318\n",
            "Epoch: 688 w1: 7.935187011516348 w2: 1.4839139189104062 b: -3.8927659719833194 loss: 0.270867448703018\n",
            "Epoch: 689 w1: 7.954985190788091 w2: 1.4948958941883101 b: -3.8383280745419035 loss: 0.6031776690132636\n",
            "Epoch: 690 w1: 7.943554381002879 w2: 1.5265985301423444 b: -3.868450694518655 loss: 0.2460980015065169\n",
            "Epoch: 691 w1: 7.929736803345359 w2: 1.5142164741254416 b: -3.9212024955061353 loss: 0.37772618898436106\n",
            "Epoch: 692 w1: 7.960557466990876 w2: 1.5599411327276473 b: -3.8307588167277093 loss: 0.5632463575106482\n",
            "Epoch: 693 w1: 7.98731635441579 w2: 1.556156900381606 b: -3.772898623915825 loss: 0.5355963399594049\n",
            "Epoch: 694 w1: 7.948321071159071 w2: 1.4807530113753262 b: -3.9017994988712523 loss: 0.43517230203023655\n",
            "Epoch: 695 w1: 7.937062239046139 w2: 1.4967741306903004 b: -3.9414216012452385 loss: 0.27653119470789705\n",
            "Epoch: 696 w1: 7.912023928084876 w2: 1.4698558165772249 b: -4.0209880963995115 loss: 0.33167621643061757\n",
            "Epoch: 697 w1: 7.883154407186977 w2: 1.4903538747139484 b: -4.084764112133928 loss: 0.4365466992810753\n",
            "Epoch: 698 w1: 7.918234173724285 w2: 1.5132675517228669 b: -4.037272710154192 loss: 0.2468714984814542\n",
            "Epoch: 699 w1: 7.9653617953401 w2: 1.531784338962728 b: -3.9319335176582477 loss: 0.5171446953301809\n",
            "Epoch: 700 w1: 7.98616096173979 w2: 1.560817736083283 b: -3.908740956562991 loss: 0.19644454095314806\n",
            "Epoch: 701 w1: 7.972466473164939 w2: 1.4839654185002251 b: -3.9954475494858244 loss: 0.3501351866362162\n",
            "Epoch: 702 w1: 7.976981987335251 w2: 1.5000613192334076 b: -3.9681137947852445 loss: 0.587598642685449\n",
            "Epoch: 703 w1: 7.950754801388855 w2: 1.534357987940198 b: -4.021489498822678 loss: 0.33018611141954546\n",
            "Epoch: 704 w1: 8.000110104557026 w2: 1.5609994886220504 b: -3.9087517313941476 loss: 0.5054812067587141\n",
            "Epoch: 705 w1: 8.030360969325582 w2: 1.5784582656133401 b: -3.835090120385933 loss: 0.43609715221014866\n",
            "Epoch: 706 w1: 8.070879805806085 w2: 1.5923131989516066 b: -3.7402540807767197 loss: 0.49499901961977383\n",
            "Epoch: 707 w1: 8.045185785228794 w2: 1.5709923845437253 b: -3.8208693907235545 loss: 0.42316293497334934\n",
            "Epoch: 708 w1: 8.016623093939119 w2: 1.563908321804999 b: -3.854877238034345 loss: 0.7198520843385416\n",
            "Epoch: 709 w1: 7.986240493094298 w2: 1.504392082143196 b: -3.961988783908637 loss: 0.3796055962131332\n",
            "Epoch: 710 w1: 8.016392517546473 w2: 1.5530738167324376 b: -3.9133070493193953 loss: 0.19537824418837402\n",
            "Epoch: 711 w1: 7.99419337996268 w2: 1.5254979481512496 b: -3.985272229537537 loss: 0.3666263856256226\n",
            "Epoch: 712 w1: 7.981967074851966 w2: 1.5122690649466883 b: -4.0372741071069385 loss: 0.35212867102092027\n",
            "Epoch: 713 w1: 8.010723149801775 w2: 1.5287724899063735 b: -3.9663521225966716 loss: 0.5123218341941246\n",
            "Epoch: 714 w1: 7.994491227565275 w2: 1.4949783561608379 b: -4.031475772024226 loss: 0.39913223002688625\n",
            "Epoch: 715 w1: 8.0021372962448 w2: 1.5053888433020524 b: -4.036340956133094 loss: 0.2869538631397857\n",
            "Epoch: 716 w1: 8.052777051688347 w2: 1.575290616254271 b: -3.9032602129842293 loss: 0.4657862196974432\n",
            "Epoch: 717 w1: 8.09278309617573 w2: 1.6324754439234341 b: -3.794070449616049 loss: 0.43960230308671117\n",
            "Epoch: 718 w1: 8.110734648707755 w2: 1.6156171068095342 b: -3.7610156737953866 loss: 0.503252487483952\n",
            "Epoch: 719 w1: 8.087537554839878 w2: 1.6053820495846924 b: -3.833463497131202 loss: 0.2909876010140659\n",
            "Epoch: 720 w1: 8.05254505173855 w2: 1.6146857324933306 b: -3.9128000869999653 loss: 0.43610698643500573\n",
            "Epoch: 721 w1: 8.048547241460255 w2: 1.5956547478305692 b: -3.9144297730876207 loss: 0.611539145113276\n",
            "Epoch: 722 w1: 8.025224957788433 w2: 1.5736338787312032 b: -3.991061776309362 loss: 0.3237880240988969\n",
            "Epoch: 723 w1: 8.065776256475777 w2: 1.6362046185511714 b: -3.9159696023417325 loss: 0.21260233166293238\n",
            "Epoch: 724 w1: 8.102657443302009 w2: 1.676373637290178 b: -3.8554972932301514 loss: 0.2379659302614309\n",
            "Epoch: 725 w1: 8.060644674673672 w2: 1.6733903451810745 b: -3.953067175123499 loss: 0.4256739891333887\n",
            "Epoch: 726 w1: 8.060115869940498 w2: 1.6437239835380586 b: -3.9923776882565973 loss: 0.2061704030510297\n",
            "Epoch: 727 w1: 8.085222918769754 w2: 1.6512159310797792 b: -3.927760227435229 loss: 0.4984272405038577\n",
            "Epoch: 728 w1: 8.044130821324233 w2: 1.5603719721609612 b: -4.063385628294252 loss: 0.5013911639568164\n",
            "Epoch: 729 w1: 8.04091477819491 w2: 1.57044764769369 b: -4.086660250101398 loss: 0.345280723177985\n",
            "Epoch: 730 w1: 8.037883156577452 w2: 1.5794604995134705 b: -4.115049986030571 loss: 0.3155691330427544\n",
            "Epoch: 731 w1: 8.057743873379593 w2: 1.5953342301631508 b: -4.099176255380891 loss: 0.25439369031127046\n",
            "Epoch: 732 w1: 8.094327059605885 w2: 1.6291953457059105 b: -4.006872411121881 loss: 0.5048725265314379\n",
            "Epoch: 733 w1: 8.093681581193696 w2: 1.5889485950885582 b: -4.0064712515399 loss: 0.6551866587923071\n",
            "Epoch: 734 w1: 8.10341714402936 w2: 1.6138406067077657 b: -3.962326135362191 loss: 0.615687793262984\n",
            "Epoch: 735 w1: 8.123817925365154 w2: 1.5703105230774592 b: -3.928598256234192 loss: 0.5575163188720028\n",
            "Epoch: 736 w1: 8.148104019711006 w2: 1.6161163883561527 b: -3.845815243490272 loss: 0.5833735212557107\n",
            "Epoch: 737 w1: 8.150420524509107 w2: 1.5762903633843957 b: -3.884333083152043 loss: 0.3011033603215009\n",
            "Epoch: 738 w1: 8.130136008455127 w2: 1.5516499687796972 b: -3.957242361568112 loss: 0.30103067967621394\n",
            "Epoch: 739 w1: 8.156593062399617 w2: 1.5991871572686684 b: -3.8717317494152503 loss: 0.58734606842634\n",
            "Epoch: 740 w1: 8.166969655849762 w2: 1.5885488562973877 b: -3.882370050386531 loss: 0.21227485057498355\n",
            "Epoch: 741 w1: 8.197526131063563 w2: 1.6309278136451377 b: -3.8315244525358323 loss: 0.15776293698699792\n",
            "Epoch: 742 w1: 8.184921778240614 w2: 1.6389489245117401 b: -3.873464580011151 loss: 0.29376797430080276\n",
            "Epoch: 743 w1: 8.150846071520835 w2: 1.575143306310938 b: -3.9838481142506463 loss: 0.4391315683412\n",
            "Epoch: 744 w1: 8.137866540139758 w2: 1.585008610390244 b: -4.024181409639604 loss: 0.2818207191885355\n",
            "Epoch: 745 w1: 8.114601748771195 w2: 1.5587355071739455 b: -4.1046170635654065 loss: 0.2829390539307143\n",
            "Epoch: 746 w1: 8.125043212129999 w2: 1.6228523837913924 b: -4.083377384173827 loss: 0.26304810583682425\n",
            "Epoch: 747 w1: 8.149828696957979 w2: 1.62832396977145 b: -4.023343981871644 loss: 0.4579729688313698\n",
            "Epoch: 748 w1: 8.17161742205514 w2: 1.611411694081702 b: -3.9774485931622183 loss: 0.5475018804445252\n",
            "Epoch: 749 w1: 8.150122592290364 w2: 1.585865611763412 b: -4.049339734978598 loss: 0.3607023097330076\n",
            "Epoch: 750 w1: 8.163432354023739 w2: 1.6189207816187627 b: -4.033831794308534 loss: 0.34737056855982595\n",
            "Epoch: 751 w1: 8.161483017818288 w2: 1.6667699775951785 b: -4.038904640338292 loss: 0.2590847942864583\n",
            "Epoch: 752 w1: 8.178036903756212 w2: 1.6421907713129644 b: -4.006058480660723 loss: 0.5492884655820574\n",
            "Epoch: 753 w1: 8.189307082210929 w2: 1.6009806106789495 b: -4.026633384868496 loss: 0.3463071146282119\n",
            "Epoch: 754 w1: 8.2316290957499 w2: 1.6143309907392747 b: -3.92968681267214 loss: 0.5021536415247276\n",
            "Epoch: 755 w1: 8.219504389245484 w2: 1.6009728390534212 b: -3.943575980197897 loss: 0.5593493766718718\n",
            "Epoch: 756 w1: 8.20928338999154 w2: 1.581426059090597 b: -3.995385330262155 loss: 0.40739691303940256\n",
            "Epoch: 757 w1: 8.203349929656087 w2: 1.5550588668296446 b: -4.0055915011503975 loss: 0.5860574964941304\n",
            "Epoch: 758 w1: 8.200944912124255 w2: 1.5330602922421765 b: -4.005355017438733 loss: 0.6366442356605323\n",
            "Epoch: 759 w1: 8.159293000479366 w2: 1.5259050189810455 b: -4.103063262117014 loss: 0.3719560372625616\n",
            "Epoch: 760 w1: 8.132266724491888 w2: 1.504173921701761 b: -4.142121245254103 loss: 0.764027060628972\n",
            "Epoch: 761 w1: 8.149854940283738 w2: 1.4744282744699144 b: -4.14875201824756 loss: 0.28484723386976096\n",
            "Epoch: 762 w1: 8.197104471400893 w2: 1.5413207999741954 b: -4.023082701366816 loss: 0.4821000926066659\n",
            "Epoch: 763 w1: 8.176787856725978 w2: 1.4975395567795324 b: -4.0633156031777204 loss: 0.6173166746204573\n",
            "Epoch: 764 w1: 8.126565056552197 w2: 1.4479249041256066 b: -4.195346185742234 loss: 0.47848342940456184\n",
            "Epoch: 765 w1: 8.170077481755492 w2: 1.489377981331355 b: -4.089825785463492 loss: 0.5016355956949832\n",
            "Epoch: 766 w1: 8.184601745713335 w2: 1.5113034214419536 b: -4.081909749968644 loss: 0.17299354593384056\n",
            "Epoch: 767 w1: 8.21301609476371 w2: 1.5419795499752647 b: -4.04367915479328 loss: 0.25324862002165505\n",
            "Epoch: 768 w1: 8.193966591713504 w2: 1.5279967968181616 b: -4.107179831940783 loss: 0.30571934114654625\n",
            "Epoch: 769 w1: 8.192843322327127 w2: 1.5068386661174265 b: -4.103446725891584 loss: 0.6259576728664378\n",
            "Epoch: 770 w1: 8.18927328607641 w2: 1.4898323408204148 b: -4.099941670865623 loss: 0.629301108873593\n",
            "Epoch: 771 w1: 8.187642773394154 w2: 1.5223917393882365 b: -4.110217015575144 loss: 0.35139443870639975\n",
            "Epoch: 772 w1: 8.214404812664291 w2: 1.5385296621792226 b: -4.08062533726281 loss: 0.2017240527342398\n",
            "Epoch: 773 w1: 8.234075638825685 w2: 1.5673326593103007 b: -4.057142028396269 loss: 0.18372480155500373\n",
            "Epoch: 774 w1: 8.282760752564819 w2: 1.5991841070235737 b: -3.941494427179202 loss: 0.5458089220010545\n",
            "Epoch: 775 w1: 8.304134464574211 w2: 1.6422949104145514 b: -3.8640169297938542 loss: 0.5771794654804367\n",
            "Epoch: 776 w1: 8.274732163907089 w2: 1.5979093714995116 b: -3.9586804079219724 loss: 0.3461688442302951\n",
            "Epoch: 777 w1: 8.277937103741687 w2: 1.6454262504420303 b: -3.952963929926376 loss: 0.2274914819032051\n",
            "Epoch: 778 w1: 8.263136619361767 w2: 1.6141367428949058 b: -4.011353194343532 loss: 0.4228573674769188\n",
            "Epoch: 779 w1: 8.279377116998953 w2: 1.5736690892945142 b: -3.989323513203204 loss: 0.5480506351895014\n",
            "Epoch: 780 w1: 8.254700960815423 w2: 1.5271355892340042 b: -4.077166838356508 loss: 0.43505825158830547\n",
            "Epoch: 781 w1: 8.272073898459194 w2: 1.5352778941389902 b: -4.069024533451522 loss: 0.21335494558649115\n",
            "Epoch: 782 w1: 8.294426679710194 w2: 1.5277717700247109 b: -4.019040862364389 loss: 0.5015444122834505\n",
            "Epoch: 783 w1: 8.310997264148703 w2: 1.547170889756555 b: -4.005352072242217 loss: 0.17240227203616199\n",
            "Epoch: 784 w1: 8.296743250936196 w2: 1.4831408265900146 b: -4.0849330386726725 loss: 0.2526691647830131\n",
            "Epoch: 785 w1: 8.252994147719328 w2: 1.4734496123206478 b: -4.187583569229653 loss: 0.39795874858730235\n",
            "Epoch: 786 w1: 8.288513009067163 w2: 1.511907482943807 b: -4.134636467063395 loss: 0.2548698373334831\n",
            "Epoch: 787 w1: 8.292100686852413 w2: 1.4796003176650168 b: -4.166943632342185 loss: 0.2850341551401199\n",
            "Epoch: 788 w1: 8.318696490301326 w2: 1.5048435678668297 b: -4.094387088871269 loss: 0.6274111195628225\n",
            "Epoch: 789 w1: 8.288808629182936 w2: 1.4859515563090813 b: -4.176552989546653 loss: 0.4405597388281349\n",
            "Epoch: 790 w1: 8.284459387629047 w2: 1.4731851726988952 b: -4.2095837130465235 loss: 0.3982614549595664\n",
            "Epoch: 791 w1: 8.245417390227407 w2: 1.4319581662343883 b: -4.3154891602265675 loss: 0.4347625578725923\n",
            "Epoch: 792 w1: 8.252836157800987 w2: 1.4771982023140073 b: -4.309867221423536 loss: 0.2787629148032879\n",
            "Epoch: 793 w1: 8.255411410984609 w2: 1.5110064131681862 b: -4.3158482004005005 loss: 0.3534186518563966\n",
            "Epoch: 794 w1: 8.245363359281844 w2: 1.5098920968868919 b: -4.3566712362872675 loss: 0.33063835977507655\n",
            "Epoch: 795 w1: 8.251659909088334 w2: 1.5736980210218077 b: -4.3429307539734054 loss: 0.2856025985506458\n",
            "Epoch: 796 w1: 8.263945032180548 w2: 1.5550982614708713 b: -4.310745260732766 loss: 0.6612232419515871\n",
            "Epoch: 797 w1: 8.279437353599302 w2: 1.5707226771380205 b: -4.3024925675957695 loss: 0.2761684137468267\n",
            "Epoch: 798 w1: 8.275510077702831 w2: 1.5988510851321711 b: -4.32195777995022 loss: 0.28718345886794266\n",
            "Epoch: 799 w1: 8.321488535057076 w2: 1.694207734761485 b: -4.226601130320907 loss: 0.2184804883674301\n",
            "Epoch: 800 w1: 8.320418650159677 w2: 1.6804733328485524 b: -4.218289423083843 loss: 0.6196129956805841\n",
            "Epoch: 801 w1: 8.303456281762463 w2: 1.685260677827194 b: -4.229290505109351 loss: 0.6806598299059916\n",
            "Epoch: 802 w1: 8.279506948318808 w2: 1.6348121806967042 b: -4.317032734928159 loss: 0.3649656692648273\n",
            "Epoch: 803 w1: 8.302432405291317 w2: 1.6164750959636383 b: -4.270769467172408 loss: 0.5752953527710822\n",
            "Epoch: 804 w1: 8.316901746012721 w2: 1.648818139626097 b: -4.215224782653397 loss: 0.5092318729405177\n",
            "Epoch: 805 w1: 8.347128943568936 w2: 1.6612220549251984 b: -4.1802911116244 loss: 0.2815250166398699\n",
            "Epoch: 806 w1: 8.361510323203682 w2: 1.6335649832853019 b: -4.152796925287829 loss: 0.5337755071929806\n",
            "Epoch: 807 w1: 8.377264883212302 w2: 1.6097272664091553 b: -4.155457390930777 loss: 0.2660877876226593\n",
            "Epoch: 808 w1: 8.386870983395461 w2: 1.5619832393858277 b: -4.1821252218739176 loss: 0.2534632761820016\n",
            "Epoch: 809 w1: 8.392380111002273 w2: 1.5461454820848788 b: -4.202954010304596 loss: 0.23321826217976427\n",
            "Epoch: 810 w1: 8.352605710051936 w2: 1.5240526124895921 b: -4.306615188953257 loss: 0.4796711562545954\n",
            "Epoch: 811 w1: 8.350205455163158 w2: 1.5560878702694516 b: -4.322943255891026 loss: 0.30596710221548934\n",
            "Epoch: 812 w1: 8.350535887840074 w2: 1.5930573414207265 b: -4.330821707796645 loss: 0.3118171775973834\n",
            "Epoch: 813 w1: 8.364978290554548 w2: 1.6025170723368136 b: -4.328749826996148 loss: 0.22650932753384506\n",
            "Epoch: 814 w1: 8.352735981008511 w2: 1.5955004675163724 b: -4.379282933253718 loss: 0.2619264310350037\n",
            "Epoch: 815 w1: 8.380843746268855 w2: 1.6481102700355008 b: -4.33374974619546 loss: 0.22411753976866988\n",
            "Epoch: 816 w1: 8.389902287334452 w2: 1.6021377243262485 b: -4.360265076631192 loss: 0.24345047405618098\n",
            "Epoch: 817 w1: 8.393178015091957 w2: 1.6409842210098236 b: -4.361647534459162 loss: 0.2928733300408862\n",
            "Epoch: 818 w1: 8.400109246885762 w2: 1.6171907579643456 b: -4.38544099750464 loss: 0.2724148437758562\n",
            "Epoch: 819 w1: 8.413101275153329 w2: 1.6374884448446163 b: -4.376122303392593 loss: 0.2954823191638419\n",
            "Epoch: 820 w1: 8.407216245848531 w2: 1.6583043330536547 b: -4.402376833308411 loss: 0.2601474666891026\n",
            "Epoch: 821 w1: 8.429207619018852 w2: 1.6710052018343091 b: -4.339779019535128 loss: 0.6473930912161378\n",
            "Epoch: 822 w1: 8.452382611543687 w2: 1.6696345055943203 b: -4.322068660856238 loss: 0.2618552767785132\n",
            "Epoch: 823 w1: 8.484840601756611 w2: 1.6998807812290562 b: -4.273327277287177 loss: 0.23789680768166813\n",
            "Epoch: 824 w1: 8.505389454770494 w2: 1.6903356795398667 b: -4.226904708955261 loss: 0.5150219034030223\n",
            "Epoch: 825 w1: 8.4846987813199 w2: 1.6473047297340708 b: -4.300973999311945 loss: 0.35404886540634006\n",
            "Epoch: 826 w1: 8.488878558240408 w2: 1.709389596798789 b: -4.2888881503501874 loss: 0.28486593168669744\n",
            "Epoch: 827 w1: 8.496302285610648 w2: 1.701930192029423 b: -4.260523224846175 loss: 0.6076501380961042\n",
            "Epoch: 828 w1: 8.473919480582502 w2: 1.63537994785701 b: -4.352151833514816 loss: 0.41309962370310227\n",
            "Epoch: 829 w1: 8.454662013181892 w2: 1.5970946435222153 b: -4.4271205837156336 loss: 0.28701074015335415\n",
            "Epoch: 830 w1: 8.464842147402402 w2: 1.619345447909154 b: -4.383565124535656 loss: 0.6141599862339611\n",
            "Epoch: 831 w1: 8.465456359065405 w2: 1.6408916935752655 b: -4.3980573126846965 loss: 0.3145658931230336\n",
            "Epoch: 832 w1: 8.478263112122526 w2: 1.643822728506178 b: -4.3992611093804195 loss: 0.18737793001090394\n",
            "Epoch: 833 w1: 8.523254279249189 w2: 1.6638449300359746 b: -4.294683743474261 loss: 0.5234901608602087\n",
            "Epoch: 834 w1: 8.541573323927437 w2: 1.6686254551090338 b: -4.242147610128644 loss: 0.6016679699726079\n",
            "Epoch: 835 w1: 8.530456346359871 w2: 1.5959529686615368 b: -4.273951614219854 loss: 0.713100920000455\n",
            "Epoch: 836 w1: 8.545340577644316 w2: 1.5949885188069364 b: -4.274916064074454 loss: 0.2772532955968729\n",
            "Epoch: 837 w1: 8.550048800954638 w2: 1.6335776033865774 b: -4.275045950061477 loss: 0.27429249177961273\n",
            "Epoch: 838 w1: 8.550722140169896 w2: 1.6422746191740494 b: -4.253821860497873 loss: 0.6026972864921367\n",
            "Epoch: 839 w1: 8.54060149735942 w2: 1.5927541563438625 b: -4.278737185297998 loss: 0.6860284952110385\n",
            "Epoch: 840 w1: 8.508765236906154 w2: 1.564426401022792 b: -4.367300649489845 loss: 0.433283336866197\n",
            "Epoch: 841 w1: 8.527564669476387 w2: 1.5404177036650821 b: -4.368205723531745 loss: 0.2569300944748858\n",
            "Epoch: 842 w1: 8.51158505968033 w2: 1.524527499997745 b: -4.425290744502352 loss: 0.2958802837428534\n",
            "Epoch: 843 w1: 8.54822102560341 w2: 1.5543955708303872 b: -4.371430470557256 loss: 0.3255834841476294\n",
            "Epoch: 844 w1: 8.537719620404706 w2: 1.4879673490558967 b: -4.44216162818228 loss: 0.2544957850221556\n",
            "Epoch: 845 w1: 8.546202230523818 w2: 1.5289124072710212 b: -4.436885365963687 loss: 0.2778805464849847\n",
            "Epoch: 846 w1: 8.511291436117064 w2: 1.525709456385422 b: -4.5203674430117005 loss: 0.43976879718207573\n",
            "Epoch: 847 w1: 8.5221365261542 w2: 1.5896030012809177 b: -4.498768095308092 loss: 0.33340256367426296\n",
            "Epoch: 848 w1: 8.538374759562473 w2: 1.621243218377805 b: -4.480366093382157 loss: 0.30075062033493694\n",
            "Epoch: 849 w1: 8.541801515302353 w2: 1.6174425582892136 b: -4.458533122887637 loss: 0.6829913974558695\n",
            "Epoch: 850 w1: 8.540133249822642 w2: 1.6391230827263354 b: -4.4768225988953265 loss: 0.3200006544091378\n",
            "Epoch: 851 w1: 8.543154134449448 w2: 1.6336516245058206 b: -4.456762755284711 loss: 0.6262611303289413\n",
            "Epoch: 852 w1: 8.569368825734232 w2: 1.671193403006546 b: -4.419220976783985 loss: 0.16688172916573088\n",
            "Epoch: 853 w1: 8.593028428870653 w2: 1.7195040607411345 b: -4.342500869098352 loss: 0.628026111705062\n",
            "Epoch: 854 w1: 8.588435135586186 w2: 1.71312885952913 b: -4.334827263582185 loss: 0.5583501413893394\n",
            "Epoch: 855 w1: 8.591164068540877 w2: 1.7464448680294145 b: -4.33956431411561 loss: 0.2632557369009026\n",
            "Epoch: 856 w1: 8.57967766336236 w2: 1.7387414099980534 b: -4.385261828814747 loss: 0.3684670710887272\n",
            "Epoch: 857 w1: 8.600145064624348 w2: 1.7581159011922973 b: -4.365887337620503 loss: 0.249283040103793\n",
            "Epoch: 858 w1: 8.594243289740875 w2: 1.7593082060112732 b: -4.396561884680032 loss: 0.2905005635914505\n",
            "Epoch: 859 w1: 8.606021821289785 w2: 1.7652349313146483 b: -4.3980072846743825 loss: 0.21167770419053303\n",
            "Epoch: 860 w1: 8.594533523682061 w2: 1.7752568565848292 b: -4.43387206080564 loss: 0.30858001535333746\n",
            "Epoch: 861 w1: 8.58303319302478 w2: 1.7773206993536381 b: -4.476810725832348 loss: 0.31971535414186725\n",
            "Epoch: 862 w1: 8.590340959904804 w2: 1.7938031315413785 b: -4.439195035030938 loss: 0.5847433537486342\n",
            "Epoch: 863 w1: 8.590083591448813 w2: 1.8261988835548513 b: -4.450098164607004 loss: 0.30348864571299244\n",
            "Epoch: 864 w1: 8.596675149596503 w2: 1.811850918018654 b: -4.423476169154192 loss: 0.6564848661938083\n",
            "Epoch: 865 w1: 8.596437542823779 w2: 1.804879468470514 b: -4.448403919451233 loss: 0.36117881099789834\n",
            "Epoch: 866 w1: 8.603342288976556 w2: 1.8004320304297623 b: -4.463928105001944 loss: 0.21845429395614963\n",
            "Epoch: 867 w1: 8.60926586603426 w2: 1.806382449261056 b: -4.4328532927055155 loss: 0.6165468545257321\n",
            "Epoch: 868 w1: 8.601092412641492 w2: 1.8384172695434238 b: -4.413584755980128 loss: 0.6326202605127984\n",
            "Epoch: 869 w1: 8.592064593903526 w2: 1.843450745654615 b: -4.4498796280224875 loss: 0.36010992542940257\n",
            "Epoch: 870 w1: 8.610320811359085 w2: 1.8623247660852555 b: -4.431005607591847 loss: 0.14650236162971267\n",
            "Epoch: 871 w1: 8.62931303803349 w2: 1.8890388744269453 b: -4.408405252223474 loss: 0.1516038407171972\n",
            "Epoch: 872 w1: 8.634697795932817 w2: 1.875106147574804 b: -4.429692106649498 loss: 0.2163286640970574\n",
            "Epoch: 873 w1: 8.633946273555724 w2: 1.8818738927300125 b: -4.448619765411408 loss: 0.3215352110113005\n",
            "Epoch: 874 w1: 8.604688264791957 w2: 1.891907852267315 b: -4.516065201756026 loss: 0.3301295118957936\n",
            "Epoch: 875 w1: 8.60935310565204 w2: 1.8840634441452886 b: -4.534329029870049 loss: 0.33531460404902713\n",
            "Epoch: 876 w1: 8.604243279944031 w2: 1.9074468247342307 b: -4.553964288676161 loss: 0.253701811379844\n",
            "Epoch: 877 w1: 8.626210426814067 w2: 1.8928376976197734 b: -4.543403215512416 loss: 0.23890885103091902\n",
            "Epoch: 878 w1: 8.644682095905718 w2: 1.9171422549236568 b: -4.5228083253125595 loss: 0.1392913996424692\n",
            "Epoch: 879 w1: 8.686035204150135 w2: 1.9598091560631745 b: -4.414866079351759 loss: 0.5575925023434228\n",
            "Epoch: 880 w1: 8.687530076832198 w2: 1.924536032422865 b: -4.409718486078917 loss: 0.6641014207569942\n",
            "Epoch: 881 w1: 8.7198191876773 w2: 1.9188884971916804 b: -4.3329769038853225 loss: 0.5565807692248304\n",
            "Epoch: 882 w1: 8.681587934743822 w2: 1.8752480936760807 b: -4.439088511973369 loss: 0.44871349131267274\n",
            "Epoch: 883 w1: 8.677321945085746 w2: 1.8221956436872577 b: -4.492140961962193 loss: 0.2787307690158286\n",
            "Epoch: 884 w1: 8.68697801435039 w2: 1.860788113635354 b: -4.477658608234175 loss: 0.27567415222819797\n",
            "Epoch: 885 w1: 8.700016689359376 w2: 1.8608761193677879 b: -4.477570602501741 loss: 0.24031322487511192\n",
            "Epoch: 886 w1: 8.683499535719676 w2: 1.8477507901450152 b: -4.531857354862884 loss: 0.3562035760665751\n",
            "Epoch: 887 w1: 8.688918141256453 w2: 1.8503686798341221 b: -4.504018931289186 loss: 0.6792151385575876\n",
            "Epoch: 888 w1: 8.696351952742432 w2: 1.910887265471563 b: -4.486310691099596 loss: 0.2516907703168562\n",
            "Epoch: 889 w1: 8.708484740785863 w2: 1.8666707457336835 b: -4.507322529145034 loss: 0.2622390827830642\n",
            "Epoch: 890 w1: 8.700425446438405 w2: 1.897818609443316 b: -4.487892193673411 loss: 0.6335062002056402\n",
            "Epoch: 891 w1: 8.715419050491235 w2: 1.89604248352535 b: -4.444806427586352 loss: 0.5966474121030895\n",
            "Epoch: 892 w1: 8.698816732542259 w2: 1.880825128802374 b: -4.501902068213248 loss: 0.3300759691513769\n",
            "Epoch: 893 w1: 8.690300377078952 w2: 1.8505771236658703 b: -4.511704922619996 loss: 0.6062216224545106\n",
            "Epoch: 894 w1: 8.697974009370226 w2: 1.8319796195512317 b: -4.530302426734635 loss: 0.3093508896053699\n",
            "Epoch: 895 w1: 8.658724583081842 w2: 1.8074314707954706 b: -4.630651953580495 loss: 0.40745787097772773\n",
            "Epoch: 896 w1: 8.633918359327968 w2: 1.765777360420128 b: -4.713802471370285 loss: 0.2851373445427006\n",
            "Epoch: 897 w1: 8.66441147031445 w2: 1.7733906811374756 b: -4.639908415102786 loss: 0.6133191104417228\n",
            "Epoch: 898 w1: 8.693391985406807 w2: 1.7766522819963293 b: -4.5707693165475884 loss: 0.5745079554233161\n",
            "Epoch: 899 w1: 8.65053202791561 w2: 1.7461609218322647 b: -4.679198367967582 loss: 0.39249146073441515\n",
            "Epoch: 900 w1: 8.659819452297267 w2: 1.7615914775463497 b: -4.638066872102006 loss: 0.59487804225852\n",
            "Epoch: 901 w1: 8.666950098012492 w2: 1.7104717681711459 b: -4.666594138089704 loss: 0.24546255917617987\n",
            "Epoch: 902 w1: 8.682549230498386 w2: 1.6800495426427153 b: -4.636876424862608 loss: 0.5433073688897704\n",
            "Epoch: 903 w1: 8.680325949711062 w2: 1.7156838893960074 b: -4.607126739293674 loss: 0.6407776533234931\n",
            "Epoch: 904 w1: 8.692622397541292 w2: 1.7468284210542246 b: -4.552512455847476 loss: 0.5449171588035926\n",
            "Epoch: 905 w1: 8.717397922912056 w2: 1.7705276109811159 b: -4.4789253042454 loss: 0.687004732375178\n",
            "Epoch: 906 w1: 8.73098229936891 w2: 1.7330150981062076 b: -4.493545558747402 loss: 0.30177756144466805\n",
            "Epoch: 907 w1: 8.702434691452247 w2: 1.6822581184516583 b: -4.585482380791897 loss: 0.32050729003388206\n",
            "Epoch: 908 w1: 8.691317541001165 w2: 1.702157405643361 b: -4.5775839925753115 loss: 0.7118232048877938\n",
            "Epoch: 909 w1: 8.660396558403631 w2: 1.7072155996073286 b: -4.650157138223466 loss: 0.32253269943147106\n",
            "Epoch: 910 w1: 8.658685083226187 w2: 1.6771176992000938 b: -4.689576858147506 loss: 0.22761722820168884\n",
            "Epoch: 911 w1: 8.690870291919493 w2: 1.6447978656489974 b: -4.628890478536974 loss: 0.6422331397773757\n",
            "Epoch: 912 w1: 8.689391630044298 w2: 1.6215085400117475 b: -4.623612178557843 loss: 0.6445263187498592\n",
            "Epoch: 913 w1: 8.711251927082191 w2: 1.6432963587764393 b: -4.601824359793151 loss: 0.25922798484309384\n",
            "Epoch: 914 w1: 8.718273878594443 w2: 1.6922764750220283 b: -4.591929964216643 loss: 0.3544359404306211\n",
            "Epoch: 915 w1: 8.69821936883325 w2: 1.6605105028712195 b: -4.663024957358859 loss: 0.2918431226555028\n",
            "Epoch: 916 w1: 8.689580537180655 w2: 1.6038644358373033 b: -4.725603831920705 loss: 0.22482703647121555\n",
            "Epoch: 917 w1: 8.702469054744212 w2: 1.6594897391657142 b: -4.70665089622812 loss: 0.28285511043204886\n",
            "Epoch: 918 w1: 8.736401175607872 w2: 1.68428133112019 b: -4.6214013621621355 loss: 0.5925382872181757\n",
            "Epoch: 919 w1: 8.749149584281433 w2: 1.7493624708443545 b: -4.596853268802443 loss: 0.2527947925809762\n",
            "Epoch: 920 w1: 8.756762704970482 w2: 1.721463579080902 b: -4.574297777364496 loss: 0.6752795018198483\n",
            "Epoch: 921 w1: 8.808004511701034 w2: 1.7525563950993748 b: -4.453776427238531 loss: 0.5507069037028117\n",
            "Epoch: 922 w1: 8.81538272180479 w2: 1.766719935092259 b: -4.455907628369272 loss: 0.29400473195188903\n",
            "Epoch: 923 w1: 8.790162981251619 w2: 1.72314767379089 b: -4.544838306070704 loss: 0.3202696857899951\n",
            "Epoch: 924 w1: 8.774623460677704 w2: 1.7297417857944468 b: -4.589665297442536 loss: 0.2531372995343451\n",
            "Epoch: 925 w1: 8.787243511079494 w2: 1.7359168548368382 b: -4.589950293744857 loss: 0.19484167741785743\n",
            "Epoch: 926 w1: 8.809050835973059 w2: 1.7751654487790967 b: -4.520598243608716 loss: 0.6338310844510543\n",
            "Epoch: 927 w1: 8.799103627702525 w2: 1.746059501280989 b: -4.5684751338781515 loss: 0.3557492853438379\n",
            "Epoch: 928 w1: 8.820977061326337 w2: 1.7359438129392561 b: -4.555063623896956 loss: 0.26983426175773123\n",
            "Epoch: 929 w1: 8.822339729907029 w2: 1.7737896861448743 b: -4.5602401205950205 loss: 0.29419685281930164\n",
            "Epoch: 930 w1: 8.837661918707935 w2: 1.8302804345411814 b: -4.528173498106869 loss: 0.3212726915667661\n",
            "Epoch: 931 w1: 8.841328576209314 w2: 1.8289325382741406 b: -4.543901632725498 loss: 0.3438928341196267\n",
            "Epoch: 932 w1: 8.821541058741 w2: 1.802409280291047 b: -4.610950156747634 loss: 0.3015507416767469\n",
            "Epoch: 933 w1: 8.792391202671118 w2: 1.8194824857003613 b: -4.675569387941126 loss: 0.35970702676576904\n",
            "Epoch: 934 w1: 8.800001471871674 w2: 1.8099851302027739 b: -4.688438159373039 loss: 0.22110610334767686\n",
            "Epoch: 935 w1: 8.79704958099376 w2: 1.7828066706383663 b: -4.686708169783524 loss: 0.637395013190066\n",
            "Epoch: 936 w1: 8.819357084562094 w2: 1.8345215728342918 b: -4.607463819978925 loss: 0.5901937560803658\n",
            "Epoch: 937 w1: 8.791264203467582 w2: 1.7673531274996406 b: -4.709964456035682 loss: 0.3762848692973151\n",
            "Epoch: 938 w1: 8.800523023852717 w2: 1.7830649098211393 b: -4.706311811531832 loss: 0.33611928118864753\n",
            "Epoch: 939 w1: 8.796557334173578 w2: 1.8251712930221027 b: -4.715809927558284 loss: 0.36970944685259893\n",
            "Epoch: 940 w1: 8.792331020300157 w2: 1.8427279867417534 b: -4.7361486696751625 loss: 0.2789098396214236\n",
            "Epoch: 941 w1: 8.798299900954559 w2: 1.8540848048371765 b: -4.701759581218628 loss: 0.6137024882693467\n",
            "Epoch: 942 w1: 8.847757967170283 w2: 1.889616727074268 b: -4.580386864501215 loss: 0.5211774990536888\n",
            "Epoch: 943 w1: 8.847669411279247 w2: 1.950545292112433 b: -4.573067149481488 loss: 0.4161550136937286\n",
            "Epoch: 944 w1: 8.806274426196204 w2: 1.9216924845184546 b: -4.679041183730749 loss: 0.38117141252035713\n",
            "Epoch: 945 w1: 8.789427122157752 w2: 1.920142994001838 b: -4.728601835392857 loss: 0.21890854910817512\n",
            "Epoch: 946 w1: 8.809634148655814 w2: 1.9114367887954395 b: -4.716801867652301 loss: 0.2759884300913255\n",
            "Epoch: 947 w1: 8.800460787519814 w2: 1.8978094055641073 b: -4.763722396725138 loss: 0.32369446499258464\n",
            "Epoch: 948 w1: 8.7913724518973 w2: 1.9035673874845245 b: -4.800586539965791 loss: 0.28522064289176374\n",
            "Epoch: 949 w1: 8.789312957708024 w2: 1.8642256994479502 b: -4.842919481373907 loss: 0.22456770101312223\n",
            "Epoch: 950 w1: 8.81294877509382 w2: 1.8997638678608006 b: -4.8101193414521015 loss: 0.29414790323977685\n",
            "Epoch: 951 w1: 8.828272563852803 w2: 1.8686075052072804 b: -4.7800793304504925 loss: 0.6085668083868645\n",
            "Epoch: 952 w1: 8.854278435966545 w2: 1.8690565202490004 b: -4.718761131994513 loss: 0.5768928960478863\n",
            "Epoch: 953 w1: 8.868299543823394 w2: 1.9015507656619566 b: -4.69926254598634 loss: 0.31955993019970524\n",
            "Epoch: 954 w1: 8.902488171971592 w2: 1.9271467168600662 b: -4.61108809593939 loss: 0.5277578955223328\n",
            "Epoch: 955 w1: 8.902335021487813 w2: 1.8886459336630896 b: -4.608263182926222 loss: 0.6553470831325522\n",
            "Epoch: 956 w1: 8.907005753416442 w2: 1.8785985853162595 b: -4.589006289392583 loss: 0.6339394385084746\n",
            "Epoch: 957 w1: 8.930683508953072 w2: 1.8735036630791364 b: -4.571266217257514 loss: 0.23526808321954926\n",
            "Epoch: 958 w1: 8.947213834714068 w2: 1.8819415192543738 b: -4.562828361082277 loss: 0.19760351578299346\n",
            "Epoch: 959 w1: 8.932487549630961 w2: 1.8414244934879118 b: -4.587209390497914 loss: 0.6641958834535406\n",
            "Epoch: 960 w1: 8.95476664038219 w2: 1.833678073118378 b: -4.572385423406215 loss: 0.24351852933614787\n",
            "Epoch: 961 w1: 8.951876346814249 w2: 1.7917593098794213 b: -4.618133252630386 loss: 0.2436815271502279\n",
            "Epoch: 962 w1: 8.967154650418845 w2: 1.8181168069965867 b: -4.5627691418180065 loss: 0.6060117611915763\n",
            "Epoch: 963 w1: 8.978739405447092 w2: 1.7862063318789556 b: -4.579728501504473 loss: 0.2791147095072573\n",
            "Epoch: 964 w1: 8.98998344126239 w2: 1.7745326611154635 b: -4.546297736369821 loss: 0.6771082583101571\n",
            "Epoch: 965 w1: 9.004565972867521 w2: 1.785906653728818 b: -4.534923743756467 loss: 0.1721030763945289\n",
            "Epoch: 966 w1: 9.033324811063737 w2: 1.7589889309515923 b: -4.475896185154753 loss: 0.5612032237314122\n",
            "Epoch: 967 w1: 9.020834322898372 w2: 1.7438023681103054 b: -4.519665239028996 loss: 0.3163456275510213\n",
            "Epoch: 968 w1: 9.045462204582705 w2: 1.7880292692135256 b: -4.479510950321629 loss: 0.18567048652538107\n",
            "Epoch: 969 w1: 9.056954262192798 w2: 1.7663863393560335 b: -4.488803892258096 loss: 0.2798504735667175\n",
            "Epoch: 970 w1: 9.06882542155399 w2: 1.7193892901683911 b: -4.4713413773034105 loss: 0.5669602035607119\n",
            "Epoch: 971 w1: 9.072423178869279 w2: 1.7330420022331032 b: -4.438096644707152 loss: 0.6577595765142636\n",
            "Epoch: 972 w1: 9.057731759510148 w2: 1.7328006593862417 b: -4.483662150872138 loss: 0.3882554224665187\n",
            "Epoch: 973 w1: 9.05793024013005 w2: 1.7017667820867495 b: -4.522291959595271 loss: 0.23735325083298556\n",
            "Epoch: 974 w1: 9.070200963078634 w2: 1.7113310199841874 b: -4.520065727218088 loss: 0.26303792091704464\n",
            "Epoch: 975 w1: 9.061411698856354 w2: 1.6827448992627203 b: -4.527949846356301 loss: 0.6511467213076393\n",
            "Epoch: 976 w1: 9.030428081125946 w2: 1.6761420228728334 b: -4.6040498409591555 loss: 0.44298365802022543\n",
            "Epoch: 977 w1: 9.053733262568237 w2: 1.6717363980037896 b: -4.550039052423621 loss: 0.5180931163794289\n",
            "Epoch: 978 w1: 9.031123547848672 w2: 1.6668821580229147 b: -4.571849704707382 loss: 0.713784047730715\n",
            "Epoch: 979 w1: 9.062667381745326 w2: 1.7232788121988651 b: -4.515453050531431 loss: 0.22252391815680928\n",
            "Epoch: 980 w1: 9.059664346678662 w2: 1.6831312373968041 b: -4.5597201912245 loss: 0.2774666449931812\n",
            "Epoch: 981 w1: 9.008189874308975 w2: 1.6443818900999352 b: -4.687137486927849 loss: 0.4154582268223262\n",
            "Epoch: 982 w1: 8.991760047657618 w2: 1.6571850213152368 b: -4.69102905653966 loss: 0.7089511251388079\n",
            "Epoch: 983 w1: 9.005957739739767 w2: 1.659814288931262 b: -4.688399788923635 loss: 0.21283359370280727\n",
            "Epoch: 984 w1: 9.000666905396216 w2: 1.6219941851779343 b: -4.696153865289257 loss: 0.6485032453668328\n",
            "Epoch: 985 w1: 9.022559423962965 w2: 1.665784613938497 b: -4.622062065907445 loss: 0.6246080336957754\n",
            "Epoch: 986 w1: 9.013469818231663 w2: 1.6629838166152038 b: -4.661820732313816 loss: 0.32834044900055087\n",
            "Epoch: 987 w1: 9.032808383411636 w2: 1.643511501646575 b: -4.6583190100806044 loss: 0.249562001937494\n",
            "Epoch: 988 w1: 9.078430313473632 w2: 1.704155320056409 b: -4.535766312692291 loss: 0.4983209990062682\n",
            "Epoch: 989 w1: 9.077891397734183 w2: 1.6715784359189243 b: -4.572396046242429 loss: 0.2674898629109719\n",
            "Epoch: 990 w1: 9.070756245485516 w2: 1.6212081554080209 b: -4.626681018245153 loss: 0.19952458671096981\n",
            "Epoch: 991 w1: 9.041028800906517 w2: 1.572580164493205 b: -4.723044045215291 loss: 0.27906243156618166\n",
            "Epoch: 992 w1: 9.087317037922768 w2: 1.5899419738909129 b: -4.616185448140441 loss: 0.5751544999339887\n",
            "Epoch: 993 w1: 9.119972665173703 w2: 1.6048527796861571 b: -4.536097172297371 loss: 0.5572494249171676\n",
            "Epoch: 994 w1: 9.114237696486178 w2: 1.546278766361588 b: -4.59467118562194 loss: 0.26849640505698763\n",
            "Epoch: 995 w1: 9.13712454738847 w2: 1.5751740983761202 b: -4.565775853607407 loss: 0.20911098736151743\n",
            "Epoch: 996 w1: 9.150979025013292 w2: 1.5629893456112411 b: -4.568725472499098 loss: 0.19174408264877488\n",
            "Epoch: 997 w1: 9.16391395770903 w2: 1.5414845141239424 b: -4.573883422493478 loss: 0.20389491800932108\n",
            "Epoch: 998 w1: 9.149206954908628 w2: 1.5395276143118553 b: -4.61973320513816 loss: 0.35232679251959714\n",
            "Epoch: 999 w1: 9.105847585230277 w2: 1.5219854796043242 b: -4.725288882590523 loss: 0.38153109089155696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bh6tp9BnkZe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4uf2I1elU7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}